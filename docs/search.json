[
  {
    "objectID": "labs/lab-01-roulette.html",
    "href": "labs/lab-01-roulette.html",
    "title": "Lab 01: Roulette",
    "section": "",
    "text": "We will simulate the casino game of American roulette! On an American roulette wheel, there are 38 equally-sized spaces that differ in color and number value:\n\nTwo spaces are green, and are labelled 0 and 00\nThe remaining spaces alternate red and black and take on the values 1-36\n\nThere is no particular order to the numbers\n\n\nThe game is simple: a ball is dropped and spins along the roulette until it settles in one of the 38 spaces. Each space has an equal chance of being landed on.\n\n\n\n\n\nDiffering wagers or bets can be made on where the ball will end up landing. For example, it is common to bet on a color. If you “bet on black”, you think the ball will land in a black-colored space. Or you might “bet on events”, which means you think the ball will land in a space with an even number greater than 0.\nYou wager some money when you make a bet. For example, if I bet $5 and I win, I will get my original $5 back and also gain $5 from the house. So I net $5. If I lose, then the house takes my $5 and I net -$5. In summary:\n\nIf I win, I net the amount that I bet\nIf I lose, I net the negative amount that I bet\n\nIn either case, your net gain will be either positive or negative.\nBecause this is a casino game, we know that the house always wins. So, the purpose of this assignment is to simulate/demonstrate that the player will always lose money in the long run."
  },
  {
    "objectID": "labs/lab-01-roulette.html#assignment",
    "href": "labs/lab-01-roulette.html#assignment",
    "title": "Lab 01: Roulette",
    "section": "Assignment",
    "text": "Assignment\nImagine that you have unlimited funds and will play roulette n number of times. You can choose any integer value of n greater than 200, but be sure to store it as a variable for reproducibility. You will always bet on red and wager $5. For each one of the n rounds, keep track of the net gain.\nAt the end of your gambling, obtain and report the sum and average of your net earnings.\nOptional: make a plot of a running total of your net gains (i.e. the x-axis represents the iteration/round of betting, and the y-axis represents the total gains up to and including that round).\nPlease clone the Lab 01 GitHub repository and work in the lab-01-roulette.Rmd file provided for you.\n\nDetails\nFor simplicity, you can assume that the red spaces take on the values (1, 2, …, 18) and the black spaces take on the values (19, 20, …, 36). You can decide how you would like to represent the two green spaces.\nHere is some structure that might help you design your code: you will need to create a for loop where on every iteration you should:\n\n“Spin” the roulette\nEvaluate how the outcome of your spin compares to your bet\nMake note of the net gain on that iteration\n\n\n\nConcepts used\n\nfor loops\nConditional statements\nComparing R objects\nCreating and modifying vectors\nWorking with GitHub: try to regularly commit your changes and push them back to GitHub!"
  },
  {
    "objectID": "labs/lab-01-roulette.html#submission-details",
    "href": "labs/lab-01-roulette.html#submission-details",
    "title": "Lab 01: Roulette",
    "section": "Submission details",
    "text": "Submission details\nKnit, commit, and push your project back to github.com using the GitHub Desktop client.\nSubmit your knitted PDF onto Canvas. You may need to install the tinytex package to knit to PDF."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Intro to base R\n\n\n\nFeb 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nConditions and for loops\n\n\n\nFeb 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regression\n\n\n\nFeb 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCreating functions\n\n\n\nMar 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nEncoding categorical variables\n\n\n\nMar 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLOOCV\n\n\n\nMar 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLists\n\n\n\nMar 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression trees (part 1)\n\n\n\nMar 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRegression trees (pruning)\n\n\n\nMar 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBagging implementations\n\n\n\nMar 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBagging trees\n\n\n\nMar 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic regression\n\n\n\nApr 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nClass Imbalance\n\n\n\nApr 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nClassification trees\n\n\n\nApr 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nK-means clustering\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical clustering\n\n\n\nMay 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assignments.html#labs",
    "href": "assignments.html#labs",
    "title": "Assignments",
    "section": "Labs",
    "text": "Labs\n\n\n\n\n\n\n\nLab 01: Roulette\n\n\nCoding roulette\n\n\n\n\n\n\n\n\n\n\nLab 02: Linear regression\n\n\nMoneyball\n\n\n\n\n\n\n\n\n\n\nLab 03: Cross-validation\n\n\nSki resorts\n\n\n\n\n\n\n\n\n\n\nLab 04: Regression trees\n\n\nForest fires\n\n\n\n\n\n\n\n\n\n\nLab 05: Logistic Regression + KNN Classification\n\n\nRain in WaggaWagga\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assignments.html#implementations",
    "href": "assignments.html#implementations",
    "title": "Assignments",
    "section": "Implementations",
    "text": "Implementations\n\n\n\n\n\n\n\nKNN regression\n\n\nPart 1\n\n\n\nMar 2, 2023\n\n\n\n\n\n\n\n\n\n\n\nKNN regression\n\n\nPart 2\n\n\n\nMar 7, 2023\n\n\n\n\n\n\n\n\n\n\n\nBootstrap\n\n\nProbability of inclusion\n\n\n\nMar 28, 2023\n\n\n\n\n\n\n\n\n\n\n\nBagging\n\n\nRegression trees\n\n\n\nMar 30, 2023\n\n\n\n\n\n\n\n\n\n\n\nKNN classification\n\n\nPart 1\n\n\n\nApr 11, 2023\n\n\n\n\n\n\n\n\n\n\n\nBagging\n\n\nClassification trees\n\n\n\nApr 21, 2023\n\n\n\n\n\n\n\n\n\n\n\nK-means\n\n\nClustering\n\n\n\nMay 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math 218: Spring 2023",
    "section": "",
    "text": "Warner 104, TRF 8:40-9:30AM Eastern\nProfessor: Becky Tang (btang@middlebury.edu)\n\nOffice: Warner 214\nOffice hours: Tuesdays 3-4pm\nSchedule 1:1 meetings via Calendly\n\nTA: Doug Rosin\n\nOffice hours: Thursdays 7-9pm and Thursdays 7:30-9:30pm in Warner 216 (common space)\n\n\nVisit the schedule page to see the current course schedule, lecture notes, and due dates.\nVisit the assignments page to see the current list of assignments."
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "Math 218: Spring 2023",
    "section": "Materials",
    "text": "Materials\nThere is no required textbook for this course.\nYou should have a fully-charged laptop, tablet with keyboard, or comparable device to every class.\nYou should also have R and RStudio installed on your machine. If you do not have either, please follow these instructions."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Math 218: Spring 2023",
    "section": "Syllabus",
    "text": "Syllabus\nThe course syllabus can be found here. Please note that the once the semester begins, the schedule on the syllabus may not be up-to-date. Refer to the schedule page to see the current course schedule."
  },
  {
    "objectID": "slides/slides-01-what-is.html#what-is-statistical-learning",
    "href": "slides/slides-01-what-is.html#what-is-statistical-learning",
    "title": "What is statistical learning?",
    "section": "What is statistical learning?",
    "text": "What is statistical learning?\n\nSet of tools used to understand data\n\nSupervised and unsupervised methods\n\nUse data and build appropriate functions (models) to try and perform inference and make predictions\n\nData-centered approach\n\nCategories of statistical learning problems\n\nClassification\nLearning relationships\nPrediction"
  },
  {
    "objectID": "slides/slides-01-what-is.html#supervised-learning",
    "href": "slides/slides-01-what-is.html#supervised-learning",
    "title": "What is statistical learning?",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nNotation: let \\(i = 1,\\ldots, n\\) index the observation\nFor each observation \\(i\\), we have:\n\nResponse (outcome): \\(y_{i}\\)\nVector of \\(p\\) predictors (covariates): \\(\\mathbf{x}_{i} = (x_{i1}, x_{i2}, \\ldots, x_{ip})'\\)\n\nRegression: the \\(y_{i}\\) are quantitative (e.g. height, price)\nClassification: the \\(y_{i}\\) are categorical (e.g. education level, diagnosis)\nGoal: relate response \\(y_{i}\\) to the various predictors"
  },
  {
    "objectID": "slides/slides-01-what-is.html#objectives-in-supervised-learning",
    "href": "slides/slides-01-what-is.html#objectives-in-supervised-learning",
    "title": "What is statistical learning?",
    "section": "Objectives in Supervised Learning",
    "text": "Objectives in Supervised Learning\n\nExplanatory: understand which predictors affect the response, and how\nPrediction: accurately predict unobserved cases for new measurements of predictors\nAssessment: quantify the quality of our predictions and inference"
  },
  {
    "objectID": "slides/slides-01-what-is.html#lets-look-at-some-real-data",
    "href": "slides/slides-01-what-is.html#lets-look-at-some-real-data",
    "title": "What is statistical learning?",
    "section": "Let’s look at some real data!",
    "text": "Let’s look at some real data!\n\nOribatid mite data: abundance data of 35 oribatid mite species observed at 70 sampling locations irregularly spaced within a study area of 2.6 × 10 m collected on the territory of the Station de biologie des Laurentides of Université de Montréal, Québec, Canada in June 1989\nVariables measured at each location:\n\nSubstrate density (quantitative)\nWater content (quantitative)\nMicrotopography (binary categorical)\nShrub density (ordinal categorical, three levels)\nSubstrate type (nominal categorical, seven levels)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#sampling-map",
    "href": "slides/slides-01-what-is.html#sampling-map",
    "title": "What is statistical learning?",
    "section": "Sampling map",
    "text": "Sampling map"
  },
  {
    "objectID": "slides/slides-01-what-is.html#data",
    "href": "slides/slides-01-what-is.html#data",
    "title": "What is statistical learning?",
    "section": "Data",
    "text": "Data\n\n# from the vegan library\ndata(\"mite\")\ndata(\"mite.env\")\nnames(mite)\n\n [1] \"Brachy\"   \"PHTH\"     \"HPAV\"     \"RARD\"     \"SSTR\"     \"Protopl\" \n [7] \"MEGR\"     \"MPRO\"     \"TVIE\"     \"HMIN\"     \"HMIN2\"    \"NPRA\"    \n[13] \"TVEL\"     \"ONOV\"     \"SUCT\"     \"LCIL\"     \"Oribatl1\" \"Ceratoz1\"\n[19] \"PWIL\"     \"Galumna1\" \"Stgncrs2\" \"HRUF\"     \"Trhypch1\" \"PPEL\"    \n[25] \"NCOR\"     \"SLAT\"     \"FSET\"     \"Lepidzts\" \"Eupelops\" \"Miniglmn\"\n[31] \"LRUG\"     \"PLAG2\"    \"Ceratoz3\" \"Oppiminu\" \"Trimalc2\"\n\n# Focus on just the LRUG mite abundances\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)\nhead(mite_dat)\n\n  SubsDens WatrCont Substrate Shrub    Topo abundance\n1    39.18   350.15   Sphagn1   Few Hummock         0\n2    54.99   434.81    Litter   Few Hummock         0\n3    46.07   371.72 Interface   Few Hummock         0\n4    48.19   360.50   Sphagn1   Few Hummock         0\n5    23.55   204.13   Sphagn1   Few Hummock         0\n6    57.32   311.55   Sphagn1   Few Hummock         0"
  },
  {
    "objectID": "slides/slides-01-what-is.html#eda",
    "href": "slides/slides-01-what-is.html#eda",
    "title": "What is statistical learning?",
    "section": "EDA",
    "text": "EDA\n(scroll for more content)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#model-building",
    "href": "slides/slides-01-what-is.html#model-building",
    "title": "What is statistical learning?",
    "section": "Model building",
    "text": "Model building\n\nGoal: predict LRUG abundance using these variables\nMaybe LRUG \\(\\approx f(\\) SubsDens + WatrCont\\()\\)?\nIf so, how would we represent these variables using our notation? i.e., what are \\(y_{i}\\) and \\(x_{i}\\)?\nThen our model can be written as \\(y_{i} = f(x_{i}) + \\epsilon_{i}\\) where \\(\\epsilon_{i}\\) represents random measurement error\n\nWhat does this equation mean?"
  },
  {
    "objectID": "slides/slides-01-what-is.html#why-care-about-f",
    "href": "slides/slides-01-what-is.html#why-care-about-f",
    "title": "What is statistical learning?",
    "section": "Why care about f?",
    "text": "Why care about f?\n\nModel (dropping the indices): \\(Y = f(X) + \\epsilon\\)\nThe function \\(f(X)\\) represents the systematic information that \\(X\\) tells us about \\(Y\\).\nIf \\(f\\) is “good”, then we can make reliable predictions of \\(Y\\) at new points \\(X = x\\)\nIf \\(f\\) is “good”, then we can identify which components of \\(X\\) are important for explaining \\(Y\\)\n\nDepending on \\(f\\), we may be able to learn how each component of \\(X\\) affects \\(Y\\)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#why-care-about-f-1",
    "href": "slides/slides-01-what-is.html#why-care-about-f-1",
    "title": "What is statistical learning?",
    "section": "Why care about f?",
    "text": "Why care about f?\n\nWe assume that \\(f\\) is fixed but unknown\nGoal of statistical learning: how to obtain an estimate \\(\\hat{f}\\) of the true \\(f\\)?\n\nSub-goals: prediction and inference\n\nThe sub-goal may affect our choice of \\(\\hat{f}\\)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#prediction",
    "href": "slides/slides-01-what-is.html#prediction",
    "title": "What is statistical learning?",
    "section": "Prediction",
    "text": "Prediction\n\nWe have a set of inputs or predictors \\(x_{i}\\), and we want to predict a corresponding \\(y_{i}\\). Assume the true model is \\(y_{i} = f(x_{i}) + \\epsilon_{i}\\), but don’t know \\(f\\)\nAssuming the error \\(\\epsilon_{i}\\) is 0 on average, we can obtain predictions of \\(y_{i}\\) as \\[\\hat{y}_{i} = \\hat{f}(x_{i})\\]\n\nThen, if we know the true \\(y_{i}\\), we can evaluate the accuracy of the prediction \\(\\hat{y}_{i}\\)\n\nGenerally, \\(y_{i} \\neq \\hat{y}_{i}\\). Why?\n\n\\(\\hat{f}\\) will not be perfect estimate of \\(f\\)\n\\(y_{i}\\) is a function of \\(\\epsilon_{i}\\), which cannot be predicted using \\(x_{i}\\)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#types-of-error",
    "href": "slides/slides-01-what-is.html#types-of-error",
    "title": "What is statistical learning?",
    "section": "Types of error",
    "text": "Types of error\n\nModel: \\(y_{i} = f(x_{i}) + \\epsilon_{i}\\)\n\nIrreducible error: \\(\\epsilon_{i}\\)\n\n\nEven if we knew \\(f\\) perfectly, there is still some inherent variability\n\\(\\epsilon_{i}\\) may also contain unmeasured variables that are not available to us\n\n\nReducible error: how far \\(\\hat{f}\\) is from the true \\(f\\)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#prediction-errors",
    "href": "slides/slides-01-what-is.html#prediction-errors",
    "title": "What is statistical learning?",
    "section": "Prediction errors",
    "text": "Prediction errors\n\nWays to quantify error\n\nDifference/error = \\(y_{i} - \\hat{y}_{i}\\)\nAbsolute error = \\(|y_{i} - \\hat{y}_{i}|\\)\nSquared error = \\((y_{i} - \\hat{y}_{i})^2\\)\n\nIntuitively, larger error indicates worse prediction\nQuestion: are there scenarios where we might prefer one error over another?"
  },
  {
    "objectID": "slides/slides-01-what-is.html#prediction-errors-1",
    "href": "slides/slides-01-what-is.html#prediction-errors-1",
    "title": "What is statistical learning?",
    "section": "Prediction errors",
    "text": "Prediction errors\n\nGiven \\(\\hat{f}\\) and \\(x_{i}\\), we can obtain a prediction \\(\\hat{y}_{i} = \\hat{f}(x_{i})\\) for \\(y_{i}\\)\nMean-squared prediction error: \\[\\begin{align*}\n\\mathsf{E}[(y_{i} - \\hat{y}_{i})^2] &= \\mathsf{E}[( f(x_{i}) + \\epsilon_{i} - \\hat{f}(x_{i}))^2] \\\\\n&= \\underbrace{[f(x_{i}) - \\hat{f}(x_{i})]^2}_\\text{reducible} + \\underbrace{\\text{Var}(\\epsilon_{i})}_\\text{irreducible}\n\\end{align*}\\]\nWe cannot do much to decrease the irreducible error\nBut we can potentially minimize the reducible error by choosing better \\(\\hat{f}\\)!"
  },
  {
    "objectID": "slides/slides-01-what-is.html#inference",
    "href": "slides/slides-01-what-is.html#inference",
    "title": "What is statistical learning?",
    "section": "Inference",
    "text": "Inference\n\nWe are often interested in learning how \\(Y\\) and the \\(X_{1}, \\ldots, X_{p}\\) are related or associated\nIn this mindset, we want to estimate \\(f\\) to learn the relationships, rather than obtain a \\(\\hat{Y}\\)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#prediction-vs-inference",
    "href": "slides/slides-01-what-is.html#prediction-vs-inference",
    "title": "What is statistical learning?",
    "section": "Prediction vs Inference",
    "text": "Prediction vs Inference\n\nPrediction: estimate \\(\\hat{f}\\) for the purpose of \\(\\hat{Y}\\) and \\(Y\\).\nInference: estimate \\(\\hat{f}\\) for the purpose of \\(X\\) and \\(Y\\)\nSome problems will call for prediction, inference, or both\n\nTo what extent is LRUG abundance associated with microtopography?\nGiven a specific land profile, how many LRUG mites would we expect there to be?"
  },
  {
    "objectID": "slides/slides-01-what-is.html#assessing-model-accuracy",
    "href": "slides/slides-01-what-is.html#assessing-model-accuracy",
    "title": "What is statistical learning?",
    "section": "Assessing model accuracy",
    "text": "Assessing model accuracy\n\nNo single method or choice of \\(\\hat{f}\\) is superior over all possible data sets\nPrediction accuracy vs. interpretability\n\nMore restrictive models may be easier to interpret (better for inference)\nGood fit vs. over-fit (or under-fit)\n\nA simpler model is often preferred over a very complex one"
  },
  {
    "objectID": "slides/slides-01-what-is.html#assessing-model-accuracy-1",
    "href": "slides/slides-01-what-is.html#assessing-model-accuracy-1",
    "title": "What is statistical learning?",
    "section": "Assessing model accuracy",
    "text": "Assessing model accuracy\n\nHow can we know how well a chosen \\(\\hat{f}\\) is performing?\nIn regression setting, we often use mean squared error (MSE) or root MSE (RMSE)\n\n\\(\\text{MSE}=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{f}(x_{i}))^2\\)\n\\(\\text{RMSE}=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-\\hat{f}(x_{i}))^2}\\)\n\nMSE (and RMSE) will be small if predictions \\(\\hat{y}_{i} = \\hat{f}(x_{i})\\) are very close to true \\(y_{i}\\)\nQuestion: why might we prefer reporting RMSE over MSE?"
  },
  {
    "objectID": "slides/slides-01-what-is.html#training-vs.-test-data",
    "href": "slides/slides-01-what-is.html#training-vs.-test-data",
    "title": "What is statistical learning?",
    "section": "Training vs. test data",
    "text": "Training vs. test data\n\nIn practice, we split our data into training and test sets\n\nTraining set is used to fit the model\nTest set is used to assess model fit\n\nWe are often most interested in accuracy of our predictions when applying the method to previously unseen data. Why?\nWe can compute the MSE for the training and test data respectively…but we typically focus more attention to test MSE"
  },
  {
    "objectID": "slides/slides-01-what-is.html#example-1",
    "href": "slides/slides-01-what-is.html#example-1",
    "title": "What is statistical learning?",
    "section": "Example 1",
    "text": "Example 1\nI generated some fake data and fit three models that differ in flexibility. In this example, the generated data (points) follow a curve-y shape."
  },
  {
    "objectID": "slides/slides-01-what-is.html#example-2",
    "href": "slides/slides-01-what-is.html#example-2",
    "title": "What is statistical learning?",
    "section": "Example 2",
    "text": "Example 2\nIn this example, the generated data (points) look more linear."
  },
  {
    "objectID": "slides/slides-01-what-is.html#bias-variance-trade-off",
    "href": "slides/slides-01-what-is.html#bias-variance-trade-off",
    "title": "What is statistical learning?",
    "section": "Bias-Variance trade-off",
    "text": "Bias-Variance trade-off\n\nAs model flexibility increases, the training MSE will decrease but test MSE may not.\nFlexible models may overfit the data, which leads to low train MSE and high test MSE\n\nThe supposed patterns in train data do not exist in test data\n\nLet us consider a test observation \\((x_{0}, y_{0})\\).\nThe expected test MSE for given \\(x_{0}\\) can be decomposed as follows:\n\n\\(\\mathsf{E}[(y_{0} - \\hat{f}(x_{0}))^2] = \\text{Var}(\\hat{f}(x_{0})) + [\\text{Bias}(\\hat{f}(x_{0}))]^2 + \\text{Var}(\\epsilon)\\)\n\\(\\text{Bias}(\\hat{f}(x_{0})) = \\mathsf{E}[\\hat{f}(x_{0})] - \\hat{f}(x_{0})\\)"
  },
  {
    "objectID": "slides/slides-01-what-is.html#bias-variance-trade-off-cont.",
    "href": "slides/slides-01-what-is.html#bias-variance-trade-off-cont.",
    "title": "What is statistical learning?",
    "section": "Bias-Variance trade-off (cont.)",
    "text": "Bias-Variance trade-off (cont.)"
  },
  {
    "objectID": "slides/slides-00-welcome.html#about-me",
    "href": "slides/slides-00-welcome.html#about-me",
    "title": "Welcome to statistical learning!",
    "section": "About me",
    "text": "About me\n\nPhD in Statistical Science from Duke University, BA in Mathematics and Computer Science from Swarthmore College\nResearch interests: Bayesian hierarchical models for ecological applications\n\nDeveloping models for single species or community abundances\n\nOffice: Warner 214\n\nIf my door is open, come on in! Also feel free to e-mail me.\nOffice hours: Tuesdays 3-4pm and by appointment via Calendly\n\nCurrent hobbies: running, mushroom foraging\nAspirational hobbies/skills: fly fishing, driving stick shift"
  },
  {
    "objectID": "slides/slides-00-welcome.html#about-you",
    "href": "slides/slides-00-welcome.html#about-you",
    "title": "Welcome to statistical learning!",
    "section": "About you",
    "text": "About you\n\nIntroduce yourself using any or all of the following (the first is mandatory):\n\nName\nYear\nMajor/minor\nHobbies\nHow do you take your coffee?"
  },
  {
    "objectID": "slides/slides-00-welcome.html#about-the-course",
    "href": "slides/slides-00-welcome.html#about-the-course",
    "title": "Welcome to statistical learning!",
    "section": "About the course",
    "text": "About the course\n\nCourse website: https://math218-spring2023.github.io/ (please bookmark!)\nLearn various models for regression and classification tasks (more on this next lecture)\n\nLinear and logistic regression, KNN, decision trees + variants, K-means and hierarchical clustering"
  },
  {
    "objectID": "slides/slides-00-welcome.html#necessary-background",
    "href": "slides/slides-00-welcome.html#necessary-background",
    "title": "Welcome to statistical learning!",
    "section": "Necessary background",
    "text": "Necessary background\n\n\n\n\nI assume you have taken Math 118 prior to this course, and are comfortable with tidyverse and RStudio. There is a large emphasis on computing.\n\nI also assume you are comfortable with knitting. In this course, I ask that you knit to PDF.\n\nWe will learn how to code in base R, and by the end of the course you should feel comfortable switching between base R and tidyverse.\nWe will focus more on applications and developing intuition. The goal is to begin developing a toolbox of methods that you may use in future analyses."
  },
  {
    "objectID": "slides/slides-00-welcome.html#class-meetings",
    "href": "slides/slides-00-welcome.html#class-meetings",
    "title": "Welcome to statistical learning!",
    "section": "Class Meetings",
    "text": "Class Meetings\n\n\nLecture\n\nFocus on concepts behind statistical learning techniques\nInteractive lecture that includes examples and hands-on exercises\nBring fully-charged laptop to every lecture\n\nPlease let me know if you do not have access to a laptop\n\n\nLab\n\nTypically occurs on Fridays\nFocus on computing using functions provided in R packages\nApply concepts from lecture to case study scenarios\n\nImplementation\n\nSome days will be focused on implementing (i.e. coding by hand) methods discussed in lecture\nComplete in small groups"
  },
  {
    "objectID": "slides/slides-00-welcome.html#major-assessments",
    "href": "slides/slides-00-welcome.html#major-assessments",
    "title": "Welcome to statistical learning!",
    "section": "Major assessments",
    "text": "Major assessments\n\n\nOne midterm with two components:\n\nComputational component (take-home)\nOral component\n\nFinal project\n\nGroups of 3-4 students (tentatively)\nPresentations during last two days of class*\nNO sit-down final"
  },
  {
    "objectID": "slides/slides-00-welcome.html#grading",
    "href": "slides/slides-00-welcome.html#grading",
    "title": "Welcome to statistical learning!",
    "section": "Grading",
    "text": "Grading\nAssignments\n\nLabs (30%)\nImplementation deliverables (20%)\nMidterm (20%)\nFinal project (25%)\nParticipation (5%)"
  },
  {
    "objectID": "slides/slides-00-welcome.html#important-dates",
    "href": "slides/slides-00-welcome.html#important-dates",
    "title": "Welcome to statistical learning!",
    "section": "Important dates",
    "text": "Important dates\n\nFriday, 3/31: take-home midterm\nMonday, 4/3: oral midterm\n\nFriday, 4/14: Spring symposium (no class)\n\nMonday, 4/17: final day to drop classes :(\n\nFriday, 5/13 and Monday, 5/15*: project presentations"
  },
  {
    "objectID": "slides/slides-00-welcome.html#excused-absences",
    "href": "slides/slides-00-welcome.html#excused-absences",
    "title": "Welcome to statistical learning!",
    "section": "Excused Absences",
    "text": "Excused Absences\n\nStudents who miss a class due to a scheduled varsity trip, religious holiday, or short-term illness should fill out the respective form.\n\nThese excused absences do not excuse you from assigned work.\n\nIf you have a personal or family emergency or chronic health condition that affects your ability to participate in class, please contact your academic dean’s office.\nExam dates cannot be changed and no make-up exams will be given."
  },
  {
    "objectID": "slides/slides-00-welcome.html#late-work-and-regrade-requests",
    "href": "slides/slides-00-welcome.html#late-work-and-regrade-requests",
    "title": "Welcome to statistical learning!",
    "section": "Late Work and Regrade Requests",
    "text": "Late Work and Regrade Requests\n\nHomework assignments:\n\nAfter the assigned deadline, there is a 10% penalty for each day the assignment is late\nPlease communicate with me early if you will need a homework extension!\n\nLate work will not be accepted for the midterm or final project.\nRegrade requests must be submitted within one week of when the assignment is returned"
  },
  {
    "objectID": "slides/slides-00-welcome.html#academic-honesty-and-reusing-code",
    "href": "slides/slides-00-welcome.html#academic-honesty-and-reusing-code",
    "title": "Welcome to statistical learning!",
    "section": "Academic Honesty and Reusing Code",
    "text": "Academic Honesty and Reusing Code\n\nAll work for this class should be done in accordance with the Middlebury Honor code. Any violations will automatically result in a grade of 0 on the assignment and will be reported.\nUnless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must or explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nOn individual assignments, you may discuss the assignment with one another; however, you may not directly share code or write up with other students. This includes copy-and-paste sharing, as well as showing your screen with the code displayed to another student.\nOn team assignments, you may not directly share code or write up with another team. Unauthorized sharing of the code or write up will be considered a violation for all students involved.\nChatGPT most likely will not be useful in this class. However, if you use it on an assignment, please let me know in what capacity you used it by including a comment in your assignment."
  },
  {
    "objectID": "slides/slides-00-welcome.html#inclusion",
    "href": "slides/slides-00-welcome.html#inclusion",
    "title": "Welcome to statistical learning!",
    "section": "Inclusion",
    "text": "Inclusion\n\nIn this course, we will strive to create a learning environment that is welcoming to all students. If there is any aspect of the class that is not welcoming or accessible to you, please let me know immediately.\nAdditionally, if you are experiencing something outside of class that is affecting your performance in the course, please feel free to talk with me and/or your academic dean."
  },
  {
    "objectID": "slides/slides-00-welcome.html#create-a-github-account",
    "href": "slides/slides-00-welcome.html#create-a-github-account",
    "title": "Welcome to statistical learning!",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\n\nGo to https://github.com, and create an account (unless you already have one). After you create your account, click here and enter your GitHub username.\n\nTips for creating a username from Happy Git with R.\n\nIncorporate your actual name!\nReuse your username from other contexts if you can.\nShorter is better than longer; be as unique as possible in as few characters as possible.\nAvoid words laden with special meaning in programming, like NA."
  },
  {
    "objectID": "slides/slides-00-welcome.html#coding-exercise",
    "href": "slides/slides-00-welcome.html#coding-exercise",
    "title": "Welcome to statistical learning!",
    "section": "“Coding” exercise",
    "text": "“Coding” exercise\nLet’s create the following plot together:"
  },
  {
    "objectID": "slides/slides-00-welcome.html#data",
    "href": "slides/slides-00-welcome.html#data",
    "title": "Welcome to statistical learning!",
    "section": "Data",
    "text": "Data\n\ncat_lovers %>%\n  datatable(options = list(pageLength = 5))"
  },
  {
    "objectID": "slides/slides-00-welcome.html#playing-with-base-r",
    "href": "slides/slides-00-welcome.html#playing-with-base-r",
    "title": "Welcome to statistical learning!",
    "section": "Playing with base R",
    "text": "Playing with base R\n\nCreate a folder on your desktop called Math218\nOpen RStudio and create a new Rmarkdown document.\n\nWe will work through some coding exercises. The associated code can be found in “Live Code 01”"
  },
  {
    "objectID": "slides/slides-00-installation.html#version-control",
    "href": "slides/slides-00-installation.html#version-control",
    "title": "Installation",
    "section": "Version control",
    "text": "Version control\n\nGit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your Git-based projects on the internet (like DropBox but much better).\nThere are a lot of Git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be using the GitHub Desktop application to perform the Git commands in a beginner-friendly way. Our local project in RStudio will be sent to GitHub using the application."
  },
  {
    "objectID": "slides/slides-00-installation.html#download-instructions",
    "href": "slides/slides-00-installation.html#download-instructions",
    "title": "Installation",
    "section": "Download Instructions",
    "text": "Download Instructions\n\nAccept the e-mailed GitHub invitation to join our course organization. If you did not receive an invitation, that means I do not have your GitHub username!\nGo to https://desktop.github.com/ and download the GitHub Desktop application. Mac users: check if you need to download for Apple silicon Mac.\nA zipped file will appear in your Downloads folder. Please unzip the file.\nA purple GitHub Desktop icon with the octocat icon will appear. I suggest dragging this to your dock.\n\n\n\nOpen GitHub Desktop. At some point, you might get the following pop-up:\n\n\nIf so, check the box and choose the white “Not Now” button"
  },
  {
    "objectID": "slides/slides-00-installation.html#syncing-your-github-account",
    "href": "slides/slides-00-installation.html#syncing-your-github-account",
    "title": "Installation",
    "section": "Syncing your GitHub Account",
    "text": "Syncing your GitHub Account\n\nNow we need to sync your GitHub Desktop application with your GitHub account\n\nMac users: GitHub Desktop -> Preference -> Accounts -> Sign-in\nWindows users: File -> Options -> Accounts -> Sign-in\n\nYou will be directed to github.com to sign-in. Enter your account information. Once authenticated, your GitHub Desktop client should be set up!"
  },
  {
    "objectID": "slides/slides-00-installation.html#cloning-a-github-repo",
    "href": "slides/slides-00-installation.html#cloning-a-github-repo",
    "title": "Installation",
    "section": "Cloning a GitHub repo",
    "text": "Cloning a GitHub repo\n\nIn this course, I will create your GitHub repositories (i.e. projects) for you. I have a master repo, and I distribute copies to each one of you that only you (and in the future, your group members) can access\nGo to the course organization on GitHub (either via github.com or by clicking on the octocat on the course website)\nFind the repo with the prefix lab-01-roulette-"
  },
  {
    "objectID": "slides/slides-00-installation.html#cloning-a-github-repo-cont.",
    "href": "slides/slides-00-installation.html#cloning-a-github-repo-cont.",
    "title": "Installation",
    "section": "Cloning a GitHub repo (cont.)",
    "text": "Cloning a GitHub repo (cont.)\n\nClick on the green Code button, and select the option Open with GitHub Desktop\n\nThe GitHub Desktop application will open up, with a white window that says “Clone a Repository”. Important: in the second line that says “Local Path”, there is a button that says Choose… Click on it, and select the Math 218 folder you created from this course. Then hit the blue Clone button."
  },
  {
    "objectID": "slides/slides-00-installation.html#committing-and-pushing-changes",
    "href": "slides/slides-00-installation.html#committing-and-pushing-changes",
    "title": "Installation",
    "section": "Committing and pushing changes",
    "text": "Committing and pushing changes\n\nWhen you work on a project locally (i.e. on your own machine), you will want to periodically “back-up” your changes in case something terrible happens to your laptop, or you need to share your progress with a team member\nThe process is done in stages:\n\nAdding your changes,\nCommiting your changes, and\nPushing your changes\n\nGitHub Desktop automatically does the add step for you, but you need to explicitly commit and push!"
  },
  {
    "objectID": "slides/slides-00-installation.html#practice",
    "href": "slides/slides-00-installation.html#practice",
    "title": "Installation",
    "section": "Practice",
    "text": "Practice\n\nOpen up the lab-01-roulette.Rmd file, and edit your name in the author section of the YAML, then knit the document.\n\n\n\nOpen GitHub Desktop and make sure the Current Repository is the project of interest.\n\nOn the left-hand side, you should see files you either edited or created, with a checked blue box. This is correct – GitHub Desktop has automatically done the add step for you.\n\nCommit: on the bottom left:\n\nType a brief comment in the small text-box next to your GitHub profile photo/graphic.\nPush the blue Commit to main button.\n\nPush: on the top right:\n\nThere should be a tab that says Push origin with an upward arrow with a number next to it. That means you are ready! Click the button to push your changes to origin.\nYou will know the push was successful if this tab returns to say Fetch origin"
  },
  {
    "objectID": "slides/slides-00-installation.html#checking-your-changes",
    "href": "slides/slides-00-installation.html#checking-your-changes",
    "title": "Installation",
    "section": "Checking your changes",
    "text": "Checking your changes\n\nGo to the corresponding repository on github.com\nCheck to see if the current version of lab-01-roulette.Rmd file has your updated author name. If it doesn’t, that means the push was not successful."
  },
  {
    "objectID": "live-code/live-code-01.html",
    "href": "live-code/live-code-01.html",
    "title": "Live code 01:",
    "section": "",
    "text": "This lab is intended to re-familiarize yourself with R and RStudio, as well as begin practicing to code in base R. You will need the tidyverse package."
  },
  {
    "objectID": "live-code/live-code-01.html#vectors",
    "href": "live-code/live-code-01.html#vectors",
    "title": "Live code 01:",
    "section": "Vectors",
    "text": "Vectors\nIn R, a vector is a data structure that holds or stores elements of the same type. Type may be numeric, integer, character, boolean, etc.\n\nThe c() function\nGenerally, we create vectors using the c() function and then save the vector into a variable. In the code below, I create a vector of three values (10, 11, and 12), and save the results into v:\n\nv <- c(10, 11, 12)\n\n\n\nThe : operator\nNow, sometimes it’s really useful to create a vector of consecutive numbers, for example, the values 1 through 10. Rather than type out every number explicitly and wrap it in c() , I can use the : operator, which looks like a:b where a and b are integers of your choosing. If a < b, R will then create a vector of numbers a, a+1, a+2,…, b-1, b .\n\nx <- 1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWhat do you think happens if a > b? Try the following code for yourself:\n\ny <- 10:1\n\n\n\nThe rep() function\nOne function that I personally use a lot to create vectors is the rep(a,b) function, which takes in two argument. The first is the value a you wish to repeat, and the second argument is the number of times b you’d like to repeat it. How would we create a vector of 20 0’s? Think about it, and check:\n\n\nCode\nrep(0, 20)"
  },
  {
    "objectID": "live-code/live-code-01.html#matrices",
    "href": "live-code/live-code-01.html#matrices",
    "title": "Live code 01:",
    "section": "Matrices",
    "text": "Matrices\nMatrices are the 2D extension of the one-dimensional vectors. When a matrix has n rows and p columns, we denote its dimensions as n x p or “n by p”. We create matrices using the matrix() function. Because of the multiple dimensions, we need to specify the number of rows and the number of columns:\n\nmatrix(NA, nrow = 2, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]   NA   NA   NA\n[2,]   NA   NA   NA\n\n\nThis code above creates a 2 x 3 matrix of NA values. The first argument takes in the elements you want to fill the matrix with. This can either be a single value, or a single vector of values."
  },
  {
    "objectID": "live-code/live-code-01.html#data-frames",
    "href": "live-code/live-code-01.html#data-frames",
    "title": "Live code 01:",
    "section": "Data frames",
    "text": "Data frames\nWe will create a data frame called my_df here, which holds the two vectors we created before.\n\nmy_df <- data.frame(xvar = x, yvar = y)\n\nNow, if I wanted to only take the variable xvar from my_df, how would I do so using dplyr functions? Take a second to think about it, then check:\n\n\nCode\nmy_df %>%\n  select(xvar)\n\n\nWe will now use base R to access that xvar variable by using $ notation: <df>$<var_name> . If you do this yourself, you should notice that immediately after typing the $ , a menu pops up with all the variables contained in the data frame.\n\nmy_df$xvar\n\nNow, do you notice the difference between the two outputs?\n\nmy_df %>%\n  select(xvar)\n\n   xvar\n1     1\n2     2\n3     3\n4     4\n5     5\n6     6\n7     7\n8     8\n9     9\n10   10\n\nmy_df$xvar\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "live-code/live-code-01.html#indexing",
    "href": "live-code/live-code-01.html#indexing",
    "title": "Live code 01:",
    "section": "Indexing",
    "text": "Indexing\nOne of the most useful tools we will use is indexing and index notation.\nAn index is essentially a numerical representation of an item’s position in a list or vector. It is typically an integer, starting from either 0 or 1 depending on the programming language. In R, our index positions always start at 1!\nFor example, in the word “learning”, the l is at index 1. Similarly, in our vector v of the numbers \\((10, 11, 12)\\), the value at index 1 is 10. We can confirm this with code:\n\nv[1]\n\n[1] 10\n\n\nNotice that we access the item held in index 1 using the square bracket notation [ ]\nNow, I can also replace or modify an element at a given index. I will still access the location using [ ], but now I will store/save the new value:\n\nv[1] <- 13\nv\n\n[1] 13 11 12\n\n\nWe can also modify multiple elements at once by passing in a vector of indices to modify, as well as a vector of new values:\n\nv[2:3] <- c(14, 15)\n\nWhat does v look like now?\nWe can also use indices to refer to elements or entire rows and columns of data frames! Unlike vectors, data frame are two-dimensional, i.e. there are both rows and columns. Thus, our index notation will need to adapt to accommodate this feature. We will still use [ ] notation, but now commas will be introduced:\n\nmy_df[1,2]\n\n[1] 10\n\n\nBased on my_df, what do you think the [1,2] means?\nNow, we already saw how to access a column of a data frame using the $ notation, but we can also use index notation. To access the first column, we would type:\n\nmy_df[,1]\n\nThe 1 after the comma tells R that we want to focus on column 1.\nAs I do not type anything before the comma, R reads this as: “since you did not want a specific row, you must want all the rows”.\nHow do you think we would access the third column? How about both the first and second row?"
  },
  {
    "objectID": "live-code/live-code-01.html#functions",
    "href": "live-code/live-code-01.html#functions",
    "title": "Live code 01:",
    "section": "Functions",
    "text": "Functions\nThere are a lot of simple functions in R that we will rely on. We already saw c() and rep(). Most of the functions we will use take in a vector or matrix of numeric values, and return either a single number or vector in return.\nThe function mean() takes in a vector, and returns the mean of the vector.\n\nmean(x)\n\n[1] 5.5\n\n\nThe function length() takes in a vector, and returns the number of elements in the vector:\n\nlength(x)\n\n[1] 10\n\n\nThe functions max() and min() return what you would expect them to!\nAn extremely useful function we will use is the which() function. Unlike the previous functions, which() does not take in a numeric vector. Rather, it takes a vector of boolean values (i.e. TRUE/FALSE values). Then, it returns the indices of the TRUE values in the vector. For example, an input might be:\n\ny == -5\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nThis is comparing each value in y to see if it equals -5 (recall the double equals sign check for equality). Notice that only one value evaluates to TRUE, specifically the element in index 6. Therefore, if we wrap the which() function around that argument, we should get 6 in return:\n\nwhich(y == -5)\n\ninteger(0)\n\n\nPersonally, I tend to read this line of code as a question: Which element(s) of y are exactly equal to -5?\nWe know that y only holds negative values. What do you think happens if we try to evaluate the following. Try it yourself!\n\nwhich(y == 0)\n\nIt’s also entirely possible that many values in the boolean vector are true, in which case the function would return multiple indices. For example, if I want to know which values in y are negative, I could code:\n\nwhich(y < 0)\n\ninteger(0)\n\n\n\nIndexing with boolean vectors\nAbove, we saw how to access elements held at specific indices of interest. We can also use boolean vectors to return values. Recall our vector v:\n\nv\n\n[1] 13 14 15\n\n\nI can index v by indexing using TRUE’s for each value that I want, and FALSE’s otherwise.\n\nv[c(F, T, F)]\n\n[1] 14"
  },
  {
    "objectID": "live-code/live-code-01.html#your-turn",
    "href": "live-code/live-code-01.html#your-turn",
    "title": "Live code 01:",
    "section": "Your turn!",
    "text": "Your turn!\nPlease complete the following exercises in order:\n\nCreate a vector called my_vec that holds the values 50 through 100.\nCreate a new vector called less60 where an element is TRUE if the corresponding element in my_vec is less than 60, and FALSE otherwise.\nConfirm that the length of your two vectors are the same.\nPass less60 into the function sum() function. Relate the value obtained to the elements of less60.\nModify my_vec such that the value at index 10 is 100.\nObtain the index of the maximum values of my_vec using functions described above.\nNow, pass my_vec into the which.max() function. Even though we haven’t seen it before, based on the function name, the name of the function is intuitive. Does the result from which.max() differ from what you obtained in Ex. 6? How so?\nCreate a 2 x 5 matrix of the values 1 through 10, where the first row holds the values 1-5, and the second row holds the values 6-10. Hint: look at the help file for matrix."
  },
  {
    "objectID": "live-code/live-code-02.html",
    "href": "live-code/live-code-02.html",
    "title": "Live code 02",
    "section": "",
    "text": "We will continue working in base R, and begin learning about conditional statements and for loops!"
  },
  {
    "objectID": "live-code/live-code-02.html#new-function",
    "href": "live-code/live-code-02.html#new-function",
    "title": "Live code 02",
    "section": "New function:",
    "text": "New function:\n\nThe sample(vec, m) function takes a random sample of size m from the vector vec . By default, we sample without replacement and each value in vec is equally likely. For example, I can draw one value between 1-5 at random (where each value as 1/5 chance of being sampled) as follows:\n\nsample(1:5, 1)\n\n[1] 1\n\nsample(1:5, 1)\n\n[1] 1\n\nsample(1:5, 1)\n\n[1] 3\n\n\n\nAs you see, running this code multiple times will lead to different values being sample-d!\nYou can sample with replacement or sample each value in vec with different probability by changing the arguments in the function call."
  },
  {
    "objectID": "live-code/live-code-02.html#conditional-statements",
    "href": "live-code/live-code-02.html#conditional-statements",
    "title": "Live code 02",
    "section": "Conditional statements",
    "text": "Conditional statements\nThus far, we have learned how to store values and relate different R objects. For example, we can obtain a boolean TRUE or FALSE value when we compare two objects as follows:\n\nx <- 3\nx <= 5\n\n[1] TRUE\n\n\nMost often, we want to use the results from these logical operators to change the behavior of our code. That is, if a certain condition is satisfied, we want our code to do something. Else, our code should do something else.\n\nif statements\nThe if statement takes in a condition. If the condition evaluates to TRUE, then the R code we associate with the if statement is executed. The syntax is as follows:\n\nif (condition){\n  code\n}\n\nNotice that the condition goes in parentheses ( ), and the relevant code goes within curly braces { }.\nFor example:\n\nif (x < 5){\n  print(\"x is less than 5\")\n}\n\nTry this yourself! Set x to be a number, then run this code. If you chose x to be greater than or equal to 5, then the condition evaluates to FALSE and so we do not run the code within the curly braces and nothing is printed.\n\n\nelse statements\nNow, maybe we want to a different block of code to run if the condition evaluates to FALSE. This is where the else statement comes in! Importantly, else statements always follows an if statement so there is no need to supply a conditional statement. The syntax is as follows:\n\nif (condition){\n  code associated with TRUE condition\n} else{\n  code associated with FALSE condition\n}\n\nTry modifying the if statement above to have a corresponding block of code that corrently prints when x is greater than or equal to 5."
  },
  {
    "objectID": "live-code/live-code-02.html#for-loops",
    "href": "live-code/live-code-02.html#for-loops",
    "title": "Live code 02",
    "section": "for loops",
    "text": "for loops\nIt is quite simple to perform repetitive tasks in R. If we want to execute the same operations over and over again, we will use a loop. If we want to repeat the operations for a specific number of times, we use a for loop.\nLet’s look at this code:\n\nfor(i in 1:5){\n  print(i)\n}\n\nThe for() code is telling R that we want to run a for loop, which means we want to repeat the code within the curly braces. How many times do we want to repeat? The code says we want to do this for every value in 1:5.\nThe confusing part is the index i, which is essentially a placeholder. Instead of i, we could use any character we’d like! However, people tend to use i for “iteration”. At the beginning, i is set to the first value in the vector 1:5, (i.e. i = 1 to begin with). All the code within the braces are executed with i = 1 being the state of the world. Once we reach the end of the code within the braces, we go back to the top and set i = 2. We continue to do this until the last value in 1:5, which would be 5.\n\nfor(i in 1:5){\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "live-code/live-code-02.html#your-turn",
    "href": "live-code/live-code-02.html#your-turn",
    "title": "Live code 02",
    "section": "Your turn!",
    "text": "Your turn!\n\nWrite code that outputs the square root of a number. If the number is negative, then print out an informative statement instead. Note: the square root of a number can be obtained via the sqrt() function.\nWrite a for loop that calculates the factorial of a whole number of your choice. As a quick refresher, 5! (which we read as “5 factorial”) is equal to 5 x 4 x 3 x 2 x 1.\nObtain a vector y of 5 values by using the sample function, where the possible values to sample from are integers ranging between 1 and 5. Here, I want you to sample with replacement. Write a for loop that loops for 5 iterations and print the number of elements in y equal to the current iteration. If the current iteration value is not contained in y, please print out a useful statement for the user instead."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Unless otherwise stated, please submit assignments as a PDF to Canvas.\nNote: course schedule is subject to change.\n\n\n\n\nDate\nDescription\nClass materials\nAssignments\nDue date\n\n\n\n\n\n\n\nWEEK 1\n\n\n\n\n\nT 02/14\nWelcome!\nClass introduction, intro to base R\n\n\n\n\nR 02/16\nWhat is statistical learning?\nWhat is statistical learning?\n\n\n\n\nF 02/17\nLab day\nMore R coding, GitHub Desktop installation\nLab 01: Roulette\n02/23 at 11:59pm\n\n\n\n\n\nWEEK 2\n\n\n\n\n\nT 02/21\nWhat is statistical learning? (cont.)\nWhat is statistical learning?\n\n\n\n\nR 02/23\nLinear regression\nSlides: Linear regression\nLive code\n\n\n\n\nF 02/24\nLinear regression (cont.)\nLab day\n\nLab 02: Moneyball\n03/02 at 11:59pm\n\n\n\n\n\nWEEK 3\n\n\n\n\n\nT 02/28\nKNN regression\nSlides: KNN regression\nKNN pseudocode\n03/02 in class\n\n\nR 03/02\nKNN regression: implementation\nLive code: Writing functions\nKNN group pseudocode (steps 1-2)\n03/03 in class\n\n\nF 03/03\nKNN: implementation\n\nKNN group implementation (step 3)\n03/06 11:59pm\n\n\n\n\n\nWEEK 4\n\n\n\n\n\nT 03/07\nKNN regression (pt. 2)\nSlides\nLive code: encoding\nKNN regression: categorical features\n03/09 11:59pm\n\n\nR 03/09\nValidation\nSlides\nLive code: LOOCV\n\n\n\n\nF 3/10\nLab 03: Validation\nLive code: lists\nLab 03: ski resorts\n03/16 11:59pm\n\n\n\n\n\nWEEK 5\n\n\n\n\n\nT 03/14\nRegression trees (part 1)\nSlides\nLive code: binary recursive split\n\n\n\n\nR 03/16\nRegression trees (part 2)\nSlides\nLive code: pruning\n\n\n\n\nF 03/17\nNO CLASS\nWork on Lab 04!\nLab 04: forest fires\n03/30 11:59pm\n\n\n\n\n\nSPRING BREAK\n\n\n\n\n\n\n\n\nWEEK 6\n\n\n\n\n\nT 03/28\nIntroduce midterm\nBootstrap\nSlides\nBootstrap implementation\n03/29 11:59pm\n\n\nR 03/30\nProject introduction\nBagging\nProject description\nSlides\nBagging implementation\nLive code from class\nUngraded\n\n\nF 03/31\nBagging (cont.) + Random forests\nSlides\nLive code: randomForest\nMidterm: computational assignment\n04/02 11:59pm\n\n\n\n\n\nWEEK 7\n\n\n\n\n\nT 04/04\nBayes classifier + Logistic regression\nSlides\nLive code: fitting logistic regression\nPlease e-mail about project partners!\n\n\n\nR 04/06\nModel Assessment + KNN classification\nSlides\nLive code: fitting logistic regression\nPlease e-mail about project partners!\n\n\n\nF 04/07\nKNN implementation\n\nKNN classification implementation\n04/11 11:59pm\n\n\nSa 04/08\nProject\nLast day to pick group\n\n\n\n\n\n\n\nWEEK 8\n\n\n\n\n\nT 04/11\nImbalanced data + Validation\nLive code\n\n\n\n\nR 04/13\nProject\nSlides + instructions for merge conflict activity\nProject proposal\nLab 05: Wagga Wagga rain\n04/20 11:59pm\n\n\nF 04/14\nNO CLASS\nSpring symposium\n\n\n\n\n\n\n\nWEEK 9\n\n\n\n\n\nT 04/18\nClassification trees\nSlides\nWorksheet building trees\n\n\n\n\nR 04/20\nClassification tree (cont.)\nSlides\nLive code\n\n\n\n\nF 04/21\nImplementation\n\nBagged classification trees\n04/27 11:59pm\n\n\nSu 04/23\nProject\n\nProposal due\nTonight 11:59pm\n\n\n\n\n\nWEEK 10\n\n\n\n\n\nT 04/25\nProject\n\nProject plan\n04/30 at 11:59pm\n\n\nR 04/27\nK-means clustering\nSlides\n\n\n\n\nF 04/28\nK-means clustering (cont.)\nSlides (cont.)\nLive code\n\n\n\n\nSu 04/30\n\n\nPlans due\nTonight 11:59pm\n\n\n\n\n\nWEEK 11\n\n\n\n\n\nT 05/02\nProject\n\n\n\n\n\nR 05/04\nHierarchical clustering\nSlides\nLive code\nK-means implementation\n05/15 11:59pm\n\n\nF 05/05\nClustering (cont.)\n\n\n\n\n\nSu 05/07\nProject\n\nDraft due!\n11:59pm\n\n\n\n\n\nWEEK 12\n\n\n\n\n\nT 05/09\nProject\nPeer review for drafts\n\n\n\n\nR 05/11\nProject\n\nReport + Repo + Slides\nTonight 11:59pm\n\n\nF 05/12\n\n\nProject presentations!"
  },
  {
    "objectID": "live-code/live-code-03.html",
    "href": "live-code/live-code-03.html",
    "title": "Live code 03:",
    "section": "",
    "text": "Here we will learn how to write functions in R. Functions are extremely helpful for automating commons tasks that you might use often (e.g. computing the RMSE for a set of predictions). If you’re going to use the same block of code more than twice, you should consider writing a function!\nThere are three key steps to creating a new function:\n\nPicking a NAME for the function\nListing the INPUTS/ARGUMENTS to the function called function()\nPlacing the code you have developed in the BODY of the function (between the sets of curly braces { } that immediately follow function()\n\nMaking sure to return() the output from the function\n\n\n\n\nFor example, suppose that I want to create a function that takes in a matrix and returns the sums of the values within each column. (There is a function that already does this, but pretend there isn’t!) The function might look like this:\n\ncolumn_sums <- function(input_matrix){\n  n_cols <- ncol(input_matrix)\n  sums <- rep(NA, n_cols)\n  for(i in 1:n_cols){\n    sums[i] <- sum(input_matrix[,i])\n  }\n  return(sums)\n}\n\nThis looks scary, but let’s break it down.\n\nThe name of the function is column_sums.\nR knows I want to create a function because I use the function() function, where I specify that my function requires a single input that will be referred to as input_matrix.\nThe code within the body specifies how I will use input_matrix to calculate the column sums.\nI finish the function by return()-ing a vector.\n\nLet’s test this out: I will create a matrix of numbers, and then use/call my function as I normally would any R function:\n\nmy_mat <- matrix(1:10, nrow = 2, ncol = 5)\nmy_mat\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10\n\ncolumn_sums(my_mat)\n\n[1]  3  7 11 15 19\n\n\nLet’s confirm this is the correct output with the pre-provided R function colSums():\n\ncolSums(my_mat)\n\n[1]  3  7 11 15 19\n\n\nHow might we code a function that calculates the squared error between two values? Try it yourself, then check here to see if your code generally agrees with mine:\n\n\nCode\nsquared_error <- function(x1, x2){\n  ret <- (x1 - x2)^2\n  return(ret)\n}\n\n\n\n\nCode\n# test your code: you should get 16 for passing in -2 and 2\nsquared_error(-2, 2)"
  },
  {
    "objectID": "live-code/live-code-03.html#your-turn",
    "href": "live-code/live-code-03.html#your-turn",
    "title": "Live code 03:",
    "section": "Your turn!",
    "text": "Your turn!\nFeel free to try any and all of the following:\n\nWrite a function that takes in a temperature in degrees Fahrenheit and returns the temperature in degrees Celsius. For reference, the conversion is \\((\\text{degreesF} - 32) * \\frac{5}{9}\\). Give your function an appropriate name.\n\nCheck to make sure your function works by passing in \\(32^\\circ\\) F. You should get 0 back!\n\nWrite a more complicated version of Exercise 1 where the function takes in two inputs: 1) a temperature (in either Fahrenheit or Celsius) and 2) a string or Boolean (your choice!) that denotes if you want to convert to Fahrenheit or Celsius. Your function should return the correct conversion based on the user’s inputs. Note: the conversion from Celsius to Fahrenheit is \\(\\text{degreesC} * \\frac{9}{5} + 32\\).\nWrit a function called get_rmse() that takes in two vectors as inputs: one of predictions, and one of true values. Your function should calculate and return the root mean squared error (see slides for equation).\nLast week we practiced coding for() loops by obtaining the factorial of a given positive integer. Create a function where the user specifies the integer they want to find the factorial of, and return the factorial."
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#linear-regression-1",
    "href": "slides/slides-02-linear-regression.html#linear-regression-1",
    "title": "Linear Regression",
    "section": "Linear regression",
    "text": "Linear regression\n\nA simple, widely used approach in supervised learning\nAssumes that the dependence of \\(Y\\) on the predictors \\(X_{1}, \\ldots, X_{p}\\) is linear"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#possible-questions-of-interest",
    "href": "slides/slides-02-linear-regression.html#possible-questions-of-interest",
    "title": "Linear Regression",
    "section": "Possible questions of interest",
    "text": "Possible questions of interest\n\nIs there a relationship between the abundance of LRUG mites and substrate density or water content in the soil where they are found?\n\nIf so, how are strong are these relationships?\n\nIs the relationship linear?\nHow accurately can we predict the abundance of these mites?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#simple-linear-regression-1",
    "href": "slides/slides-02-linear-regression.html#simple-linear-regression-1",
    "title": "Linear Regression",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\n\nSimple linear regression (SLR)\n\n\nAssumes a linear model for a quantitative response \\(Y\\) using a single predictor \\(X\\)\n\\[Y = \\beta_{0} + \\beta_{1} X + \\epsilon,\\]\nwhere \\(\\beta_{0}, \\beta_{1}\\) are unknown coefficients (parameters) and \\(\\epsilon\\) is the error\n\n\\(\\beta_{0}\\) is commonly referred to as the intercept, and \\(\\beta_{1}\\) is the slope\nFor example: abundance = \\(\\beta_{0}\\) + \\(\\beta_{1}\\) watercont + \\(\\epsilon\\)"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#parameter-estimation",
    "href": "slides/slides-02-linear-regression.html#parameter-estimation",
    "title": "Linear Regression",
    "section": "Parameter estimation",
    "text": "Parameter estimation\n\nAssuming \\(n\\) observations, we have data of the form \\((x_{1}, y_{1}), (x_{2}, y_{2}), \\ldots, (x_{n}, y_{n})\\)\nAn SLR model says \\[\\begin{align*} y_{i} &= \\beta_{0} + \\beta_{1}x_{i}+ \\epsilon\\\\ &\\approx \\beta_{0} + \\beta_{1}x_{i}\\ , \\qquad \\text{ for all } i = 1,\\ldots, n \\end{align*}\\]\n\nIn this model, \\(f(x_{i}) = \\beta_{0} + \\beta_{1} x_{i}\\)\nNotice that the relationship between \\(x_{i}\\) and \\(y_{i}\\) is the same for all \\(i\\)\n\nIn practice, \\(\\beta_{0}\\) and \\(\\beta_{1}\\) are unknown, so we must estimate them\nGoal: obtain (good) estimates \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\) that are as close to the true values as possible, such that \\(y_{i} \\approx \\hat{\\beta}_{0} + \\hat{\\beta}_{1} x_{i}\\)\n\nHow? Minimize the least squares criterion"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#least-squares",
    "href": "slides/slides-02-linear-regression.html#least-squares",
    "title": "Linear Regression",
    "section": "Least squares",
    "text": "Least squares\n\nLet \\(\\hat{y}_{i} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}x_{i}\\) be predicted response for \\(i\\)-th observation with predictor \\(x_{i}\\)\nThe \\(i\\)-th residual \\(e_{i}\\) is defined as \\[e_{i} = y_{i} - \\hat{y}_{i}\\]\nDefine residual sum of squares (RSS) as \\[\\text{RSS} = e_{1}^{2} + e_{2}^{2} + \\ldots + e_{n}^{2} = \\sum_{i=1}^{n} e_{i}^2\\]"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#estimation-by-least-squares",
    "href": "slides/slides-02-linear-regression.html#estimation-by-least-squares",
    "title": "Linear Regression",
    "section": "Estimation by least squares",
    "text": "Estimation by least squares\n\\[\\text{RSS} = \\sum_{i=1}^{n} e_{i}^2 = \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^2 = \\sum_{i=1}^{n} (y_{i} - (\\hat{\\beta}_{0} + \\hat{\\beta}_{1}x_{i}))^2\\]\n\nLeast squares approach selects the pair \\((\\hat{\\beta}_{0}, \\hat{\\beta}_{1})\\) that minimize the RSS. Can be shown that the minimizing values are: \\[\\begin{align*}\n\\hat{\\beta}_{1} &= \\frac{\\sum_{i=1}^{n}(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum_{i=1}^{n}(x_{i} - \\bar{x})^2}\\\\\n\\hat{\\beta}_{0} &= \\bar{y} - \\hat{\\beta}_{1} \\bar{x}\n\\end{align*}\\]\nwhere \\(\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_{i}\\) and \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_{i}\\)"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#mite-data",
    "href": "slides/slides-02-linear-regression.html#mite-data",
    "title": "Linear Regression",
    "section": "Mite data",
    "text": "Mite data\nLeast squares fit for abundance regressed on WaterCont, with residuals in orange.\n\nm1 <- lm(abundance ~ WatrCont, data = mite_dat)\n\n\nLet’s interpret this plot! Do you see anything strange or any patterns?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#interpreting-coefficients-and-estimates",
    "href": "slides/slides-02-linear-regression.html#interpreting-coefficients-and-estimates",
    "title": "Linear Regression",
    "section": "Interpreting Coefficients and Estimates",
    "text": "Interpreting Coefficients and Estimates\n\\[Y = \\beta_{0} + \\beta_{1} X + \\epsilon\\]\n\n\\(\\beta_{0}\\) is the expected value of \\(Y\\) when \\(X = 0\\)\n\\(\\beta_{1}\\) is the average increase in \\(Y\\) for one-unit increase in \\(X\\)\n\\(\\epsilon\\) is error\nThis equation is the population regression line\nWhen using the least squares estimates for the coefficients, \\(\\hat{Y} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} X\\) is the least squares line"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#interpreting-coefficients-and-estimates-cont.",
    "href": "slides/slides-02-linear-regression.html#interpreting-coefficients-and-estimates-cont.",
    "title": "Linear Regression",
    "section": "Interpreting Coefficients and Estimates (cont.)",
    "text": "Interpreting Coefficients and Estimates (cont.)\n\nsummary(m1)\n\n\nCall:\nlm(formula = abundance ~ WatrCont, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.525  -8.033  -4.088   4.493  47.937 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  0.63410    4.51171   0.141   0.8886  \nWatrCont     0.02385    0.01039   2.296   0.0248 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.29 on 68 degrees of freedom\nMultiple R-squared:  0.07194,   Adjusted R-squared:  0.05829 \nF-statistic: 5.271 on 1 and 68 DF,  p-value: 0.02477\n\n\n\n\\[\\widehat{\\text{LRUG}} = 0.634 + 0.024 \\text{WatrCont}\\]\n\n\nHow do I interpret \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\) for this specific example?\nNote: the estimates \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\) will depend on the observed data! If I took a different sample of LRUG mites, I would probably have different estimated values.\n\nIsn’t that problematic? Can we asses how accurate are our estimates \\(\\hat{\\beta}_{0}\\) and \\(\\hat{\\beta}_{1}\\)?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#assessing-accuracy-of-coefficient-estimates",
    "href": "slides/slides-02-linear-regression.html#assessing-accuracy-of-coefficient-estimates",
    "title": "Linear Regression",
    "section": "Assessing Accuracy of Coefficient Estimates",
    "text": "Assessing Accuracy of Coefficient Estimates\n\nStandard error (SE) of an estimator reflects how it varies under repeated sampling.\nFor simple linear regression: \\[\\text{SE}(\\hat{\\beta}_{0}) = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n}(x_{i} - \\bar{x})^2}\\right] \\qquad\n\\text{SE}(\\hat{\\beta}_{1}) = \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_{i} - \\bar{x})^2}\\]\nwhere \\(\\sigma^2 = \\text{Var}(\\epsilon)\\)\nTypically \\(\\sigma^2\\) is not known, but can be estimated from the data.\nEstimate \\(\\hat{\\sigma}\\) is residual standard error (RSE), given by: \\[\\hat{\\sigma}= \\text{RSE} = \\sqrt{\\frac{1}{n-2}\\text{RSS}}\\]\nWe use this estimate to calculate \\(\\text{SE}(\\hat{\\beta}_{0})\\) and \\(\\text{SE}(\\hat{\\beta}_{1})\\)"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#hypothesis-testing",
    "href": "slides/slides-02-linear-regression.html#hypothesis-testing",
    "title": "Linear Regression",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nHypothesis testing is a method of statistical inference to determine whether the data at hand sufficiently support a particular hypothesis\n\nHelps test the results of an experiment or survey to see if you have meaningful results\nHelps draw conclusions about a population parameter\n\nStandard errors can be used to perform hypothesis tests on the coefficients"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#hypothesis-testing-1",
    "href": "slides/slides-02-linear-regression.html#hypothesis-testing-1",
    "title": "Linear Regression",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nNotion of “null” versus “alternate” hypothesis\n\nNull hypothesis \\(H_{0}\\): there is no relationship between \\(X\\) and \\(Y\\)\nAlternative hypothesis \\(H_{A}\\): there is some relationship between \\(X\\) and \\(Y\\)\n\nMathematically, corresponds to testing \\[H_{0}: \\beta_{1} = 0 \\quad \\text{ vs. } \\quad H_{A}: \\beta_{1} \\neq 0\\]\nbecause if \\(H_{0}\\) true, then the model reduces to \\(Y = \\beta_{0} + \\epsilon\\) so there is no relationship\nTo test this null hypothesis, want to determine if \\(\\hat{\\beta}_{1}\\) is sufficiently far from zero\n\nHow much is ‘sufficiently far’? Depends on \\(\\text{SE}(\\hat{\\beta}_{1})\\)."
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#p-value",
    "href": "slides/slides-02-linear-regression.html#p-value",
    "title": "Linear Regression",
    "section": "p-value",
    "text": "p-value\n\nWith lots of hand-waving: can calculate a p-value, which is a probability that we observed the data we did, given that \\(H_{0}\\) is true. If the p-value is small, the observed data don’t seem to support \\(H_{0}\\)\n\nCompare \\(p\\)-value to a pre-determined rejection level \\(\\alpha\\) (often 0.05).\nIf \\(p\\)-value \\(< \\alpha\\), reject \\(H_{0}\\). Otherwise, fail to reject \\(H_{0}\\).\n\n\n\n\nsummary(m1)\n\n\nCall:\nlm(formula = abundance ~ WatrCont, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.525  -8.033  -4.088   4.493  47.937 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  0.63410    4.51171   0.141   0.8886  \nWatrCont     0.02385    0.01039   2.296   0.0248 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.29 on 68 degrees of freedom\nMultiple R-squared:  0.07194,   Adjusted R-squared:  0.05829 \nF-statistic: 5.271 on 1 and 68 DF,  p-value: 0.02477\n\n\n\n\n\\(H_{0}: \\beta_{1} = 0\\) (there is no relationship between LRUG abundance and WatrCont)\n\nWhat is the p-value for this hypothesis?\nWhat is our decision in the mite example?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#why-hypothesis-testing",
    "href": "slides/slides-02-linear-regression.html#why-hypothesis-testing",
    "title": "Linear Regression",
    "section": "Why hypothesis testing?",
    "text": "Why hypothesis testing?\n\nHypothesis testing can help us determine if there is a relationship between the predictor and the response variable!\n\n\nThis is the inference part of statistical learning\n\n\nIf there is a relationship, then it makes sense to interpret the strength of the relationship (i.e. interpret the value \\(\\hat{\\beta}_{1}\\))"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#multiple-linear-regression-1",
    "href": "slides/slides-02-linear-regression.html#multiple-linear-regression-1",
    "title": "Linear Regression",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nIn practice, we often have more than one predictor\nWith \\(p\\) predictors, the model is \\[Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\ldots + \\beta_{p}X_{p} +\\epsilon\\]\nInterpret \\(\\beta_{j}\\) as the average effect on \\(Y\\) for a one-unit increase in \\(X_{j}\\), holding all other predictors fixed/constant"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#mite-data-1",
    "href": "slides/slides-02-linear-regression.html#mite-data-1",
    "title": "Linear Regression",
    "section": "Mite data",
    "text": "Mite data\nRegressing abundance on both WatrCont and SubsDens:\n\nm2 <- lm(abundance ~ WatrCont + SubsDens, data = mite_dat)\nsummary(m2)\n\n\nCall:\nlm(formula = abundance ~ WatrCont + SubsDens, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.192  -8.633  -1.385   6.866  44.245 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 10.30549    5.48833   1.878  0.06477 . \nWatrCont     0.03444    0.01057   3.257  0.00177 **\nSubsDens    -0.35682    0.12604  -2.831  0.00612 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.7 on 67 degrees of freedom\nMultiple R-squared:  0.1711,    Adjusted R-squared:  0.1464 \nF-statistic: 6.915 on 2 and 67 DF,  p-value: 0.001861\n\n\n\n\\[\\widehat{abundance} = 10.306 + 0.034 \\text{WatrCont} -0.357 \\text{SubsDens}\\]\n\n\nHow do we interpret the estimated coefficients?\nHow do we interpret the p-values?\n\nThe p-value for \\(\\beta_{j}\\) corresponds to the test of \\(H_{0}: \\beta_{j} = 0\\) and \\(\\beta_{k} (k \\neq j)\\) unrestricted"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#model-fit",
    "href": "slides/slides-02-linear-regression.html#model-fit",
    "title": "Linear Regression",
    "section": "Model fit",
    "text": "Model fit\n\nHow well does our linear regression model “fit” the data it was trained on? How accurate is our model?\nResidual standard error (RSE) \\[\\text{RSE}  = \\sqrt{\\frac{1}{n-p-1} \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^2},\\]\nwhere \\(p\\) is the number of predictors, and \\(i\\) indexes the observations used to fit the model\nRSE is considered a measure of the lack of fit of the model\n\nMeasured in the units of \\(Y\\)"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#predictions",
    "href": "slides/slides-02-linear-regression.html#predictions",
    "title": "Linear Regression",
    "section": "Predictions",
    "text": "Predictions\n\nHow well does our linear regression model predict new responses for a given set of covariates?\nFor example, suppose I want to use our model to predict the abundance of LRUG mites at a new sampling location where the WatrCont is 400 g/L and the SubsDens is 30 g/L\nI will plug these values into our fitted model m2:\n\n\n\n\n\n\\[\\widehat{abundance} = 10.306 + 0.034 \\times 400 -0.357 \\times 30 = 13.3747829\\]\n\n\n\nnew_data <- data.frame(WatrCont = 400, SubsDens = 30)\npred_mite <- predict(m2, newdata = new_data)\n\n\n\nOkay…great! But should I trust these predictions?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#prediction-performance",
    "href": "slides/slides-02-linear-regression.html#prediction-performance",
    "title": "Linear Regression",
    "section": "Prediction performance",
    "text": "Prediction performance\n\nWe could get a better sense of a model’s prediction performance by comparing the predicted responses to the true values\nWe should always compare prediction performance for “previously unseen” data (i.e. test data)\n\nThe model already “knows” the data used to fit it (i.e. the training data)\n\n\nDiscuss: what are some important criteria for the testing data?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#qualitative-predictors-1",
    "href": "slides/slides-02-linear-regression.html#qualitative-predictors-1",
    "title": "Linear Regression",
    "section": "Qualitative predictors",
    "text": "Qualitative predictors\n\nThus far, we have assumed that all predictors in our linear model are quantitative. In practice, we often have categorical predictors\nOur mite data has the following categorical variables: Shrub, Substrate, and Topo\nLet’s begin with the simplest case: a categorical predictor with two categories/levels\n\ne.g. the Topo variable takes on the values “Blanket” or “Hummock” only"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#level-qualitative-predictor",
    "href": "slides/slides-02-linear-regression.html#level-qualitative-predictor",
    "title": "Linear Regression",
    "section": "2-level qualitative predictor",
    "text": "2-level qualitative predictor\n\nWe will create an indicator or dummy variable as follows: \\[\\text{TopoBlanket}_{i} = \\begin{cases} 1 & \\text{ if } \\color{blue}{\\text{Topo}_{i}} = \\text{Blanket} \\\\\n0 & \\text{ if } \\color{blue}{\\text{Topo}_{i}} = \\text{Hummock} \\end{cases}\\]\nSimple linear regression model for LRUG regressed on Topo: \\[\\text{LRUG}_{i} = \\beta_{0} + \\beta_{1}\\text{TopoBlanket}_{i} + \\epsilon_{i} = \\begin{cases}\n\\beta_{0} + \\epsilon_{i} & \\text{ if } \\color{blue}{\\text{Topo}_{i}} = \\text{Blanket} \\\\\n\\beta_{0} + \\beta_{1} + \\epsilon_{i} & \\text{ if } \\color{blue}{\\text{Topo}_{i}} = \\text{Hummock}  \\end{cases}\\]\n\nHow to interpret?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#mite-data-2",
    "href": "slides/slides-02-linear-regression.html#mite-data-2",
    "title": "Linear Regression",
    "section": "Mite data",
    "text": "Mite data\n\nm3 <- lm(abundance ~ Topo, data = mite_dat)\nsummary(m3)\n\n\nCall:\nlm(formula = abundance ~ Topo, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.318  -4.318  -2.154   4.473  41.682 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.318      1.658   9.238 1.26e-13 ***\nTopoHummock  -13.164      2.721  -4.838 7.85e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11 on 68 degrees of freedom\nMultiple R-squared:  0.2561,    Adjusted R-squared:  0.2452 \nF-statistic: 23.41 on 1 and 68 DF,  p-value: 7.851e-06\n\n\n\nFitted model is: \\[\\widehat{\\text{LRUG}} = 15.318 - 13.164 \\text{TopoHummock}\\]\nInterpret!"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#more-than-two-levels",
    "href": "slides/slides-02-linear-regression.html#more-than-two-levels",
    "title": "Linear Regression",
    "section": "More than two levels",
    "text": "More than two levels\n\nWith more than two levels, we simply create additional dummy variables: \\[\\begin{align*}\\text{Shrub}_{i,Few} &= \\begin{cases} 1 & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{Few} \\\\\n0 & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{not Few} \\end{cases} \\\\\n\\text{Shrub}_{i, Many} &= \\begin{cases} 1 & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{Many} \\\\\n0 & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{not Many} \\end{cases}\n\\end{align*}\\]\nResulting regression model for LRUG with only Shrub as predictor: \\[\\begin{align*} \\text{LRUG}_{i} &= \\beta_{0} + \\beta_{1} \\text{Shrub}_{i, Few} + \\beta_{2} \\text{Shrub}_{i, Many} + \\epsilon_{i}\\\\\n&\\approx \\begin{cases}  \\beta_{0} + \\beta_{1} & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{Few} \\\\\n\\beta_{0} + \\beta_{2} & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{Many} \\\\\n\\beta_{0} & \\text{ if } \\color{blue}{\\text{Shrub}_{i}} = \\text{None} \\end{cases}\\end{align*}\\]\n\n\n\nm4 <- lm(abundance ~ Shrub, data = mite_dat)\nsummary(m4)\n\n\nCall:\nlm(formula = abundance ~ Shrub, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.895  -8.060  -2.760   6.635  40.105 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   10.923      1.405   7.775 6.12e-11 ***\nShrub.L       -9.288      2.505  -3.707 0.000427 ***\nShrub.Q       -1.460      2.359  -0.619 0.538164    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.64 on 67 degrees of freedom\nMultiple R-squared:  0.1791,    Adjusted R-squared:  0.1545 \nF-statistic: 7.306 on 2 and 67 DF,  p-value: 0.001348"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#remarks",
    "href": "slides/slides-02-linear-regression.html#remarks",
    "title": "Linear Regression",
    "section": "Remarks",
    "text": "Remarks\n\nFor a given categorical variable, there will always be one fewer dummy variables than levels\n\nLevel with no dummy variable is known as baseline. For model m4 on previous slide, the “None” category was the baseline level\n\nCan have multiple categorical variables in a single model:\n\n\n\nm5 <- lm(abundance ~ Topo + Shrub, data = mite_dat)\nsummary(m5)\n\n\nCall:\nlm(formula = abundance ~ Topo + Shrub, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.895  -6.056   0.691   4.756  40.105 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   14.755      1.641   8.993 4.48e-13 ***\nTopoHummock  -11.253      2.997  -3.755 0.000369 ***\nShrub.L       -4.832      2.580  -1.873 0.065552 .  \nShrub.Q       -3.128      2.203  -1.420 0.160385    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.65 on 66 degrees of freedom\nMultiple R-squared:  0.3236,    Adjusted R-squared:  0.2928 \nF-statistic: 10.52 on 3 and 66 DF,  p-value: 9.593e-06\n\n\n\n\nLet’s write out the estimated regression model together\n\nWhat does \\(\\beta_{0}\\) represent?\nHow do we interpret the coefficients?"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#linear-model-is-restrictive",
    "href": "slides/slides-02-linear-regression.html#linear-model-is-restrictive",
    "title": "Linear Regression",
    "section": "Linear model is restrictive",
    "text": "Linear model is restrictive\n\nLinear model is widely used and works quite well, but has several highly restrictive assumptions\n\nRelationship between \\(X\\) and \\(Y\\) is additive\nRelationship between \\(X\\) and \\(Y\\) is linear\n\nThere are common approaches to loosen these assumptions. We will only discuss the first restriction here. Take a regression class for more!"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#interactions",
    "href": "slides/slides-02-linear-regression.html#interactions",
    "title": "Linear Regression",
    "section": "Interactions",
    "text": "Interactions\n\nAdditive assumption: the association between a predictor \\(X_{j}\\) and the response \\(Y\\) does not depend on the value of any other predictors\n\n\n\\[Y = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} + \\epsilon\\]\nvs\n\\[Y = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} + \\beta_{3}\\color{orange}{X_{1}X_{2}} + \\epsilon\\]\n\n\nThis third predictor \\(\\color{orange}{X_{1}X_{2}}\\) is known as an interaction term\nThe total effect of \\(X_{1}\\) on \\(Y\\) also depends on the value of \\(X_{2}\\) through the interaction\nIn the above equation, \\(\\beta_{1}\\) and \\(\\beta_{2}\\) are called the “main effects” of \\(X_{1}\\) and \\(X_{2}\\) respectively"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#mite-data-3",
    "href": "slides/slides-02-linear-regression.html#mite-data-3",
    "title": "Linear Regression",
    "section": "Mite data",
    "text": "Mite data\n\nSuppose I want to regress LRUG abundance on SubsDens and WatrCont and their interaction:\n\n\n\nmod_int <- lm(abundance ~ SubsDens + WatrCont + \n                SubsDens * WatrCont,\n              data = mite_dat)\nsummary(mod_int)\n\n\n\n\n\n\nCall:\nlm(formula = abundance ~ SubsDens + WatrCont + SubsDens * WatrCont, \n    data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-24.012  -7.155  -1.896   5.011  44.539 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)  \n(Intercept)       -1.012e+01  1.369e+01  -0.740   0.4621  \nSubsDens           1.323e-01  3.256e-01   0.406   0.6859  \nWatrCont           8.667e-02  3.379e-02   2.565   0.0126 *\nSubsDens:WatrCont -1.210e-03  7.443e-04  -1.625   0.1088  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.56 on 66 degrees of freedom\nMultiple R-squared:  0.203, Adjusted R-squared:  0.1668 \nF-statistic: 5.604 on 3 and 66 DF,  p-value: 0.001744"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#mite-data-4",
    "href": "slides/slides-02-linear-regression.html#mite-data-4",
    "title": "Linear Regression",
    "section": "Mite data",
    "text": "Mite data\n\nFitted model: \\(\\widehat{LRUG} = -10.12 + 0.132 \\text{SubsDens} + 0.087 \\text{WatrCont} -0.001 \\text{SubsDens} \\times \\text{WatrCont}\\)\nInterpretations?\n\n\n\n\n\nEstimates suggest that a 1 g/L increase in the \\(\\color{blue}{\\text{WaterCont}}\\) of the soil is associated with an increased abundance of (0.087 + -0.001 \\(\\times \\color{blue}{\\text{SubsDens}}\\)) LRUG mites"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#interactions-with-categorical-variable",
    "href": "slides/slides-02-linear-regression.html#interactions-with-categorical-variable",
    "title": "Linear Regression",
    "section": "Interactions with categorical variable",
    "text": "Interactions with categorical variable\n\nCan also have interactions involving categorical variables!\nIn particular, the interaction between a quantitative and a categorical variable has nice interpretation\nConsider the effects of SubsDens and Topo and their interaction on the abundances: \\[\\begin{align*}\n\\text{LRUG}_{i} &\\approx \\beta_{0} + \\beta_{1} \\text{SubsDens}_{i} + \\beta_{2}\\text{TopoBlanket}_{i} +  \\beta_{3}  \\text{SubsDens}_{i} \\times \\text{TopoBlanket}_{i} \\\\\n& = \\begin{cases}\n\\beta_{0} + \\beta_{1}\\text{SubsDens}_{i} & \\text{ if } \\color{blue}{\\text{Topo}_{i}} = \\text{Blanket} \\\\\n(\\beta_{0} + \\beta_{2}) + (\\beta_{1} + \\beta_{3}) \\text{SubsDens}_{i} & \\text{ if } \\color{blue}{\\text{Topo}_{i}} = \\text{Hummock}  \\end{cases}\n\\end{align*}\\]\n\n\n\n\n\nCall:\nlm(formula = abundance ~ SubsDens + Topo + SubsDens * Topo, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.059  -4.764  -1.186   3.229  39.191 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           34.7881     5.3697   6.479 1.35e-08 ***\nSubsDens              -0.4695     0.1242  -3.781 0.000338 ***\nTopoHummock          -29.4584     9.0331  -3.261 0.001757 ** \nSubsDens:TopoHummock   0.3803     0.2323   1.637 0.106406    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.11 on 66 degrees of freedom\nMultiple R-squared:  0.3901,    Adjusted R-squared:  0.3624 \nF-statistic: 14.07 on 3 and 66 DF,  p-value: 3.425e-07"
  },
  {
    "objectID": "slides/slides-02-linear-regression.html#fitted-regression-lines",
    "href": "slides/slides-02-linear-regression.html#fitted-regression-lines",
    "title": "Linear Regression",
    "section": "Fitted regression lines",
    "text": "Fitted regression lines"
  },
  {
    "objectID": "live-code/live-code-04.html",
    "href": "live-code/live-code-04.html",
    "title": "Live code 04:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan) # install this in your Console: install.packages(\"vegan\")\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)\n\n\n# SLR\nm1 <- lm(abundance ~ WatrCont, data = mite_dat)\nsummary(m1)\n\n\nCall:\nlm(formula = abundance ~ WatrCont, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.525  -8.033  -4.088   4.493  47.937 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  0.63410    4.51171   0.141   0.8886  \nWatrCont     0.02385    0.01039   2.296   0.0248 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.29 on 68 degrees of freedom\nMultiple R-squared:  0.07194,   Adjusted R-squared:  0.05829 \nF-statistic: 5.271 on 1 and 68 DF,  p-value: 0.02477\n\n# MLR\nm2 <- lm(abundance ~ WatrCont + SubsDens, data = mite_dat)\nsummary(m2)\n\n\nCall:\nlm(formula = abundance ~ WatrCont + SubsDens, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.192  -8.633  -1.385   6.866  44.245 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 10.30549    5.48833   1.878  0.06477 . \nWatrCont     0.03444    0.01057   3.257  0.00177 **\nSubsDens    -0.35682    0.12604  -2.831  0.00612 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.7 on 67 degrees of freedom\nMultiple R-squared:  0.1711,    Adjusted R-squared:  0.1464 \nF-statistic: 6.915 on 2 and 67 DF,  p-value: 0.001861\n\n\n\nnew_dat <- data.frame(WatrCont = 400:405, SubsDens = 30:35)\npreds <- predict(m2, newdata = new_dat)\npreds\n\n       1        2        3        4        5        6 \n13.37478 13.05239 12.73000 12.40761 12.08523 11.76284"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#k-nearest-neighbors-1",
    "href": "slides/slides-03-knn-regression.html#k-nearest-neighbors-1",
    "title": "KNN Regression",
    "section": "K-nearest neighbors",
    "text": "K-nearest neighbors\n\nK-nearest neighbors (KNN) is a nonparametric supervised learning method\nIntuitive and simple\nRelies on the assumption: observations with similar predictors will have similar responses\nWorks for both regression and classification (we will start with regression)"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#algorithm-in-words",
    "href": "slides/slides-03-knn-regression.html#algorithm-in-words",
    "title": "KNN Regression",
    "section": "Algorithm (in words)",
    "text": "Algorithm (in words)\n\nChoose a positive integer \\(K\\), and have your data split into a train set and test set\nFor a given test observation with predictor \\(x_{0}\\):\n\nIdentify the \\(K\\) points in the train data that are closest (in predictor space) to \\(x_{0}\\). Call this set of neighbors \\(\\mathcal{N}_{0}\\).\nPredict \\(\\hat{y}_{0}\\) to be the average of the responses in the neighbor set, i.e. \\[\\hat{y}_{0} = \\frac{1}{K} \\sum_{i \\in \\mathcal{N}_{0}} y_{i}\\]"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#example",
    "href": "slides/slides-03-knn-regression.html#example",
    "title": "KNN Regression",
    "section": "Example",
    "text": "Example\n\n\n\n\nOn the next slide, you will see plot with a bunch of colored points\nEach point is plotted in predictor space \\((x1, x2)\\), and is colored according to the value of its response \\(y\\)\nI have a new point (\\(\\color{blue}{*}\\)) and its covariates/predictors, but I need to make a prediction for its response"
  },
  {
    "objectID": "labs/lab-02-linear-regression.html",
    "href": "labs/lab-02-linear-regression.html",
    "title": "Lab 02: Linear regression",
    "section": "",
    "text": "Note\n\n\n\nThroughout this document, you will see text in different colors. The text in maroon/red denotes the “deliverable” (i.e. what I will be looking for you to code/answer/address in your submission.\n\n\n\nIntroduction\nMoneyball tells the success story of the Oakland A baseball team in 2002. In 2001, the team was extremely poor, and so the General Manager named Billy Beane needed ideas on how to improve the team with limited financial resources.\nBilly Beane and his colleague Paul DePodesta did some analysis and explored models to assemble a competitive baseball team. Beane hypothesized that some skills of a baseball player were overvalued, whereas others undervalued. If they could detect the undervalued skills, they could find good players at a bargain (i.e. cheaper) contract. We will re-create their findings here.\nLoad in the data using the following code (if you get an error, make sure you are set to the correct file directory):\n\nbaseball <- read.csv(\"data/baseball.csv\")\n\nFor terminology, according to Wikipedia, “a run is scored when a player advances around first, second and third base and returns safely to home plate, touching the bases in that order, before three outs are recorded…The object of the game is for a team to score more runs than its opponent.”\nEach observation represents a team in a given year. The data dictionary is as follows:\n\nTeam: MLB team\nLeague: National League (NL) or American League (AL)\nYear: Year\nRS: Total runs scored\nRA: Total runs allowed (the amount of runs that score against a pitcher)\nW: Total wins in the season\nOBP: On-base percentage (how frequently a batter reaches base per plate appearance)\nSLG: Slugging percentage (total bases divided by at bats)\nBA: Batting average (total hit divided by total at-bats)\nPlayoffs: If the team made it to the playoffs (1) or did not (0)\nOOBP: Opponent’s on-base percentage\nOSLG: Opponent’s slugging percentage\n\n\n\nPart 1: EDA and Data Wrangling\n\nData wrangling\nThe data provided to you have data ranging from 1962 to 2012. To re-create this famous analysis, we need to pretend it’s the year 2002 and thus we only have data through 2001.\n\nCreate a new data frame called moneyball with the appropriate subset of the baseball data.\n\n\n\nEDA\nThe goal of any MLB team (I think) is to make it to the playoffs. Billy Beane determined that a team needs to win at least 95 games to make it to the playoffs.\n\nUsing some appropriate EDA, demonstrate how you think Billy Beane arrived at the number 95.\n\n\n\nMore data wrangling\nSo, Billy Beane needed some way to understand what influences/determines the number of wins a team had in a given season. It was determined that the run differential was an important metric, calculated as the overall runs scored minus the runs allowed. A positive run differential means the team scores more than it allows (this is good).\n\nModify your moneyball data frame to add a new variable called RD that is the run differential.\n\n\n\nMore EDA\n\nCreate a scatterplot of a team’s wins versus its run differential in each season. Does there appear to be a linear relationship?\n\n\n\n\n\n\n\nCommit reminder\n\n\n\n\n\nThis would be a good time to knit, commit, and push your changes to GitHub!\n\n\n\n\n\n\nPart 2: Model for wins\n\nFit the model\n\nFit a simple linear regression model with a team’s wins as the response variable and the run differential as the predictor. Call this model mod_wins. Interpret the coefficients.\nRecall that we need at least 95 wins to enter the playoffs. Based on your model, how large of a run differential do we need to get into the playoffs?\n\n\n\n\n\n\n\nCommit reminder\n\n\n\n\n\nThis would be a good time to knit, commit, and push your changes to GitHub!\n\n\n\n\n\n\nPart 3: Components of run differential\nRecall that the runs scored and the runs allowed determine the run differential. So, we also need to understand which variables impact both of these components and how.\n\nModel for runs scored\nThe Oakland A’s discovered that a team’s on-base percentage (OBP), the slugging percentage (SLG), and the batting average (BA) were important for determining how many runs are scored (RS).\n\nFit a linear regression model called mod_rs1 for the runs scored as the response regressed on these three predictors. Is a team’s batting average important for explaining its runs scored? Why or why not?\n\nThe Oakland A’s determined that a team’s batting average was overvalued. Because of this, the Oakland A’s decided to not consider batting average.\n\nUse your fitted model mod_rs1 to explain how they came to this conclusion. Then fit another linear regression model called mod_rs2 for runs scored regressed only on on-base percentage and the slugging percentage.\n\n\n\nModel for runs allowed\nThe Oakland A’s found that the runs allowed (RA) were influenced by the opponents on-base percentage (OOBP) and the opponents slugging percentage (OSLG).\n\nFit a multiple linear regression model called mod_ra for this relationship.\n\n\n\n\n\n\n\nCommit reminder\n\n\n\n\n\nThis would be a good time to knit, commit, and push your changes to GitHub!\n\n\n\n\n\n\nPart 4: Putting it all together\nRecap: for the upcoming 2002 baseball season, we need at least 95 wins to enter the playoffs. We fit a model (mod_wins) for a team’s wins based on its run differential. So, we need to predict the run differential for our team in the upcoming season. To do this, we can predict the runs scored and runs allowed for our new team given some statistics.\n\nCreate new team\nPaul DePodesta ultimately formulated a team of players with the following statistics:\n\nOBP: 0.339\nSLG: 0.430\nOOBP: 0.307\nOSLG: 0.373\n\n\nCreate a new data frame called pauls_team that contains these four statistics of the new team (i.e. pauls_team should have one row and four columns).\n\n\n\nPredictions\n\nUsing your models mod_rs2 and mod_ra and the predict() function, predict the runs scored and runs allowed for pauls_team. Based on these two predictions, what is the predicted run differential?\nBased on the predicted run differential, what is the predicted number of wins for our team in the upcoming season? Should we expect to enter the playoffs?\n\n\n\n\n\n\n\nCommit reminder\n\n\n\n\n\nThis would be a good time to knit, commit, and push your changes to GitHub!\n\n\n\n\n\n\nPart 5: Prediction performance\nBilly Beane and Paul DePodesta ultimately decided to remove batting average from their model for runs scored because they had limited financial resources and wanted to find the skills that were undervalued. However, it could be the case that knowing the batting average of a player is important to explaining the runs scored, and also predicting the runs scored. After all, we had to make predictions for the 2002 season, so we would like a model that predicts the runs scored well. Let’s examine this now to see if the team would have made better predictions of runs scored if they had kept the batting average in the model. We will predict for the upcoming year 2002.\n\nData preparation\n\nCreate a new data frame called baseball2002 that contains the observations from the year 2002 in the original baseball data.\nThen, create a new a variable called RS_true that holds the vector of true runs scored in 2002.\n\n\n\nPredict\n\nObtain predictions of runs scored for the baseball2002 data using both mod_rs1 and mod_rs2 (i.e. you should have two vectors of predictions).\n\nPlease do not report/display/print the vectors of predictions! Just store them using an appropriate variable name.\n\n\nPrediction error\n\nLastly, calculate and report the root mean squared error (RMSE) for the predictions from both of the models.\nBased on your results, do you think the Oakland A’s were correct to remove batting average from their model for runs scored? Why or why not?\n\n\n\n\n\n\n\n\n\nBrief comprehension questions\nPlease answer each of the following questions. Each question only requires a 1-2 sentence response at most!\n\nFor this analysis, did we have train and test datasets? If so, what was the train set and what was the test set?\nFor this analysis, did we ask questions concerning prediction? If so, where?\nFor this analysis, did we ask questions concerning inference? If so, where?\n\n\n\nSubmission\nWhen you’re finished, knit to PDF one last time and upload the PDF to Canvas. Commit and push your code back to GitHub one last time."
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#considerations",
    "href": "slides/slides-03-knn-regression.html#considerations",
    "title": "KNN Regression",
    "section": "Considerations",
    "text": "Considerations\n\nHow do we determine who the neighbors \\(\\mathcal{N}_{0}\\) should be? On the previous slide, it may have seemed intuitive.\n\ni.e. how do we quantify “closeness”?\n\nWhich \\(K\\) should we use?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#euclidean-distance",
    "href": "slides/slides-03-knn-regression.html#euclidean-distance",
    "title": "KNN Regression",
    "section": "Euclidean distance",
    "text": "Euclidean distance\n\nOne of the most common ways to measure distance between points is with Euclidean distance\nOn a number line (one-dimension), the distance between two points \\(a\\) and \\(b\\) is simply the absolute value of their difference\n\nLet \\(d(a,b)\\) denote the Euclidean distance between \\(a\\) and $b$. Then in 1-D, \\(d(a,b) = |a-b|\\).\n\nIn 2-D (think lon-lat coordinate system), the two points are \\(\\mathbf{a} = (a_{1}, a_{2})\\) and \\(\\mathbf{b} = (b_{1}, b_{2})\\) with Euclidean distance \\[d(\\mathbf{a}, \\mathbf{b}) = \\sqrt{(a_{1} - b_{1}) ^2 + (a_{2} - b_{2})^2}\\]\nImportant: the “two-dimensions” refers to the number of coordinates in each point, not the fact that we are calculating a distance between two points"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#euclidean-distance-cont.",
    "href": "slides/slides-03-knn-regression.html#euclidean-distance-cont.",
    "title": "KNN Regression",
    "section": "Euclidean distance (cont.)",
    "text": "Euclidean distance (cont.)\n\nGeneralizing to \\(p\\) dimensions: if \\(\\mathbf{a} = (a_{1}, a_{2}, \\ldots, a_{p})\\) and \\(\\mathbf{b} = (b_{1}, b_{2}, \\ldots, b_{p})\\), then \\[d(\\mathbf{a}, \\mathbf{b}) = \\sqrt{(a_{1} - b_{1}) ^2 + (a_{2} - b_{2})^2 + \\ldots (a_{p} - b_{p})^2} = \\sqrt{\\sum_{j=1}^{p}(a_{j} - b_{j})^2}\\]\nE.g. let \\(\\mathbf{a} = (1, 0, 3)\\) and \\(\\mathbf{b} = (-1, 2, 2)\\). What is \\(d(\\mathbf{a}, \\mathbf{b})\\)?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#euclidean-distance-1",
    "href": "slides/slides-03-knn-regression.html#euclidean-distance-1",
    "title": "KNN Regression",
    "section": "Euclidean distance",
    "text": "Euclidean distance\n\nAnother common distance metric is Manhattan distance\n\nNamed after the grid-system of Manhattan’s roads\n\nThe Manhattan distance between two points \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) in \\(p\\)-dimensions is \\[d_{m}(\\mathbf{a}, \\mathbf{b}) = |a_{1} - b_{1}| + |a_{2}  - b_{2}| + \\ldots +|a_{p}  - b_{p}| = \\sum_{j=1}^{p} |a_{j}  - b_{j}|\\]\nE.g. let \\(\\mathbf{a} = (1, 0, 3)\\) and \\(\\mathbf{b} = (-1, 2, 2)\\). What is \\(d_{m}(\\mathbf{a}, \\mathbf{b})\\)?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#distance-in-knn",
    "href": "slides/slides-03-knn-regression.html#distance-in-knn",
    "title": "KNN Regression",
    "section": "Distance in KNN",
    "text": "Distance in KNN\n\nWe want to find the closest neighbor(s) in the train set to a given test point \\(\\mathbf{x}_{0}\\), such that we can make a prediction \\(\\hat{y}_{0}\\).\n\nImportant: what would the points \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) be in KNN?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#how-much-does-k-matter",
    "href": "slides/slides-03-knn-regression.html#how-much-does-k-matter",
    "title": "KNN Regression",
    "section": "How much does K matter?",
    "text": "How much does K matter?\n\nIt can matter a lot!\nAs we saw previously, you will get different predicted \\(\\hat{y}_{0}\\) for different choices of \\(K\\) in KNN regression\nDiscuss:\n\nWhat does \\(K=1\\) mean? Do you think \\(K = 1\\) is a good choice?\nIt is better to choose a small \\(K\\) or big \\(K\\)?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#example-cont.",
    "href": "slides/slides-03-knn-regression.html#example-cont.",
    "title": "KNN Regression",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing \\(K= 3\\), predicted \\(\\hat{y}_{0} = \\frac{1}{3}(8.073 + 8.838 + 9.17) = 8.694\\)\n\n\n\n\n\nUsing \\(K= 4\\), predicted \\(\\hat{y}_{0} = \\frac{1}{4}(8.073 + 8.838 + 9.17 + 9.541) = 8.906\\)"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#mite-data",
    "href": "slides/slides-03-knn-regression.html#mite-data",
    "title": "KNN Regression",
    "section": "Mite data",
    "text": "Mite data\n\nset.seed(1)\nn <- nrow(mite_dat)\ntest_ids <- sample(1:n, 2)\ntrain_dat <- mite_dat[-test_ids,]\ntest_dat <- mite_dat[test_ids,]\ntest_dat\n\n   SubsDens WatrCont Substrate Shrub    Topo abundance\n68    29.24   590.11   Sphagn1  None Blanket         0\n39    64.75   691.79   Sphagn2   Few Blanket        18"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#mite-data-preparation",
    "href": "slides/slides-03-knn-regression.html#mite-data-preparation",
    "title": "KNN Regression",
    "section": "Mite data: preparation",
    "text": "Mite data: preparation\n\nThe following code divides my data into train and test sets.\n\nMake sure you understand what each line of code is doing! If you don’t, please ask!\n\n\n\n\nset.seed(6)\nn <- nrow(mite_dat)\ntest_ids <- sample(1:n, 2)\ntrain_x <- mite_dat[-test_ids, c(\"SubsDens\", \"WatrCont\")]\ntrain_y <-  mite_dat$abundance[-test_ids]\ntest_x <- mite_dat[test_ids,  c(\"SubsDens\", \"WatrCont\")]\ntest_y <-  mite_dat$abundance[test_ids]\nhead(train_x)\n\n  SubsDens WatrCont\n1    39.18   350.15\n2    54.99   434.81\n3    46.07   371.72\n4    48.19   360.50\n5    23.55   204.13\n6    57.32   311.55"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#mite-data-knn",
    "href": "slides/slides-03-knn-regression.html#mite-data-knn",
    "title": "KNN Regression",
    "section": "Mite data: KNN",
    "text": "Mite data: KNN"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#scaling",
    "href": "slides/slides-03-knn-regression.html#scaling",
    "title": "KNN Regression",
    "section": "Scaling",
    "text": "Scaling\n\nRMSE: 3.3082389"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#mite-data-knn-continued",
    "href": "slides/slides-03-knn-regression.html#mite-data-knn-continued",
    "title": "KNN Regression",
    "section": "Mite data: KNN continued",
    "text": "Mite data: KNN continued\n\n\n\nRunning KNN with \\(K = 3\\) and using Euclidean distance, I identify the following neighbor sets for each test point:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted abundance \\(\\hat{y}\\) and true abundance \\(y\\) for both test points, for a test RMSE of 9.428.\n\n\n\n\n# A tibble: 2 × 3\n  test_pt y_hat y_true\n    <int> <dbl>  <int>\n1       1  11.7     25\n2       2   0        0\n\n\n\n\n\nDiscuss: it seems like we did poorly for the first test observation. Does its neighbor set “make sense”?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#scaling-code",
    "href": "slides/slides-03-knn-regression.html#scaling-code",
    "title": "KNN Regression",
    "section": "Scaling code",
    "text": "Scaling code\nWe will standardize our predictors, meaning that each predictor \\(X_{j}\\) will be transformed to have mean 0 and standard deviation 1:\n\\[X_{j}^{\\text{std}} = \\frac{X_{j} - \\bar{X_{j}}}{\\sigma_{X_{j}}},\\]\nwhere \\(X_{j}\\) is the vector of the \\(j\\)-th predictor, \\(\\bar{X}_{j}\\) is the average of \\(X_{j}\\), and \\(\\sigma_{X_{j}}\\) is its standard deviation.\n\n\nscale(train_x$SubsDens)\n\n              [,1]\n [1,] -0.032638509\n [2,]  1.286001417\n [3,]  0.542024937\n [4,]  0.718844459\n [5,] -1.336265457\n [6,]  1.480336080\n [7,] -0.218632629\n [8,]  3.421180550\n [9,]  1.823132417\n[10,] -0.332064020\n[11,]  0.602910905\n[12,] -0.967613434\n[13,] -0.193610999\n[14,]  1.698024265\n[15,] -0.347076999\n[16,] -0.834998793\n[17,] -1.145267011\n[18,]  0.377716231\n[19,] -0.080179607\n[20,] -1.137760522\n[21,] -0.569769510\n[22,] -0.633157640\n[23,] -0.608970064\n[24,] -0.356251597\n[25,]  0.992414286\n[26,] -1.390478989\n[27,] -0.313714825\n[28,] -0.559760858\n[29,] -0.116877998\n[30,]  0.361035144\n[31,] -0.186938564\n[32,] -0.261169401\n[33,]  1.134203525\n[34,] -0.870029076\n[35,]  0.003225828\n[36,] -0.401290531\n[37,]  0.681312014\n[38,]  2.100038461\n[39,] -0.442993249\n[40,] -0.272012107\n[41,] -1.081878880\n[42,]  1.424454439\n[43,]  1.902367580\n[44,]  0.603744959\n[45,]  0.370209741\n[46,] -0.466346771\n[47,]  0.178377241\n[48,] -1.101062130\n[49,] -0.940923695\n[50,] -0.171925585\n[51,] -0.893382597\n[52,]  0.501990329\n[53,] -0.633157640\n[54,]  0.150853448\n[55,]  1.438633362\n[56,] -1.028499402\n[57,]  1.097505134\n[58,] -0.684034956\n[59,]  0.622094155\n[60,]  0.752206633\n[61,] -0.378771064\n[62,] -0.959272891\n[63,] -1.534770392\n[64,] -0.676528467\n[65,]  1.046627818\n[66,] -0.861688532\n[67,] -0.854182043\n[68,] -1.435517924\nattr(,\"scaled:center\")\n[1] 39.57132\nattr(,\"scaled:scale\")\n[1] 11.98963\n\n# confirming we have mean 0 and sd 1\nscaled_SubsDens <- scale(train_x$SubsDens)\nmean(scaled_SubsDens)\n\n[1] -4.865389e-16\n\nsd(scaled_SubsDens)\n\n[1] 1"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#scaled-mite-data",
    "href": "slides/slides-03-knn-regression.html#scaled-mite-data",
    "title": "KNN Regression",
    "section": "Scaled mite data",
    "text": "Scaled mite data"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#scaled-mite-data-knn",
    "href": "slides/slides-03-knn-regression.html#scaled-mite-data-knn",
    "title": "KNN Regression",
    "section": "Scaled mite data: KNN",
    "text": "Scaled mite data: KNN"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#scaled-mite-data-knn-results",
    "href": "slides/slides-03-knn-regression.html#scaled-mite-data-knn-results",
    "title": "KNN Regression",
    "section": "Scaled mite data: KNN results",
    "text": "Scaled mite data: KNN results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted abundance \\(\\hat{y}\\) and true abundance \\(y\\) for both test points, for a test RMSE of 3.308.\n\n\n\n\n# A tibble: 2 × 3\n  test_pt  y_hat y_true\n    <int>  <dbl>  <int>\n1       1 20.3       25\n2       2  0.333      0\n\n\n\n\nNote how this RMSE compares to when we fit on original scale!\n\nEven though we do slightly worse predicting test point 2, we improve a lot on test point 1"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#mite-data-knn-results",
    "href": "slides/slides-03-knn-regression.html#mite-data-knn-results",
    "title": "KNN Regression",
    "section": "Mite data: KNN results",
    "text": "Mite data: KNN results\n\n\n\nRunning KNN with \\(K = 3\\) and using Euclidean distance, I identify the following neighbor sets for each test point:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted abundance \\(\\hat{y}\\) and true abundance \\(y\\) for both test points, for a test RMSE of 9.428.\n\n\n\n\n# A tibble: 2 × 3\n  test_pt y_hat y_true\n    <int> <dbl>  <int>\n1       1  11.7     25\n2       2   0        0\n\n\n\n\n\nDiscuss: it seems like we did poorly for the first test observation. Does its neighbor set “make sense”?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#pro-and-cons",
    "href": "slides/slides-03-knn-regression.html#pro-and-cons",
    "title": "KNN Regression",
    "section": "Pro and cons",
    "text": "Pro and cons\n\nDiscuss: what do you think are some pros and cons of KNN regression?\n\nYou might want to compare to linear regression"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#considerations-1",
    "href": "slides/slides-03-knn-regression.html#considerations-1",
    "title": "KNN Regression",
    "section": "Considerations",
    "text": "Considerations\n\nWhen your predictors do are on very different scales, you should consider scaling them\nWe will learn later on in the semester how we might pick \\(K\\)\nWhat about categorical predictors?"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#standardizing-multiple-variables",
    "href": "slides/slides-03-knn-regression.html#standardizing-multiple-variables",
    "title": "KNN Regression",
    "section": "Standardizing multiple variables",
    "text": "Standardizing multiple variables\n\n\n\n\ntrain_x_scaled <- train_x %>%\n  mutate_if(is.numeric, scale)\nhead(train_x_scaled)\n\n     SubsDens   WatrCont\n1 -0.03263851 -0.4434260\n2  1.28600142  0.1503860\n3  0.54202494 -0.2921323\n4  0.71884446 -0.3708303\n5 -1.33626546 -1.4676219\n6  1.48033608 -0.7141694\n\n\n\n\n\n\ntrain_x_scaled <- train_x\ntrain_x_scaled$SubsDens <- scale(train_x$SubsDens)\ntrain_x_scaled$WatrCont <- scale(train_x$WatrCont)\nhead(train_x_scaled)\n\n     SubsDens   WatrCont\n1 -0.03263851 -0.4434260\n2  1.28600142  0.1503860\n3  0.54202494 -0.2921323\n4  0.71884446 -0.3708303\n5 -1.33626546 -1.4676219\n6  1.48033608 -0.7141694"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#standardizing-the-test-data",
    "href": "slides/slides-03-knn-regression.html#standardizing-the-test-data",
    "title": "KNN Regression",
    "section": "Standardizing the test data",
    "text": "Standardizing the test data\n\nWe should use the same statistics from the training data to scale the test data\n\ni.e. to standardize the \\(j\\)-th predictor of the test data, we should use the mean and standard deviation of the \\(j\\)-th predictor from the training data\n\n\nDiscuss: why not scale the predictors first, and then split into train/test sets?\n\n\n\n\n\n\n\n# note: I am not providing you the code for how I scaled my test observations!\ntest_x_scaled\n\n     SubsDens     WatrCont\n53 -1.0626956  0.008982148\n10 -0.6198128 -1.351188146\n\n\n\n\n\n\n\nImportant:\n\nI do not scale the response variable\nI scale after splitting into train/test"
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#standardizing-predictors",
    "href": "slides/slides-03-knn-regression.html#standardizing-predictors",
    "title": "KNN Regression",
    "section": "Standardizing predictors",
    "text": "Standardizing predictors\nWe will standardize our predictors, meaning that each predictor \\(X_{j}\\) will be transformed to have mean 0 and standard deviation 1:\n\\[X_{j}^{\\text{std}} = \\frac{X_{j} - \\bar{X_{j}}}{\\sigma_{X_{j}}},\\]\nwhere \\(X_{j}\\) is the vector of the \\(j\\)-th predictor, \\(\\bar{X}_{j}\\) is the average of \\(X_{j}\\), and \\(\\sigma_{X_{j}}\\) is its standard deviation.\n\n\nscale(train_x$SubsDens)\n\n              [,1]\n [1,] -0.032638509\n [2,]  1.286001417\n [3,]  0.542024937\n [4,]  0.718844459\n [5,] -1.336265457\n [6,]  1.480336080\n [7,] -0.218632629\n [8,]  3.421180550\n [9,]  1.823132417\n[10,] -0.332064020\n[11,]  0.602910905\n[12,] -0.967613434\n[13,] -0.193610999\n[14,]  1.698024265\n[15,] -0.347076999\n[16,] -0.834998793\n[17,] -1.145267011\n[18,]  0.377716231\n[19,] -0.080179607\n[20,] -1.137760522\n[21,] -0.569769510\n[22,] -0.633157640\n[23,] -0.608970064\n[24,] -0.356251597\n[25,]  0.992414286\n[26,] -1.390478989\n[27,] -0.313714825\n[28,] -0.559760858\n[29,] -0.116877998\n[30,]  0.361035144\n[31,] -0.186938564\n[32,] -0.261169401\n[33,]  1.134203525\n[34,] -0.870029076\n[35,]  0.003225828\n[36,] -0.401290531\n[37,]  0.681312014\n[38,]  2.100038461\n[39,] -0.442993249\n[40,] -0.272012107\n[41,] -1.081878880\n[42,]  1.424454439\n[43,]  1.902367580\n[44,]  0.603744959\n[45,]  0.370209741\n[46,] -0.466346771\n[47,]  0.178377241\n[48,] -1.101062130\n[49,] -0.940923695\n[50,] -0.171925585\n[51,] -0.893382597\n[52,]  0.501990329\n[53,] -0.633157640\n[54,]  0.150853448\n[55,]  1.438633362\n[56,] -1.028499402\n[57,]  1.097505134\n[58,] -0.684034956\n[59,]  0.622094155\n[60,]  0.752206633\n[61,] -0.378771064\n[62,] -0.959272891\n[63,] -1.534770392\n[64,] -0.676528467\n[65,]  1.046627818\n[66,] -0.861688532\n[67,] -0.854182043\n[68,] -1.435517924\nattr(,\"scaled:center\")\n[1] 39.57132\nattr(,\"scaled:scale\")\n[1] 11.98963\n\n# confirming we have mean 0 and sd 1\nscaled_SubsDens <- scale(train_x$SubsDens)\nmean(scaled_SubsDens)\n\n[1] -4.865389e-16\n\nsd(scaled_SubsDens)\n\n[1] 1"
  },
  {
    "objectID": "live-code/live-code-lin-regression.html",
    "href": "live-code/live-code-lin-regression.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan) # install this in your Console: install.packages(\"vegan\")\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)\n\n\n# SLR\nm1 <- lm(abundance ~ WatrCont, data = mite_dat)\nsummary(m1)\n\n\nCall:\nlm(formula = abundance ~ WatrCont, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.525  -8.033  -4.088   4.493  47.937 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  0.63410    4.51171   0.141   0.8886  \nWatrCont     0.02385    0.01039   2.296   0.0248 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.29 on 68 degrees of freedom\nMultiple R-squared:  0.07194,   Adjusted R-squared:  0.05829 \nF-statistic: 5.271 on 1 and 68 DF,  p-value: 0.02477\n\n# MLR\nm2 <- lm(abundance ~ WatrCont + SubsDens, data = mite_dat)\nsummary(m2)\n\n\nCall:\nlm(formula = abundance ~ WatrCont + SubsDens, data = mite_dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.192  -8.633  -1.385   6.866  44.245 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 10.30549    5.48833   1.878  0.06477 . \nWatrCont     0.03444    0.01057   3.257  0.00177 **\nSubsDens    -0.35682    0.12604  -2.831  0.00612 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.7 on 67 degrees of freedom\nMultiple R-squared:  0.1711,    Adjusted R-squared:  0.1464 \nF-statistic: 6.915 on 2 and 67 DF,  p-value: 0.001861\n\n\n\nnew_dat <- data.frame(WatrCont = 400:405, SubsDens = 30:35)\npreds <- predict(m2, newdata = new_dat)\npreds\n\n       1        2        3        4        5        6 \n13.37478 13.05239 12.73000 12.40761 12.08523 11.76284"
  },
  {
    "objectID": "live-code/live-code-base-R.html",
    "href": "live-code/live-code-base-R.html",
    "title": "Live code:",
    "section": "",
    "text": "This lab is intended to re-familiarize yourself with R and RStudio, as well as begin practicing to code in base R. You will need the tidyverse package."
  },
  {
    "objectID": "live-code/live-code-base-R.html#vectors",
    "href": "live-code/live-code-base-R.html#vectors",
    "title": "Live code:",
    "section": "Vectors",
    "text": "Vectors\nIn R, a vector is a data structure that holds or stores elements of the same type. Type may be numeric, integer, character, boolean, etc.\n\nThe c() function\nGenerally, we create vectors using the c() function and then save the vector into a variable. In the code below, I create a vector of three values (10, 11, and 12), and save the results into v:\n\nv <- c(10, 11, 12)\n\n\n\nThe : operator\nNow, sometimes it’s really useful to create a vector of consecutive numbers, for example, the values 1 through 10. Rather than type out every number explicitly and wrap it in c() , I can use the : operator, which looks like a:b where a and b are integers of your choosing. If a < b, R will then create a vector of numbers a, a+1, a+2,…, b-1, b .\n\nx <- 1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWhat do you think happens if a > b? Try the following code for yourself:\n\ny <- 10:1\n\n\n\nThe rep() function\nOne function that I personally use a lot to create vectors is the rep(a,b) function, which takes in two argument. The first is the value a you wish to repeat, and the second argument is the number of times b you’d like to repeat it. How would we create a vector of 20 0’s? Think about it, and check:\n\n\nCode\nrep(0, 20)"
  },
  {
    "objectID": "live-code/live-code-base-R.html#matrices",
    "href": "live-code/live-code-base-R.html#matrices",
    "title": "Live code:",
    "section": "Matrices",
    "text": "Matrices\nMatrices are the 2D extension of the one-dimensional vectors. When a matrix has n rows and p columns, we denote its dimensions as n x p or “n by p”. We create matrices using the matrix() function. Because of the multiple dimensions, we need to specify the number of rows and the number of columns:\n\nmatrix(NA, nrow = 2, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]   NA   NA   NA\n[2,]   NA   NA   NA\n\n\nThis code above creates a 2 x 3 matrix of NA values. The first argument takes in the elements you want to fill the matrix with. This can either be a single value, or a single vector of values."
  },
  {
    "objectID": "live-code/live-code-base-R.html#data-frames",
    "href": "live-code/live-code-base-R.html#data-frames",
    "title": "Live code:",
    "section": "Data frames",
    "text": "Data frames\nWe will create a data frame called my_df here, which holds the two vectors we created before.\n\nmy_df <- data.frame(xvar = x, yvar = y)\n\nNow, if I wanted to only take the variable xvar from my_df, how would I do so using dplyr functions? Take a second to think about it, then check:\n\n\nCode\nmy_df %>%\n  select(xvar)\n\n\nWe will now use base R to access that xvar variable by using $ notation: <df>$<var_name> . If you do this yourself, you should notice that immediately after typing the $ , a menu pops up with all the variables contained in the data frame.\n\nmy_df$xvar\n\nNow, do you notice the difference between the two outputs?\n\nmy_df %>%\n  select(xvar)\n\n   xvar\n1     1\n2     2\n3     3\n4     4\n5     5\n6     6\n7     7\n8     8\n9     9\n10   10\n\nmy_df$xvar\n\n [1]  1  2  3  4  5  6  7  8  9 10"
  },
  {
    "objectID": "live-code/live-code-base-R.html#indexing",
    "href": "live-code/live-code-base-R.html#indexing",
    "title": "Live code:",
    "section": "Indexing",
    "text": "Indexing\nOne of the most useful tools we will use is indexing and index notation.\nAn index is essentially a numerical representation of an item’s position in a list or vector. It is typically an integer, starting from either 0 or 1 depending on the programming language. In R, our index positions always start at 1!\nFor example, in the word “learning”, the l is at index 1. Similarly, in our vector v of the numbers \\((10, 11, 12)\\), the value at index 1 is 10. We can confirm this with code:\n\nv[1]\n\n[1] 10\n\n\nNotice that we access the item held in index 1 using the square bracket notation [ ]\nNow, I can also replace or modify an element at a given index. I will still access the location using [ ], but now I will store/save the new value:\n\nv[1] <- 13\nv\n\n[1] 13 11 12\n\n\nWe can also modify multiple elements at once by passing in a vector of indices to modify, as well as a vector of new values:\n\nv[2:3] <- c(14, 15)\n\nWhat does v look like now?\nWe can also use indices to refer to elements or entire rows and columns of data frames! Unlike vectors, data frame are two-dimensional, i.e. there are both rows and columns. Thus, our index notation will need to adapt to accommodate this feature. We will still use [ ] notation, but now commas will be introduced:\n\nmy_df[1,2]\n\n[1] 10\n\n\nBased on my_df, what do you think the [1,2] means?\nNow, we already saw how to access a column of a data frame using the $ notation, but we can also use index notation. To access the first column, we would type:\n\nmy_df[,1]\n\nThe 1 after the comma tells R that we want to focus on column 1.\nAs I do not type anything before the comma, R reads this as: “since you did not want a specific row, you must want all the rows”.\nHow do you think we would access the third column? How about both the first and second row?"
  },
  {
    "objectID": "live-code/live-code-base-R.html#functions",
    "href": "live-code/live-code-base-R.html#functions",
    "title": "Live code:",
    "section": "Functions",
    "text": "Functions\nThere are a lot of simple functions in R that we will rely on. We already saw c() and rep(). Most of the functions we will use take in a vector or matrix of numeric values, and return either a single number or vector in return.\nThe function mean() takes in a vector, and returns the mean of the vector.\n\nmean(x)\n\n[1] 5.5\n\n\nThe function length() takes in a vector, and returns the number of elements in the vector:\n\nlength(x)\n\n[1] 10\n\n\nThe functions max() and min() return what you would expect them to!\nAn extremely useful function we will use is the which() function. Unlike the previous functions, which() does not take in a numeric vector. Rather, it takes a vector of boolean values (i.e. TRUE/FALSE values). Then, it returns the indices of the TRUE values in the vector. For example, an input might be:\n\ny == -5\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nThis is comparing each value in y to see if it equals -5 (recall the double equals sign check for equality). Notice that only one value evaluates to TRUE, specifically the element in index 6. Therefore, if we wrap the which() function around that argument, we should get 6 in return:\n\nwhich(y == -5)\n\ninteger(0)\n\n\nPersonally, I tend to read this line of code as a question: Which element(s) of y are exactly equal to -5?\nWe know that y only holds negative values. What do you think happens if we try to evaluate the following. Try it yourself!\n\nwhich(y == 0)\n\nIt’s also entirely possible that many values in the boolean vector are true, in which case the function would return multiple indices. For example, if I want to know which values in y are negative, I could code:\n\nwhich(y < 0)\n\ninteger(0)\n\n\n\nIndexing with boolean vectors\nAbove, we saw how to access elements held at specific indices of interest. We can also use boolean vectors to return values. Recall our vector v:\n\nv\n\n[1] 13 14 15\n\n\nI can index v by indexing using TRUE’s for each value that I want, and FALSE’s otherwise.\n\nv[c(F, T, F)]\n\n[1] 14"
  },
  {
    "objectID": "live-code/live-code-base-R.html#your-turn",
    "href": "live-code/live-code-base-R.html#your-turn",
    "title": "Live code:",
    "section": "Your turn!",
    "text": "Your turn!\nPlease complete the following exercises in order:\n\nCreate a vector called my_vec that holds the values 50 through 100.\nCreate a new vector called less60 where an element is TRUE if the corresponding element in my_vec is less than 60, and FALSE otherwise.\nConfirm that the length of your two vectors are the same.\nPass less60 into the function sum() function. Relate the value obtained to the elements of less60.\nModify my_vec such that the value at index 10 is 100.\nObtain the index of the maximum values of my_vec using functions described above.\nNow, pass my_vec into the which.max() function. Even though we haven’t seen it before, based on the function name, the name of the function is intuitive. Does the result from which.max() differ from what you obtained in Ex. 6? How so?\nCreate a 2 x 5 matrix of the values 1 through 10, where the first row holds the values 1-5, and the second row holds the values 6-10. Hint: look at the help file for matrix."
  },
  {
    "objectID": "live-code/live-code-conditions.html",
    "href": "live-code/live-code-conditions.html",
    "title": "Live code:",
    "section": "",
    "text": "We will continue working in base R, and begin learning about conditional statements and for loops!"
  },
  {
    "objectID": "live-code/live-code-conditions.html#new-function",
    "href": "live-code/live-code-conditions.html#new-function",
    "title": "Live code:",
    "section": "New function:",
    "text": "New function:\n\nThe sample(vec, m) function takes a random sample of size m from the vector vec . By default, we sample without replacement and each value in vec is equally likely. For example, I can draw one value between 1-5 at random (where each value as 1/5 chance of being sampled) as follows:\n\nsample(1:5, 1)\n\n[1] 3\n\nsample(1:5, 1)\n\n[1] 4\n\nsample(1:5, 1)\n\n[1] 3\n\n\n\nAs you see, running this code multiple times will lead to different values being sample-d!\nYou can sample with replacement or sample each value in vec with different probability by changing the arguments in the function call."
  },
  {
    "objectID": "live-code/live-code-conditions.html#conditional-statements",
    "href": "live-code/live-code-conditions.html#conditional-statements",
    "title": "Live code:",
    "section": "Conditional statements",
    "text": "Conditional statements\nThus far, we have learned how to store values and relate different R objects. For example, we can obtain a boolean TRUE or FALSE value when we compare two objects as follows:\n\nx <- 3\nx <= 5\n\n[1] TRUE\n\n\nMost often, we want to use the results from these logical operators to change the behavior of our code. That is, if a certain condition is satisfied, we want our code to do something. Else, our code should do something else.\n\nif statements\nThe if statement takes in a condition. If the condition evaluates to TRUE, then the R code we associate with the if statement is executed. The syntax is as follows:\n\nif (condition){\n  code\n}\n\nNotice that the condition goes in parentheses ( ), and the relevant code goes within curly braces { }.\nFor example:\n\nif (x < 5){\n  print(\"x is less than 5\")\n}\n\nTry this yourself! Set x to be a number, then run this code. If you chose x to be greater than or equal to 5, then the condition evaluates to FALSE and so we do not run the code within the curly braces and nothing is printed.\n\n\nelse statements\nNow, maybe we want to a different block of code to run if the condition evaluates to FALSE. This is where the else statement comes in! Importantly, else statements always follows an if statement so there is no need to supply a conditional statement. The syntax is as follows:\n\nif (condition){\n  code associated with TRUE condition\n} else{\n  code associated with FALSE condition\n}\n\nTry modifying the if statement above to have a corresponding block of code that corrently prints when x is greater than or equal to 5."
  },
  {
    "objectID": "live-code/live-code-conditions.html#for-loops",
    "href": "live-code/live-code-conditions.html#for-loops",
    "title": "Live code:",
    "section": "for loops",
    "text": "for loops\nIt is quite simple to perform repetitive tasks in R. If we want to execute the same operations over and over again, we will use a loop. If we want to repeat the operations for a specific number of times, we use a for loop.\nLet’s look at this code:\n\nfor(i in 1:5){\n  print(i)\n}\n\nThe for() code is telling R that we want to run a for loop, which means we want to repeat the code within the curly braces. How many times do we want to repeat? The code says we want to do this for every value in 1:5.\nThe confusing part is the index i, which is essentially a placeholder. Instead of i, we could use any character we’d like! However, people tend to use i for “iteration”. At the beginning, i is set to the first value in the vector 1:5, (i.e. i = 1 to begin with). All the code within the braces are executed with i = 1 being the state of the world. Once we reach the end of the code within the braces, we go back to the top and set i = 2. We continue to do this until the last value in 1:5, which would be 5.\n\nfor(i in 1:5){\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "live-code/live-code-conditions.html#your-turn",
    "href": "live-code/live-code-conditions.html#your-turn",
    "title": "Live code:",
    "section": "Your turn!",
    "text": "Your turn!\n\nWrite code that outputs the square root of a number. If the number is negative, then print out an informative statement instead. Note: the square root of a number can be obtained via the sqrt() function.\nWrite a for loop that calculates the factorial of a whole number of your choice. As a quick refresher, 5! (which we read as “5 factorial”) is equal to 5 x 4 x 3 x 2 x 1.\nObtain a vector y of 5 values by using the sample function, where the possible values to sample from are integers ranging between 1 and 5. Here, I want you to sample with replacement. Write a for loop that loops for 5 iterations and print the number of elements in y equal to the current iteration. If the current iteration value is not contained in y, please print out a useful statement for the user instead."
  },
  {
    "objectID": "live-code/live-code-functions.html",
    "href": "live-code/live-code-functions.html",
    "title": "Live code:",
    "section": "",
    "text": "Here we will learn how to write functions in R. Functions are extremely helpful for automating commons tasks that you might use often (e.g. computing the RMSE for a set of predictions). If you’re going to use the same block of code more than twice, you should consider writing a function!\nThere are three key steps to creating a new function:\n\nPicking a NAME for the function\nListing the INPUTS/ARGUMENTS to the function called function()\nPlacing the code you have developed in the BODY of the function (between the sets of curly braces { } that immediately follow function()\n\nMaking sure to return() the output from the function\n\n\n\n\nFor example, suppose that I want to create a function that takes in a matrix and returns the sums of the values within each column. (There is a function that already does this, but pretend there isn’t!) The function might look like this:\n\ncolumn_sums <- function(input_matrix){\n  n_cols <- ncol(input_matrix)\n  sums <- rep(NA, n_cols)\n  for(i in 1:n_cols){\n    sums[i] <- sum(input_matrix[,i])\n  }\n  return(sums)\n}\n\nThis looks scary, but let’s break it down.\n\nThe name of the function is column_sums.\nR knows I want to create a function because I use the function() function, where I specify that my function requires a single input that will be referred to as input_matrix.\nThe code within the body specifies how I will use input_matrix to calculate the column sums.\nI finish the function by return()-ing a vector.\n\nLet’s test this out: I will create a matrix of numbers, and then use/call my function as I normally would any R function:\n\nmy_mat <- matrix(1:10, nrow = 2, ncol = 5)\nmy_mat\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10\n\ncolumn_sums(my_mat)\n\n[1]  3  7 11 15 19\n\n\nLet’s confirm this is the correct output with the pre-provided R function colSums():\n\ncolSums(my_mat)\n\n[1]  3  7 11 15 19\n\n\nHow might we code a function that calculates the squared error between two values? Try it yourself, then check here to see if your code generally agrees with mine:\n\n\nCode\nsquared_error <- function(x1, x2){\n  ret <- (x1 - x2)^2\n  return(ret)\n}\n\n\n\n\nCode\n# test your code: you should get 16 for passing in -2 and 2\nsquared_error(-2, 2)"
  },
  {
    "objectID": "live-code/live-code-functions.html#your-turn",
    "href": "live-code/live-code-functions.html#your-turn",
    "title": "Live code:",
    "section": "Your turn!",
    "text": "Your turn!\nFeel free to try any and all of the following:\n\nWrite a function that takes in a temperature in degrees Fahrenheit and returns the temperature in degrees Celsius. For reference, the conversion is \\((\\text{degreesF} - 32) * \\frac{5}{9}\\). Give your function an appropriate name.\n\nCheck to make sure your function works by passing in \\(32^\\circ\\) F. You should get 0 back!\n\nWrite a more complicated version of Exercise 1 where the function takes in two inputs: 1) a temperature (in either Fahrenheit or Celsius) and 2) a string or Boolean (your choice!) that denotes if you want to convert to Fahrenheit or Celsius. Your function should return the correct conversion based on the user’s inputs. Note: the conversion from Celsius to Fahrenheit is \\(\\text{degreesC} * \\frac{9}{5} + 32\\).\nWrit a function called get_rmse() that takes in two vectors as inputs: one of predictions, and one of true values. Your function should calculate and return the root mean squared error (see slides for equation).\nLast week we practiced coding for() loops by obtaining the factorial of a given positive integer. Create a function where the user specifies the integer they want to find the factorial of, and return the factorial."
  },
  {
    "objectID": "files/knn_pseudocode.html",
    "href": "files/knn_pseudocode.html",
    "title": "Pseudocode: KNN",
    "section": "",
    "text": "Given a set of train data (predictors and responses), how would you would implement predictions for a set of test predictors using KNN regression? Be as clear, thoughtful, and detailed as possible. This involves describing the algorithm step-by-step.\nYou may assume that all of our predictors are quantitative, and that we are currently not worried about scaling the predictors.\nSome helpful guiding questions:\n\nWhat information (think data, variables) does your method require as input(s)? What do we want to output?\nWhat are the main components/parts/action for implementing this method? In other words, what do we generally need to “do”?\n\nFor each of the main components, what are the steps to achieve it? For example, if my hypothetical main action is “cook pasta”, then the important steps might be to boil water, add salt after water is boiling, add pasta, set timer, then drain pasta.\n\nWhat information do we need to keep track of/store when implementing this method?\nWill I need to loop through and iterate many times? If so, what components does that affect?\nWhat sorts of functions/calculations will I need?"
  },
  {
    "objectID": "files/knn_pseudocode.html#pseudocode-101",
    "href": "files/knn_pseudocode.html#pseudocode-101",
    "title": "Pseudocode: KNN",
    "section": "Pseudocode 101",
    "text": "Pseudocode 101\nPseudocode is more of an art than a science. It is a kind of structured English for describing algorithms. It allows the designer to focus on the logic of the algorithm without being distracted by details of language syntax (ideally, the pseudocode would be agnostic to the programming language, but sometimes it’s easier to write it specific to your domain).\nPseudocode describes the entire logic of the algorithm so that implementation becomes a rote mechanical task of translating line by line into source code. I should be able to read your pseudocode and write working code from it. We use it here to demonstrate complete understanding of the method. In my mind, you don’t truly understand how a statistical learning method works until you code it yourself!\nWhen writing pseudocode, each specific action/piece of logic must be decomposed to the level of a single loop or decision. Very common constructs that we will use are for loops and if/else statements. Foor loops are specialized constructs for iterating a specific number of times. If/else statements evaluate binary outcomes. It is always important to have indents such that the reader can clearly see the conditions under which a line of a logic falls. In the following examples, notice how and where I indent.\n\nExamples\n\nExample 1\nSuppose I have a vector of numbers vec and I want to obtain their sum. I could write the following pseudocode:\nSet counter = 0, n = length(vec);\n\nFor i from 1, 2, ..., n:\n  \n  Add i-th value of vec to counter;\n\nReturn counter;\n\n\nExample 2\nIf maybe instead I wanted to obtain two separate sums, one of the even values and one of the odd, I might write:\nSet even_counter = 0, odd_counter = 0; n = length(vec);\n\nFor i from 1, 2, ..., n:\n\n  If the i-th value of vec is even:\n    \n    Add the  i-th value of vec to even_counter;\n  \n  Else:\n  \n    Add the i-th value of vec to odd_counter;\n\nReturn even_counter and odd_counter;\n\n\nExample 3\nPersonally, I am fine with a little bit of actual code within the pseudocode, such as:\nSet even_counter = 0, odd_counter = 0; n = length(vec);\n\nFor i from 1:n:\n\n  if vec[i] is even:\n    \n    Add vec[i] to even_counter;\n  \n  else:\n  \n    Add vec[i] to odd_counter;\n\nReturn even_counter and odd_counter;"
  },
  {
    "objectID": "files/knn_pseudocode.html#pseudocode-for-knn-regression",
    "href": "files/knn_pseudocode.html#pseudocode-for-knn-regression",
    "title": "Pseudocode: KNN",
    "section": "Pseudocode for KNN regression",
    "text": "Pseudocode for KNN regression\nAs “homework” for the next class, write (on paper/tablet) pseudocode for implementing KNN regression. For next class, come prepared to share your pseudocode for KNN regression with your group. Please do not begin coding up the method on your own because that takes away from the learning of the group."
  },
  {
    "objectID": "slides/slides-03-knn-regression.html#practice",
    "href": "slides/slides-03-knn-regression.html#practice",
    "title": "KNN Regression",
    "section": "Practice",
    "text": "Practice\n\n\n  X1 X2 X3 y\n1  1  1 -1 0\n2  2  0  0 2\n3 -1  1  0 4\n4  0  1  0 6\n\n\n\nSuppose I have the above data, and I want to predict for a new test point x0 with X1 = 0, X2 = 0, X3 = 0.\nCalculate the distance between x0 and each of the observed data points using:\n\nEuclidean distance\nManhattan distance"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#algorithm-recap",
    "href": "slides/slides-04-knn-regression-pt2.html#algorithm-recap",
    "title": "KNN Regression (cont.)",
    "section": "Algorithm (recap)",
    "text": "Algorithm (recap)\n\nChoose a positive integer \\(K\\), and have your data split into a train set and test set\nFor a given test observation with predictor \\(x_{0}\\):\n\nIdentify the \\(K\\) points in the train data that are closest (in predictor space) to \\(x_{0}\\). Call this set of neighbors \\(\\mathcal{N}_{0}\\).\nPredict \\(\\hat{y}_{0}\\) to be the average of the responses in the neighbor set, i.e. \\[\\hat{y}_{0} = \\frac{1}{K} \\sum_{i \\in \\mathcal{N}_{0}} y_{i}\\]"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data-preparation",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data-preparation",
    "title": "KNN Regression (cont.)",
    "section": "Mite data: preparation",
    "text": "Mite data: preparation\n\nThe following code divides my data into train and test sets.\n\nMake sure you understand what each line of code is doing! If you don’t, please ask!\n\n\n\n\nset.seed(6)\nn <- nrow(mite_dat)\ntest_ids <- sample(1:n, 2)\ntrain_x <- mite_dat[-test_ids, c(\"SubsDens\", \"WatrCont\")]\ntrain_y <-  mite_dat$abundance[-test_ids]\ntest_x <- mite_dat[test_ids,  c(\"SubsDens\", \"WatrCont\")]\ntest_y <-  mite_dat$abundance[test_ids]\nhead(train_x)\n\n  SubsDens WatrCont\n1    39.18   350.15\n2    54.99   434.81\n3    46.07   371.72\n4    48.19   360.50\n5    23.55   204.13\n6    57.32   311.55"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data-knn-results",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data-knn-results",
    "title": "KNN Regression (cont.)",
    "section": "Mite data: KNN results",
    "text": "Mite data: KNN results\n\n\n\nRunning KNN with \\(K = 3\\) and using Euclidean distance, I identify the following neighbor sets for each test point:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted abundance \\(\\hat{y}\\) and true abundance \\(y\\) for both test points, for a test RMSE of 9.428.\n\n\n\n\n# A tibble: 2 × 3\n  test_pt y_hat y_true\n    <int> <dbl>  <int>\n1       1  11.7     25\n2       2   0        0\n\n\n\n\n\nDiscuss: it seems like we did poorly for the first test observation. Does its neighbor set “make sense”?"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#standardizing-predictors-1",
    "href": "slides/slides-04-knn-regression-pt2.html#standardizing-predictors-1",
    "title": "KNN Regression (cont.)",
    "section": "Standardizing predictors",
    "text": "Standardizing predictors\nWe will standardize our predictors, meaning that each predictor \\(X_{j}\\) will be transformed to have mean 0 and standard deviation 1:\n\\[X_{j}^{\\text{std}} = \\frac{X_{j} - \\bar{X_{j}}}{\\sigma_{X_{j}}},\\]\nwhere \\(X_{j}\\) is the vector of the \\(j\\)-th predictor, \\(\\bar{X}_{j}\\) is the average of \\(X_{j}\\), and \\(\\sigma_{X_{j}}\\) is its standard deviation.\n\n\nscale(train_x$SubsDens)\n\n              [,1]\n [1,] -0.032638509\n [2,]  1.286001417\n [3,]  0.542024937\n [4,]  0.718844459\n [5,] -1.336265457\n [6,]  1.480336080\n [7,] -0.218632629\n [8,]  3.421180550\n [9,]  1.823132417\n[10,] -0.332064020\n[11,]  0.602910905\n[12,] -0.967613434\n[13,] -0.193610999\n[14,]  1.698024265\n[15,] -0.347076999\n[16,] -0.834998793\n[17,] -1.145267011\n[18,]  0.377716231\n[19,] -0.080179607\n[20,] -1.137760522\n[21,] -0.569769510\n[22,] -0.633157640\n[23,] -0.608970064\n[24,] -0.356251597\n[25,]  0.992414286\n[26,] -1.390478989\n[27,] -0.313714825\n[28,] -0.559760858\n[29,] -0.116877998\n[30,]  0.361035144\n[31,] -0.186938564\n[32,] -0.261169401\n[33,]  1.134203525\n[34,] -0.870029076\n[35,]  0.003225828\n[36,] -0.401290531\n[37,]  0.681312014\n[38,]  2.100038461\n[39,] -0.442993249\n[40,] -0.272012107\n[41,] -1.081878880\n[42,]  1.424454439\n[43,]  1.902367580\n[44,]  0.603744959\n[45,]  0.370209741\n[46,] -0.466346771\n[47,]  0.178377241\n[48,] -1.101062130\n[49,] -0.940923695\n[50,] -0.171925585\n[51,] -0.893382597\n[52,]  0.501990329\n[53,] -0.633157640\n[54,]  0.150853448\n[55,]  1.438633362\n[56,] -1.028499402\n[57,]  1.097505134\n[58,] -0.684034956\n[59,]  0.622094155\n[60,]  0.752206633\n[61,] -0.378771064\n[62,] -0.959272891\n[63,] -1.534770392\n[64,] -0.676528467\n[65,]  1.046627818\n[66,] -0.861688532\n[67,] -0.854182043\n[68,] -1.435517924\nattr(,\"scaled:center\")\n[1] 39.57132\nattr(,\"scaled:scale\")\n[1] 11.98963\n\n# confirming we have mean 0 and sd 1\nscaled_SubsDens <- scale(train_x$SubsDens)\nmean(scaled_SubsDens)\n\n[1] -4.865389e-16\n\nsd(scaled_SubsDens)\n\n[1] 1"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#standardizing-multiple-variables",
    "href": "slides/slides-04-knn-regression-pt2.html#standardizing-multiple-variables",
    "title": "KNN Regression (cont.)",
    "section": "Standardizing multiple variables",
    "text": "Standardizing multiple variables\n\n\n\n\ntrain_x_scaled <- train_x %>%\n  mutate_if(is.numeric, scale)\nhead(train_x_scaled)\n\n     SubsDens   WatrCont\n1 -0.03263851 -0.4434260\n2  1.28600142  0.1503860\n3  0.54202494 -0.2921323\n4  0.71884446 -0.3708303\n5 -1.33626546 -1.4676219\n6  1.48033608 -0.7141694\n\n\n\n\n\n\ntrain_x_scaled <- train_x\ntrain_x_scaled$SubsDens <- scale(train_x$SubsDens)\ntrain_x_scaled$WatrCont <- scale(train_x$WatrCont)\nhead(train_x_scaled)\n\n     SubsDens   WatrCont\n1 -0.03263851 -0.4434260\n2  1.28600142  0.1503860\n3  0.54202494 -0.2921323\n4  0.71884446 -0.3708303\n5 -1.33626546 -1.4676219\n6  1.48033608 -0.7141694"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#standardizing-the-test-data",
    "href": "slides/slides-04-knn-regression-pt2.html#standardizing-the-test-data",
    "title": "KNN Regression (cont.)",
    "section": "Standardizing the test data",
    "text": "Standardizing the test data\n\nWe should use the same statistics from the training data to scale the test data\n\ni.e. to standardize the \\(j\\)-th predictor of the test data, we should use the mean and standard deviation of the \\(j\\)-th predictor from the training data\n\n\nDiscuss: why not scale the predictors first, and then split into train/test sets?\n\n\n\n\n\n\n\n# note: I am not providing you the code for how I scaled my test observations!\ntest_x_scaled\n\n     SubsDens     WatrCont\n53 -1.0626956  0.008982148\n10 -0.6198128 -1.351188146\n\n\n\n\n\n\n\nImportant:\n\nI do not scale the response variable\nI scale after splitting into train/test"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#scaled-mite-data",
    "href": "slides/slides-04-knn-regression-pt2.html#scaled-mite-data",
    "title": "KNN Regression (cont.)",
    "section": "Scaled mite data",
    "text": "Scaled mite data"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#scaled-mite-data-knn-results",
    "href": "slides/slides-04-knn-regression-pt2.html#scaled-mite-data-knn-results",
    "title": "KNN Regression (cont.)",
    "section": "Scaled mite data: KNN results",
    "text": "Scaled mite data: KNN results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted abundance \\(\\hat{y}\\) and true abundance \\(y\\) for both test points, for a test RMSE of 3.308.\n\n\n\n\n# A tibble: 2 × 3\n  test_pt  y_hat y_true\n    <int>  <dbl>  <int>\n1       1 20.3       25\n2       2  0.333      0\n\n\n\n\nNote how this RMSE compares to when we fit on original scale!\n\nEven though we do slightly worse predicting test point 2, we improve a lot on test point 1"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#why-are-categorical-predictors-a-problem",
    "href": "slides/slides-04-knn-regression-pt2.html#why-are-categorical-predictors-a-problem",
    "title": "KNN Regression (cont.)",
    "section": "Why are categorical predictors a problem?",
    "text": "Why are categorical predictors a problem?\n\nSuppose we want to include the categorical predictors into our predictions:\nTopo \\(\\in \\{ \\text{Blanket, Hummock}\\}\\)\nShrub \\(\\in \\{\\text{None, Few, Many} \\}\\)\nSubstrate \\(\\in \\{\\text{Sphagn1, Spaghn2, Sphagn3, Sphagn4, Litter, Barepeat, Interface}\\}\\)\nDiscuss: how would you define “distance” or “closeness” between two observations based on:\n\nTopo\nShrub\n\nWe will create new quantitative variables to represent categorical variables"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#integer-encoding",
    "href": "slides/slides-04-knn-regression-pt2.html#integer-encoding",
    "title": "KNN Regression (cont.)",
    "section": "Integer encoding",
    "text": "Integer encoding\n\nThe predictor Shrub is ordinal\n\ni.e. there is a natural ordering (None < Few < Many) to the \\(L = 3\\) categories\n\nThe ordering should be reflected in the new quantitative variable\nInteger encoding: convert each label (category/level) into an integer value, where:\n\n“Lowest” level gets assigned 0\nSecond lowest level gets assigned 1\n…\n“Highest” level gets assigned \\(L-1\\)\n\n\nLive code"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data-integer-encoding",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data-integer-encoding",
    "title": "KNN Regression (cont.)",
    "section": "Mite data: integer encoding",
    "text": "Mite data: integer encoding\n\n\n   Shrub Shrub_encode\n68  None            0\n39   Few            1\n1    Few            1\n34  Many            2\n43   Few            1\n\n\n\nNow I can calculate distances using Shrub_encode!"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#one-hot-encoding",
    "href": "slides/slides-04-knn-regression-pt2.html#one-hot-encoding",
    "title": "KNN Regression (cont.)",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\nQuestion: why wouldn’t I want to use integer encoding for a non-ordinal variable such as Substrate?\nOne-hot encoding: map each level of the variable to a new binary 0/1 variable, where\n\n0 represents the absence of the category\n1 represents the presence of the category\n\nThese are called “dummy variables”; will have \\(L\\) new variables\n\nLive code"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data-one-hot-encoding",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data-one-hot-encoding",
    "title": "KNN Regression (cont.)",
    "section": "Mite data: one-hot encoding",
    "text": "Mite data: one-hot encoding\nOne-hot encoding of the Topo variable:\n\n\n      Topo Topo_hummock Topo_blanket\n68 Blanket            0            1\n39 Blanket            0            1\n1  Hummock            1            0\n34 Blanket            0            1\n43 Blanket            0            1"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data-one-hot-encoding-cont.",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data-one-hot-encoding-cont.",
    "title": "KNN Regression (cont.)",
    "section": "Mite data: one-hot encoding (cont.)",
    "text": "Mite data: one-hot encoding (cont.)\nOne-hot encoding of the Substrate variable:\n\n\n# A tibble: 8 × 8\n  Substrate Sub_Sphagn1 Sub_Litter Sub_Interface Sub_S…¹ Sub_S…² Sub_S…³ Sub_B…⁴\n  <fct>           <dbl>      <dbl>         <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Sphagn2             0          0             0       0       0       1       0\n2 Interface           0          0             1       0       0       0       0\n3 Barepeat            0          0             0       0       0       0       1\n4 Sphagn1             1          0             0       0       0       0       0\n5 Sphagn1             1          0             0       0       0       0       0\n6 Interface           0          0             1       0       0       0       0\n7 Sphagn2             0          0             0       0       0       1       0\n8 Interface           0          0             1       0       0       0       0\n# … with abbreviated variable names ¹​Sub_Sphagn3, ²​Sub_Sphagn4, ³​Sub_Sphagn2,\n#   ⁴​Sub_Barepeat"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data",
    "title": "KNN Regression (cont.)",
    "section": "Mite data",
    "text": "Mite data\nSo, our final set of predictors X that we could use in KNN regression for the response variable abundance would be:\n\n\n# A tibble: 6 × 12\n  SubsDens WatrCont Shrub_encode Topo_hummock Topo_blanket Sub_Sphagn1\n     <dbl>    <dbl>        <dbl>        <dbl>        <dbl>       <dbl>\n1     29.2     590.            0            0            1           1\n2     64.8     692.            1            0            1           0\n3     39.2     350.            1            1            0           1\n4     53.2     367.            2            0            1           0\n5     56.6     581             1            0            1           0\n6     37.2     240.            2            0            1           0\n  Sub_Litter Sub_Interface Sub_Sphagn3 Sub_Sphagn4 Sub_Sphagn2 Sub_Barepeat\n       <dbl>         <dbl>       <dbl>       <dbl>       <dbl>        <dbl>\n1          0             0           0           0           0            0\n2          0             0           0           0           1            0\n3          0             0           0           0           0            0\n4          0             1           0           0           0            0\n5          0             1           0           0           0            0\n6          0             1           0           0           0            0"
  },
  {
    "objectID": "slides/slides-04-knn-regression-pt2.html#mite-data-final-data-set",
    "href": "slides/slides-04-knn-regression-pt2.html#mite-data-final-data-set",
    "title": "KNN Regression (cont.)",
    "section": "Mite data: final data set",
    "text": "Mite data: final data set\nSo, our final set of predictors X that we could use in KNN regression for the response variable abundance would be:\n\n\n# A tibble: 70 × 12\n   SubsDens WatrCont Shrub_encode Topo_hummock Topo_blanket Sub_Sphagn1\n      <dbl>    <dbl>        <dbl>        <dbl>        <dbl>       <dbl>\n 1     46.8     406.            1            1            0           1\n 2     37.3     284.            2            0            1           0\n 3     29.2     590.            0            0            1           1\n 4     28.9     588.            0            0            1           1\n 5     46.8     539.            1            0            1           0\n 6     26.8     415.            0            0            1           0\n 7     47.0     626.            0            0            1           0\n 8     48.6     635.            0            0            1           0\n 9     56.6     581             1            0            1           0\n10     27.2     353.            0            0            1           1\n   Sub_Litter Sub_Interface Sub_Sphagn3 Sub_Sphagn4 Sub_Sphagn2 Sub_Barepeat\n        <dbl>         <dbl>       <dbl>       <dbl>       <dbl>        <dbl>\n 1          0             0           0           0           0            0\n 2          0             1           0           0           0            0\n 3          0             0           0           0           0            0\n 4          0             0           0           0           0            0\n 5          0             1           0           0           0            0\n 6          0             1           0           0           0            0\n 7          0             1           0           0           0            0\n 8          0             1           0           0           0            0\n 9          0             1           0           0           0            0\n10          0             0           0           0           0            0\n# … with 60 more rows\n\n\n\nDiscuss: what are some potential issues with one-hot encoding?"
  },
  {
    "objectID": "implementations/implementation_knn_regression_1.html",
    "href": "implementations/implementation_knn_regression_1.html",
    "title": "KNN regression",
    "section": "",
    "text": "You and your group will implement KNN regression. I will break down the process for you below. Your group will build on this assignment over the next 2-3 weeks as we learn more content. Therefore, it is important that you communicate with and contribute to your group! Asking clarifying questions, explaining your thought process, throwing ideas out there, etc. all count as contributing.\nThere will be a series of small deliverables roughly 1-2 times a week. Even though you are working as a group, I want you to submit your deliverables individually. This is so you can continue to develop your skills as a coder and work at a pace that’s more comfortable for you!\n\n\n\nIntroduce yourself: name, majors, anything at all\nTalk about how coding in R (base R or tidyverse) is going for you so well. Some people in the group may be more nervous about or proficient in coding, but I think it’s good to name it early on.\nFind a time and place to meet outside of class this week"
  },
  {
    "objectID": "slides/slides-05-resampling.html#resampling",
    "href": "slides/slides-05-resampling.html#resampling",
    "title": "Validation",
    "section": "Resampling",
    "text": "Resampling\n\nEconomically use a collected dataset by repeatedly drawing samples from the same training dataset and fitting a model of interest on each sample\n\nObtain additional information about the fitted model\n\nTwo methods: cross-validation and the bootstrap\nThese slides will focus on the following topics of cross-validation:\n\nValidation set\nLOOCV\nk-fold CV (another k!)"
  },
  {
    "objectID": "slides/slides-05-resampling.html#training-vs-test-errors",
    "href": "slides/slides-05-resampling.html#training-vs-test-errors",
    "title": "Validation",
    "section": "Training vs Test errors",
    "text": "Training vs Test errors\n\nRecall the distinction between the training and test datasets\n\nTraining data: used to fit model\nTest data: used to test/evaluate the model\n\nThese two datasets result in two types of error:\n\nTraining error: average error resulting from using the model to predict the responses for the training data\nTest error: average error from using the model to predict the responses on new, “unseen” observations\n\nTraining error is often very different from test error"
  },
  {
    "objectID": "slides/slides-05-resampling.html#validation-set-approach",
    "href": "slides/slides-05-resampling.html#validation-set-approach",
    "title": "Validation",
    "section": "Validation set approach",
    "text": "Validation set approach\n\nWe have been using a validation set approach: randomly divide (e.g. 50/50) the available data into two parts: a training set and a test/validation/hold-out set\n\nModel is fit on training set\nFitted model predicts responses for the observations in the validation set\n\nThe resulting validation-set error provides an estimate of the test error (e.g. RMSE)"
  },
  {
    "objectID": "slides/slides-05-resampling.html#validation-set-approach-drawbacks",
    "href": "slides/slides-05-resampling.html#validation-set-approach-drawbacks",
    "title": "Validation",
    "section": "Validation set approach: drawbacks",
    "text": "Validation set approach: drawbacks\n\nOur estimate for test error will depend on the observations that are included in the training and validation sets\n\nValidation estimate of test error can be highly variable\n\nOnly a subset of the available data are used to fit the model\n\ni.e. fewer observations used to fit model might lead to overestimating test error rate"
  },
  {
    "objectID": "slides/slides-05-resampling.html#leave-one-out-cross-validation",
    "href": "slides/slides-05-resampling.html#leave-one-out-cross-validation",
    "title": "Resampling",
    "section": "Leave-One-Out Cross-Validation",
    "text": "Leave-One-Out Cross-Validation\n\nLeave-one-out cross-validation (LOOCV) attempts to address the drawbacks from validation set approach\nStill splits all observations into two sets: training and validation\nKey difference: just one observation is used for the validation set, leaving \\(n-1\\) observations for training set\nFor example: choose observation \\((x_{1}, y_{1})\\) to be validation set, and fit model on training set \\(\\{(x_{2}, y_{2}), (x_{3}, y_{3}), \\ldots, (x_{n}, y_{n}) \\}\\)\n\n\\(\\text{RMSE}_{1} = \\sqrt{(y_{1} -\\hat{y}_{1})^2}\\) an approximately unbiased estimate for test error\n\nRepeat procedure by selecting the second observation to be validation set, then third, etc.\nWill end up with \\(n\\) errors: \\(\\text{RMSE}_{1}, \\text{RMSE}_{2}, \\ldots, \\text{RMSE}_{n}\\). Then LOOCV estimate for test RMSE is the average:\n\n\n\\[\\text{CV}_{(n)} = \\frac{1}{n}\\sum_{i=1}^{n} \\text{RMSE}_{i}\\]"
  },
  {
    "objectID": "slides/slides-05-resampling.html#discuss",
    "href": "slides/slides-05-resampling.html#discuss",
    "title": "Validation",
    "section": "Discuss",
    "text": "Discuss\n\nSuppose I am fitting a simple linear regression model \\(Y = \\beta_{0} + \\beta_{1}X + \\epsilon\\).\nI want to obtain an estimate of the test error using LOOCV\nDiscuss exactly how you would implement this in code. Specific things to mention:\n\nWhat “actions”/functions you would use, and in what order\nWhat values you would compute\nWhat values you would store\n\n\nLive code"
  },
  {
    "objectID": "slides/slides-05-resampling.html#loocv-pros-and-cos",
    "href": "slides/slides-05-resampling.html#loocv-pros-and-cos",
    "title": "Resampling",
    "section": "LOOCV pros and cos",
    "text": "LOOCV pros and cos\n\n::: {.column width = “50%”} - Pros\nEach training set has \\(n-1\\) observations \\(\\rightarrow\\) tend to not overestimate test error as much\nThere is no randomness in training/validation set splits\n\n\n::: {.column width = “50%”} - Cons\n\nLOOCV can be expensive to implement – must fit the model \\(n\\) times\nEstimates for each validation set \\(i\\) are highly correlated, so the average can have high variance\n\n:::\n:::: ## k-fold Cross-Validation {.scrollable}\n\nIn k-fold CV, the observations are randomly divided into \\(K\\) groups (or folds) of approximately equal size.\nFor each \\(k\\) in \\(1, 2, \\ldots, K\\):\n\nLeave out \\(k\\)-th group as validation set, and fit model on remaining \\(K-1\\) parts (combined)\nPrediction for the held-out \\(k\\)-th fold, and obtain a corresponding \\(\\text{RMSE}_{k}\\)\n\nLetting the \\(k\\)-th fold have \\(n_{k}\\) observations:\n\n\\(\\text{RMSE}_{k} = \\sqrt{\\frac{1}{n_{k}}\\sum_{i \\in \\mathcal{C}_{k}} (y_{i} - \\hat{y}^{(k)}_{i})^2}\\), where \\(\\mathcal{C}_{k}\\) is set of observations in \\(k\\)-th fold and \\(\\hat{y}^{(k)}_{i}\\) is fit for observation \\(i\\) obtained from data with part \\(k\\) removed\nIf \\(n\\) is a multiple of \\(K\\), then \\(n_{k} = n/K\\)\n\nThe \\(k\\)-fold CV estimate of the test error is the average:\n\n\\[\\text{CV}_{(K)} = \\frac{1}{K} \\sum_{k=1}^{K} \\text{RMSE}_{k}\\]"
  },
  {
    "objectID": "slides/slides-05-resampling.html#k-fold-cross-validation",
    "href": "slides/slides-05-resampling.html#k-fold-cross-validation",
    "title": "Resampling",
    "section": "k-fold Cross-Validation",
    "text": "k-fold Cross-Validation\n\nIn k-fold CV, the observations are randomly divided into \\(k\\) partitions (or folds) of approximately equal size.\nFor each \\(j\\) in \\(1, 2, \\ldots, k\\):\n\nLeave out \\(j\\)-th group as validation set, and fit model on remaining \\(k-1\\) parts (combined)\nPredict for all observations in the held-out \\(j\\)-th fold, and obtain a corresponding \\(\\text{RMSE}_{j}\\)\n\nThe \\(k\\)-fold CV estimate of the test error is the average:\n\n\n\\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^{k} \\text{RMSE}_{j}\\]"
  },
  {
    "objectID": "slides/slides-05-resampling.html#visual",
    "href": "slides/slides-05-resampling.html#visual",
    "title": "Validation",
    "section": "Visual",
    "text": "Visual\n\nImportant: k is the number of folds/partitions, not the number of observations within each fold!"
  },
  {
    "objectID": "slides/slides-05-resampling.html#remarks",
    "href": "slides/slides-05-resampling.html#remarks",
    "title": "Resampling",
    "section": "Remarks",
    "text": "Remarks\n\nLOOCV is a special case of \\(k\\)-fold CV.\n\nQuestion: Which value of \\(k\\) yields LOOCV?\n\n\\(k\\)-fold CV estimate is still biased upward; bias minimized when \\(k = n\\)\n\n\\(k = 5\\) or \\(k=10\\) often used as a compromise for bias-variance tradeoff\n\nLOOCV and \\(k\\)-fold CV are useful and commonly used because of their generality"
  },
  {
    "objectID": "slides/slides-05-resampling.html#the-bootstrap-1",
    "href": "slides/slides-05-resampling.html#the-bootstrap-1",
    "title": "Validation",
    "section": "The Bootstrap",
    "text": "The Bootstrap\n\nThe bootstrap is a flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method\nExample: can be used to estimate the standard errors of the \\(\\beta\\) coefficients in linear regression\nOne goal of statistics: learn about a population.\n\nUsually, population is not available, so must make inference from sample data\n\nBootstrapping operates by resampling this sample data to create many simulated samples"
  },
  {
    "objectID": "slides/slides-05-resampling.html#the-bootstrap-cont.",
    "href": "slides/slides-05-resampling.html#the-bootstrap-cont.",
    "title": "Validation",
    "section": "The Bootstrap (cont.)",
    "text": "The Bootstrap (cont.)\n\nBootstrapping resamples the original dataset with replacement\nIf the original datset has \\(n\\) observations, then each bootstrap/resampled dataset also has \\(n\\) observations\n\nEach observation has equal probability of being included in resampled dataset\nCan select an observation more than once for a resampled dataset"
  },
  {
    "objectID": "slides/slides-05-resampling.html#example",
    "href": "slides/slides-05-resampling.html#example",
    "title": "Validation",
    "section": "Example",
    "text": "Example\n\nSuppose a study on adult daily caffeine consumption (mg) collects 4 data points: 110, 130, 150, 200. I want to learn about the average consumption in adults.\nCreate my first bootstrap sample:\n\n\ndat <- c(110, 130, 150, 200)\nn <- length(dat)\n\nsamp1 <- sample(x = dat, size = n, replace = T)\nsamp1\n\n[1] 200 200 200 110\n\n\n\nObtain our first estimate for \\(\\mu\\), the population mean daily caffeine consumption in adults: \\(\\hat{\\mu}_{1} = 177.5\\)"
  },
  {
    "objectID": "slides/slides-05-resampling.html#example-cont.",
    "href": "slides/slides-05-resampling.html#example-cont.",
    "title": "Validation",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nTake second sample:\n\n\nsamp2 <- sample(x = dat, size = n, replace = T)\nsamp2\n\n[1] 150 110 150 150\n\n\n\n\\(\\hat{\\mu}_{2} = 140\\)\nRepeat this process thousands of times!\n…\n\n\n\n\n\nAfter 1000 bootstrap samples, we end up with 1000 estimates for \\(\\mu\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean over all estimates is \\(\\hat{\\mu} = 147.365\\)\nApproximate 95% confidence interval for the mean are the 5% and 95% quantiles of the 1000 mean estimates: (120, 182.5)\n\nCalled a bootstrap percentile confidence interval"
  },
  {
    "objectID": "slides/slides-05-resampling.html#bootstrap-pros-and-cons",
    "href": "slides/slides-05-resampling.html#bootstrap-pros-and-cons",
    "title": "Validation",
    "section": "Bootstrap: pros and cons",
    "text": "Bootstrap: pros and cons\n\nReal world vs bootstrap world\nPros:\n\nNo assumptions about distribution of your data\nVery general method that allows estimating sampling distribution of almost any statistic!\nCost-effective\n\nCons:\n\nIn more complex scenarios, figuring out appropriate way to bootstrap may require thought\nCan fail in some situations\nRelies quite heavily on the original sample"
  },
  {
    "objectID": "slides/slides-05-resampling.html#validation-remarks",
    "href": "slides/slides-05-resampling.html#validation-remarks",
    "title": "Validation",
    "section": "Validation: remarks",
    "text": "Validation: remarks\n\nLOOCV is a special case of \\(k\\)-fold CV.\n\nQuestion: Which value of \\(k\\) yields LOOCV?\n\n\\(k\\)-fold CV estimate is still biased upward; bias minimized when \\(k = n\\)\n\n\\(k = 5\\) or \\(k=10\\) often used as a compromise for bias-variance tradeoff\n\nLOOCV and \\(k\\)-fold CV are useful and commonly used because of their generality"
  },
  {
    "objectID": "slides/slides-05-resampling.html#live-code",
    "href": "slides/slides-05-resampling.html#live-code",
    "title": "Validation",
    "section": "Live code",
    "text": "Live code"
  },
  {
    "objectID": "slides/slides-05-resampling.html#example-varying-k",
    "href": "slides/slides-05-resampling.html#example-varying-k",
    "title": "Validation",
    "section": "Example: varying k",
    "text": "Example: varying k\nI fit the linear model abundance = \\(\\beta_{0} + \\beta_{1}\\) WatrCont + \\(\\beta_{2}\\) SubsDens and obtain estimates of the test RMSE using k-fold CV for varying k:"
  },
  {
    "objectID": "slides/slides-05-resampling.html#loocv-pros-and-cons",
    "href": "slides/slides-05-resampling.html#loocv-pros-and-cons",
    "title": "Validation",
    "section": "LOOCV pros and cons",
    "text": "LOOCV pros and cons\n\n\n\nPros\n\nEach training set has \\(n-1\\) observations \\(\\rightarrow\\) tend to not overestimate test error as much\nThere is no randomness in how the original data is split\n\n\n\n\nCons\n\nLOOCV can be expensive to implement – must fit the model \\(n\\) times\nEstimates for each validation set \\(i\\) are highly correlated, so the average can have high variance"
  },
  {
    "objectID": "slides/slides-05-resampling.html#k-fold-cv-cont.",
    "href": "slides/slides-05-resampling.html#k-fold-cv-cont.",
    "title": "Validation",
    "section": "k-fold CV (cont.)",
    "text": "k-fold CV (cont.)\n\nLetting the \\(j\\)-th fold have \\(n_{j}\\) observations:\n\n\n\\[\\text{RMSE}_{j} = \\sqrt{\\frac{1}{n_{j}}\\sum_{i \\in \\mathcal{C}_{j}} (y_{i} - \\hat{y}^{(j)}_{i})^2},\\]\n\n\nwhere \\(\\mathcal{C}_{j}\\) is set of observations in the \\(j\\)-th fold, so \\(i\\) indexes the observations in \\(\\mathcal{C}_{j}\\). \\(\\hat{y}^{(j)}_{i}\\) is the prediction for \\(i\\)-th observation, obtained from data with part \\(j\\) removed\n\n\nIf \\(n\\) is a multiple of \\(k\\), then \\(n_{j} = \\frac{n}{k}\\)"
  },
  {
    "objectID": "slides/slides-05-resampling.html#leave-one-out-cross-validation-1",
    "href": "slides/slides-05-resampling.html#leave-one-out-cross-validation-1",
    "title": "Validation",
    "section": "Leave-One-Out Cross-Validation",
    "text": "Leave-One-Out Cross-Validation\n\nLeave-one-out cross-validation (LOOCV) attempts to address the drawbacks from validation set approach\nWe still split all observations into two sets: training and validation\nKey difference: instead of splitting just once, we split many times, where one observation is used for the validation set, leaving the remaining \\(n-1\\) observations for training set"
  },
  {
    "objectID": "slides/slides-05-resampling.html#k-fold-cross-validation-1",
    "href": "slides/slides-05-resampling.html#k-fold-cross-validation-1",
    "title": "Validation",
    "section": "k-fold Cross-Validation",
    "text": "k-fold Cross-Validation\n\nIn k-fold CV, the observations are randomly divided into \\(k\\) partitions (or folds) of approximately equal size.\nFor each \\(j\\) in \\(1, 2, \\ldots, k\\):\n\nLeave out \\(j\\)-th partition/fold as validation set, and fit model on remaining \\(k-1\\) partitions (combined)\nPredict for all observations in the held-out \\(j\\)-th fold, and obtain a corresponding \\(\\text{RMSE}_{j}\\)\n\nThe \\(k\\)-fold CV estimate of the test error is the average:\n\n\n\\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^{k} \\text{RMSE}_{j}\\]"
  },
  {
    "objectID": "slides/slides-05-resampling.html#loocv-method",
    "href": "slides/slides-05-resampling.html#loocv-method",
    "title": "Validation",
    "section": "LOOCV: method",
    "text": "LOOCV: method\n\nStart by choosing first observation \\((x_{1}, y_{1})\\) to be validation set, and fit model on remaining \\(\\{(x_{2}, y_{2}), (x_{3}, y_{3}), \\ldots, (x_{n}, y_{n}) \\}\\) as our training set\nObtain \\(\\text{RMSE}_{1} = \\sqrt{(y_{1} -\\hat{y}_{1})^2}\\), an approximately unbiased estimate for test error\nRepeat procedure by selecting the second observation to be validation set, then third, etc.\nWill end up with \\(n\\) errors: \\(\\text{RMSE}_{1}, \\text{RMSE}_{2}, \\ldots, \\text{RMSE}_{n}\\). Then LOOCV estimate for test RMSE is the average:\n\n\n\\[\\text{CV}_{(n)} = \\frac{1}{n}\\sum_{i=1}^{n} \\text{RMSE}_{i}\\]"
  },
  {
    "objectID": "implementations/implementation-knn_regression_2.html",
    "href": "implementations/implementation-knn_regression_2.html",
    "title": "KNN regression",
    "section": "",
    "text": "Now that you’ve implemented KNN regression, you will work on incorporating categorical features. Thankfully, you shouldn’t have to modify anything about your .knn() function!\nWe will continue to work with the mite_dat data, but will now extend the predictors to include Substrate, Shrub and Topo.\n\nlibrary(tidyverse)\nlibrary(vegan) \ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "implementations/implementation-knn_regression_2.html#assignment",
    "href": "implementations/implementation-knn_regression_2.html#assignment",
    "title": "KNN regression",
    "section": "Assignment",
    "text": "Assignment\nRecall the slides from the first week of class where we did some EDA exploring the relationship between each predictor and the abundance of the mites. The whole class was of the opinion that the categorical predictors might be more useful than the quantitative predictors for predicting the abundance. We will explore that here!\n\nIn the file called knn_regresssion2.Rmd, copy and paste your .knn() function (and any accompanying functions) into the appropriate code chunk.\n\n\nCreate new data frame\n\nCreate a new data frame mite_dat2 that holds the original quantitative variables and response, and the appropriately encoded versions of the three categorical predictors.\n\n\n\nSplit into train/test sets\nThe following code splits the original data into a train set and a test set. As a group, discuss what each line of code is doing.\nCopy and paste this code into your .Rmd file in the appropriate code chunk.\n\nset.seed(1)\nn <- nrow(mite_dat2) \ntrain_ids <- sample(1:n, size = 0.7*n)\ntrain_dat <- mite_dat2[train_ids,]\ntest_dat <- mite_dat2[-train_ids,]\n\n\n\nRun KNN using all features\n\nWith \\(K = 5\\) neighbors, use your .knn() function to obtain predictions for the test data using all the predictors. Report your RMSE for the test data.\n\n\n\nRun KNN using quantitative features only\n\nNow use your .knn() function to obtain predictions for the test data using only the quantitative predictors WatrCont and SubsDens. Still use \\(K = 5\\) neighbors. Report your RMSE for the test data.\n\n\n\nRun KNN using categorical features only\n\nNow use your .knn() function to obtain predictions for the test data using only the encoded categorical predictors. Still use \\(K = 5\\) neighbors. Report your RMSE for the test data.\n\n\n\nDiscuss\n\nCompare and contrast the RMSEs from the three models you fit. What are you surprised or not surprised by? What do you think explains or contributes to the results you obtained?\n\nUsing the same test/train split and encodings, I also fit a fourth model where I used all the predictors but standardized the quantitative predictors. I obtained an RMSE of roughly 6.5 for the test data.\n\nComment on how this fourth RMSE compares to the ones you obtained. Are you surprised by this result? Why or why not? What do you think explains this result?"
  },
  {
    "objectID": "implementations/implementation-knn_regression_2.html#submission",
    "href": "implementations/implementation-knn_regression_2.html#submission",
    "title": "KNN regression",
    "section": "Submission",
    "text": "Submission\nOnce you’ve finished, push your changes to GitHub. Upload the finished PDF to Canvas."
  },
  {
    "objectID": "live-code/live-code-encoding.html",
    "href": "live-code/live-code-encoding.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)\n\nRecall that in our mite_dat, we have the following three categorical predictors:\n\nShrub, which takes values “None”, “Few”, and “Many”\nTopo, which takes values “Hummock” and “Blanket”\nSubstrate, which takes values “Sphagn1”, “Spaghn2”, “Sphagn3”, “Sphagn4”, “Litter”, “Barepeat”, “Interface”\n\nWe would like to be able to convert these categorical predictors into quantitative ones in order to compute distances."
  },
  {
    "objectID": "live-code/live-code-encoding.html#integer-encoding",
    "href": "live-code/live-code-encoding.html#integer-encoding",
    "title": "Live code:",
    "section": "Integer encoding",
    "text": "Integer encoding\n\nmite_dat <- mite_dat %>%\n  mutate(Shrub_encode = case_when(\n    Shrub == \"None\" ~ 0,\n    Shrub == \"Few\" ~ 1, \n    Shrub == \"Many\" ~ 2\n      )\n    )\n\n# compare your new variable to confirm it's correct:\nmite_dat %>%\n  select(Shrub, Shrub_encode) %>%\n  View()"
  },
  {
    "objectID": "live-code/live-code-encoding.html#one-hot-encoding-few-levels",
    "href": "live-code/live-code-encoding.html#one-hot-encoding-few-levels",
    "title": "Live code:",
    "section": "One-hot encoding (few levels)",
    "text": "One-hot encoding (few levels)\n\nmite_dat <-  mite_dat %>%\n  mutate(\n    Topo_hummock = if_else(Topo == \"Hummock\", 1, 0),\n    Topo_blanket = if_else(Topo == \"Blanket\", 1, 0)\n  ) \n\n# compare your new variable to confirm it's correct"
  },
  {
    "objectID": "live-code/live-code-encoding.html#one-hot-encoding-many-levels",
    "href": "live-code/live-code-encoding.html#one-hot-encoding-many-levels",
    "title": "Live code:",
    "section": "One-hot encoding (many levels)",
    "text": "One-hot encoding (many levels)\nThe Substrate variable has 7 levels! We could write 7 different if_else() statements, but that seems rather inefficient…\nInstead, we will make clever use of the of the pivot_wider() function. In the code below:\n\nLine 2: create a new place-holder variable value that gives us the mechanism to create dummy variables\nLine 3: pivot_wider() to create new variables, one for each level of Substrate. Each new variable gets its value from value (i.e. a 1) if the original Substrate variable belonged to that level.\n\n\nmite_dat %>%\n  mutate(value = 1) %>% \n  pivot_wider(names_from = Substrate, values_from = value) \n\nYou should notice that we get a lot of NA values! We just need to replace those NA’s with 0s. In the code below:\n\nLine 4: use the values_fill argument to specify that NAs should be 0s\nLine 5: modify the names of our new variables to more clearly indicate that they correspond to the same original variable\n\n\nmite_dat <- mite_dat %>%\n  mutate(value = 1) %>%\n  pivot_wider(names_from = Substrate, values_from = value, \n              values_fill = 0,\n              names_prefix = \"Sub_\")\nmite_dat %>%\n  slice(1:6)\n\n# A tibble: 6 × 12\n  SubsDens WatrCont Shrub Topo   abund…¹ Sub_S…² Sub_L…³ Sub_I…⁴ Sub_S…⁵ Sub_S…⁶\n     <dbl>    <dbl> <ord> <fct>    <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1     39.2     350. Few   Hummo…       0       1       0       0       0       0\n2     55.0     435. Few   Hummo…       0       0       1       0       0       0\n3     46.1     372. Few   Hummo…       0       0       0       1       0       0\n4     48.2     360. Few   Hummo…       0       1       0       0       0       0\n5     23.6     204. Few   Hummo…       0       1       0       0       0       0\n6     57.3     312. Few   Hummo…       0       1       0       0       0       0\n# … with 2 more variables: Sub_Sphagn2 <dbl>, Sub_Barepeat <dbl>, and\n#   abbreviated variable names ¹​abundance, ²​Sub_Sphagn1, ³​Sub_Litter,\n#   ⁴​Sub_Interface, ⁵​Sub_Sphagn3, ⁶​Sub_Sphagn4"
  },
  {
    "objectID": "implementations/implementation_knn_regression_2.html",
    "href": "implementations/implementation_knn_regression_2.html",
    "title": "KNN regression",
    "section": "",
    "text": "Now that you’ve implemented KNN regression, you will work on incorporating categorical features. Thankfully, you shouldn’t have to modify anything about your .knn() function!\nWe will continue to work with the mite_dat data, but will now extend the predictors to include Substrate, Shrub and Topo.\n\nlibrary(tidyverse)\nlibrary(vegan) \ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "implementations/implementation_knn_regression_2.html#assignment",
    "href": "implementations/implementation_knn_regression_2.html#assignment",
    "title": "KNN regression",
    "section": "Assignment",
    "text": "Assignment\nRecall the slides from the first week of class where we did some EDA exploring the relationship between each predictor and the abundance of the mites. The whole class was of the opinion that the categorical predictors might be more useful than the quantitative predictors for predicting the abundance. We will explore that here!\n\n\n\n\n\n\nNote\n\n\n\n\n\nI have added a new .Rmd file to your knn_regression GitHub project. We will now practice pulling changes from GitHub to your local machine.\n\n\n\n\nIn the file called knn_regresssion2.Rmd, copy and paste your .knn() function (and any accompanying functions) into the appropriate code chunk.\n\n\nCreate new data frame\n\nCreate a new data frame mite_dat2 that holds the original quantitative variables and response, and the appropriately encoded versions of the three categorical predictors.\n\n\n\nSplit into train/test sets\nThe following code splits the original data into a train set and a test set. As a group, discuss what each line of code is doing.\nCopy and paste this code into your .Rmd file in the appropriate code chunk.\n\nset.seed(1)\nn <- nrow(mite_dat2) \ntrain_ids <- sample(1:n, size = 0.7*n)\ntrain_dat <- mite_dat2[train_ids,]\ntest_dat <- mite_dat2[-train_ids,]\n\n\n\nRun KNN using all features\n\nWith \\(K = 5\\) neighbors, use your .knn() function to obtain predictions for the test data using all the predictors. Report your RMSE for the test data.\n\n\n\nRun KNN using quantitative features only\n\nNow use your .knn() function to obtain predictions for the test data using only the quantitative predictors WatrCont and SubsDens. Still use \\(K = 5\\) neighbors. Report your RMSE for the test data.\n\n\n\nRun KNN using categorical features only\n\nNow use your .knn() function to obtain predictions for the test data using only the encoded categorical predictors. Still use \\(K = 5\\) neighbors. Report your RMSE for the test data.\n\n\n\nDiscussion\n\nCompare and contrast the RMSEs from the three models you fit. What are you surprised or not surprised by? What do you think explains or contributes to the results you obtained?\n\nUsing the same test/train split and encodings, I also fit a fourth model where I used all the predictors but standardized the quantitative predictors. I obtained an RMSE of roughly 6.5 for the test data.\n\nComment on how this fourth RMSE compares to the ones you obtained. Are you surprised by this result? Why or why not? What do you think explains this result?"
  },
  {
    "objectID": "implementations/implementation_knn_regression_2.html#submission",
    "href": "implementations/implementation_knn_regression_2.html#submission",
    "title": "KNN regression",
    "section": "Submission",
    "text": "Submission\nOnce you’ve finished, push your changes to GitHub. Upload the finished PDF to Canvas."
  },
  {
    "objectID": "slides/slides-05-validation.html#resampling",
    "href": "slides/slides-05-validation.html#resampling",
    "title": "Validation",
    "section": "Resampling",
    "text": "Resampling\n\nEconomically use a collected dataset by repeatedly drawing samples from the same training dataset and fitting a model of interest on each sample\n\nObtain additional information about the fitted model\n\nTwo methods: cross-validation and the bootstrap\nThese slides will focus on the following topics of cross-validation:\n\nValidation set\nLOOCV\nk-fold CV (another k!)"
  },
  {
    "objectID": "slides/slides-05-validation.html#training-vs-test-errors",
    "href": "slides/slides-05-validation.html#training-vs-test-errors",
    "title": "Validation",
    "section": "Training vs Test errors",
    "text": "Training vs Test errors\n\nRecall the distinction between the training and test datasets\n\nTraining data: used to fit model\nTest data: used to test/evaluate the model\n\nThese two datasets result in two types of error:\n\nTraining error: average error resulting from using the model to predict the responses for the training data\nTest error: average error from using the model to predict the responses on new, “unseen” observations\n\nTraining error is often very different from test error"
  },
  {
    "objectID": "slides/slides-05-validation.html#validation-set-approach",
    "href": "slides/slides-05-validation.html#validation-set-approach",
    "title": "Validation",
    "section": "Validation set approach",
    "text": "Validation set approach\n\nWe have been using a validation set approach: randomly divide (e.g. 50/50) the available data into two parts: a training set and a test/validation/hold-out set\n\nModel is fit on training set\nFitted model predicts responses for the observations in the validation set\n\nThe resulting validation-set error provides an estimate of the test error (e.g. RMSE)"
  },
  {
    "objectID": "slides/slides-05-validation.html#validation-set-approach-drawbacks",
    "href": "slides/slides-05-validation.html#validation-set-approach-drawbacks",
    "title": "Validation",
    "section": "Validation set approach: drawbacks",
    "text": "Validation set approach: drawbacks\n\nOur estimate for test error will depend on the observations that are included in the training and validation sets\n\nValidation estimate of test error can be highly variable\n\nOnly a subset of the available data are used to fit the model\n\ni.e. fewer observations used to fit model might lead to overestimating test error rate"
  },
  {
    "objectID": "slides/slides-05-validation.html#leave-one-out-cross-validation-1",
    "href": "slides/slides-05-validation.html#leave-one-out-cross-validation-1",
    "title": "Validation",
    "section": "Leave-One-Out Cross-Validation",
    "text": "Leave-One-Out Cross-Validation\n\nLeave-one-out cross-validation (LOOCV) attempts to address the drawbacks from validation set approach\nWe still split all observations into two sets: training and validation\nKey difference: instead of splitting just once, we split many times, where one observation is used for the validation set, leaving the remaining \\(n-1\\) observations for training set"
  },
  {
    "objectID": "slides/slides-05-validation.html#loocv-method",
    "href": "slides/slides-05-validation.html#loocv-method",
    "title": "Validation",
    "section": "LOOCV: method",
    "text": "LOOCV: method\n\nStart by choosing first observation \\((x_{1}, y_{1})\\) to be validation set, and fit model on remaining \\(\\{(x_{2}, y_{2}), (x_{3}, y_{3}), \\ldots, (x_{n}, y_{n}) \\}\\) as our training set\nObtain \\(\\text{RMSE}_{1} = \\sqrt{(y_{1} -\\hat{y}_{1})^2}\\), an approximately unbiased estimate for test error\nRepeat procedure by selecting the second observation to be validation set, then third, etc.\nWill end up with \\(n\\) errors: \\(\\text{RMSE}_{1}, \\text{RMSE}_{2}, \\ldots, \\text{RMSE}_{n}\\). Then LOOCV estimate for test RMSE is the average:\n\n\n\\[\\text{CV}_{(n)} = \\frac{1}{n}\\sum_{i=1}^{n} \\text{RMSE}_{i}\\]"
  },
  {
    "objectID": "slides/slides-05-validation.html#discuss",
    "href": "slides/slides-05-validation.html#discuss",
    "title": "Validation",
    "section": "Discuss",
    "text": "Discuss\n\nSuppose I am fitting a simple linear regression model \\(Y = \\beta_{0} + \\beta_{1}X + \\epsilon\\).\nI want to obtain an estimate of the test error using LOOCV\nDiscuss exactly how you would implement this in code. Specific things to mention:\n\nWhat “actions”/functions you would use, and in what order\nWhat values you would compute\nWhat values you would store\n\n\nLive code"
  },
  {
    "objectID": "slides/slides-05-validation.html#loocv-pros-and-cons",
    "href": "slides/slides-05-validation.html#loocv-pros-and-cons",
    "title": "Validation",
    "section": "LOOCV pros and cons",
    "text": "LOOCV pros and cons\n\n\n\nPros\n\nEach training set has \\(n-1\\) observations \\(\\rightarrow\\) tend to not overestimate test error as much\nThere is no randomness in how the original data is split\n\n\n\n\nCons\n\nLOOCV can be expensive to implement – must fit the model \\(n\\) times\nEstimates for each validation set \\(i\\) are highly correlated, so the average can have high variance"
  },
  {
    "objectID": "slides/slides-05-validation.html#k-fold-cross-validation-1",
    "href": "slides/slides-05-validation.html#k-fold-cross-validation-1",
    "title": "Validation",
    "section": "k-fold Cross-Validation",
    "text": "k-fold Cross-Validation\n\nIn k-fold CV, the observations are randomly divided into \\(k\\) partitions (or folds) of approximately equal size.\nFor each \\(j\\) in \\(1, 2, \\ldots, k\\):\n\nLeave out \\(j\\)-th partition/fold as validation set, and fit model on remaining \\(k-1\\) partitions (combined)\nPredict for all observations in the held-out \\(j\\)-th fold, and obtain a corresponding \\(\\text{RMSE}_{j}\\)\n\nThe \\(k\\)-fold CV estimate of the test error is the average:\n\n\n\\[\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{j=1}^{k} \\text{RMSE}_{j}\\]"
  },
  {
    "objectID": "slides/slides-05-validation.html#k-fold-cv-cont.",
    "href": "slides/slides-05-validation.html#k-fold-cv-cont.",
    "title": "Validation",
    "section": "k-fold CV (cont.)",
    "text": "k-fold CV (cont.)\n\nLetting the \\(j\\)-th fold have \\(n_{j}\\) observations:\n\n\n\\[\\text{RMSE}_{j} = \\sqrt{\\frac{1}{n_{j}}\\sum_{i \\in \\mathcal{C}_{j}} (y_{i} - \\hat{y}^{(j)}_{i})^2},\\]\n\n\nwhere \\(\\mathcal{C}_{j}\\) is set of observations in the \\(j\\)-th fold, so \\(i\\) indexes the observations in \\(\\mathcal{C}_{j}\\). \\(\\hat{y}^{(j)}_{i}\\) is the prediction for \\(i\\)-th observation, obtained from data with part \\(j\\) removed\n\n\nIf \\(n\\) is a multiple of \\(k\\), then \\(n_{j} = \\frac{n}{k}\\)"
  },
  {
    "objectID": "slides/slides-05-validation.html#visual",
    "href": "slides/slides-05-validation.html#visual",
    "title": "Validation",
    "section": "Visual",
    "text": "Visual\n\nImportant: k is the number of folds/partitions, not the number of observations within each fold!"
  },
  {
    "objectID": "slides/slides-05-validation.html#example-varying-k",
    "href": "slides/slides-05-validation.html#example-varying-k",
    "title": "Validation",
    "section": "Example: varying k",
    "text": "Example: varying k\nI fit the linear model abundance = \\(\\beta_{0} + \\beta_{1}\\) WatrCont + \\(\\beta_{2}\\) SubsDens and obtain estimates of the test RMSE using k-fold CV for varying k:"
  },
  {
    "objectID": "slides/slides-05-validation.html#validation-remarks",
    "href": "slides/slides-05-validation.html#validation-remarks",
    "title": "Validation",
    "section": "Validation: remarks",
    "text": "Validation: remarks\n\nLOOCV is a special case of \\(k\\)-fold CV.\n\nQuestion: Which value of \\(k\\) yields LOOCV?\n\n\\(k\\)-fold CV estimate is still biased upward; bias minimized when \\(k = n\\)\n\n\\(k = 5\\) or \\(k=10\\) often used as a compromise for bias-variance tradeoff\n\nLOOCV and \\(k\\)-fold CV are useful and commonly used because of their generality"
  },
  {
    "objectID": "slides/slides-bootstrap.html#resampling",
    "href": "slides/slides-bootstrap.html#resampling",
    "title": "Bootstrap",
    "section": "Resampling",
    "text": "Resampling\n\nEconomically use a collected dataset by repeatedly drawing samples from the same training dataset and fitting a model of interest on each sample\n\nObtain additional information about the fitted model\n\nTwo methods: cross-validation and the bootstrap\nThese slides will focus on thebootstrap"
  },
  {
    "objectID": "slides/slides-bootstrap.html#the-bootstrap-1",
    "href": "slides/slides-bootstrap.html#the-bootstrap-1",
    "title": "Bootstrap",
    "section": "The Bootstrap",
    "text": "The Bootstrap\n\nThe bootstrap is a flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method\nExample: can be used to estimate the standard errors of the \\(\\beta\\) coefficients in linear regression\nOne goal of statistics: learn about a population.\n\nUsually, population is not available, so must make inference from sample data\n\nBootstrapping operates by resampling this sample data to create many simulated samples"
  },
  {
    "objectID": "slides/slides-bootstrap.html#the-bootstrap-cont.",
    "href": "slides/slides-bootstrap.html#the-bootstrap-cont.",
    "title": "Bootstrap",
    "section": "The Bootstrap (cont.)",
    "text": "The Bootstrap (cont.)\n\nBootstrapping resamples the original dataset with replacement\nIf the original datset has \\(n\\) observations, then each bootstrap/resampled dataset also has \\(n\\) observations\n\nEach observation has equal probability of being included in resampled dataset\nCan select an observation more than once for a resampled dataset"
  },
  {
    "objectID": "slides/slides-bootstrap.html#example",
    "href": "slides/slides-bootstrap.html#example",
    "title": "Bootstrap",
    "section": "Example",
    "text": "Example\n\nSuppose a study on adult daily caffeine consumption (mg) collects 4 data points: 110, 130, 150, 200. I want to learn about the average consumption in adults.\nCreate my first bootstrap sample:\n\n\ndat <- c(110, 130, 150, 200)\nn <- length(dat)\n\nsamp1 <- sample(x = dat, size = n, replace = T)\nsamp1\n\n[1] 200 110 150 200\n\n\n\nObtain our first estimate for \\(\\mu\\), the population mean daily caffeine consumption in adults: \\(\\hat{\\mu}_{1} = 165\\)"
  },
  {
    "objectID": "slides/slides-bootstrap.html#example-cont.",
    "href": "slides/slides-bootstrap.html#example-cont.",
    "title": "Bootstrap",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nTake second sample:\n\n\nsamp2 <- sample(x = dat, size = n, replace = T)\nsamp2\n\n[1] 200 200 130 130\n\n\n\n\\(\\hat{\\mu}_{2} = 165\\)\nRepeat this process thousands of times!\n…\n\n\n\n\n\nAfter 1000 bootstrap samples, we end up with 1000 estimates for \\(\\mu\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean over all estimates is \\(\\hat{\\mu} = 148.2725\\)\nApproximate 95% confidence interval for the mean are the 5% and 95% quantiles of the 1000 mean estimates: (120, 182.5)\n\nCalled a bootstrap percentile confidence interval\n\n2/3"
  },
  {
    "objectID": "slides/slides-bootstrap.html#bootstrap-pros-and-cons",
    "href": "slides/slides-bootstrap.html#bootstrap-pros-and-cons",
    "title": "Bootstrap",
    "section": "Bootstrap: pros and cons",
    "text": "Bootstrap: pros and cons\n\nReal world vs bootstrap world\nPros:\n\nNo assumptions about distribution of your data\nVery general method that allows estimating sampling distribution of almost any statistic!\nCost-effective\n\nCons:\n\nIn more complex scenarios, figuring out appropriate way to bootstrap may require thought\nCan fail in some situations\nRelies quite heavily on the original sample"
  },
  {
    "objectID": "live-code/live-code-loocv.html",
    "href": "live-code/live-code-loocv.html",
    "title": "Live code:",
    "section": "",
    "text": "Data\n\nlibrary(tidyverse)\nlibrary(vegan)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)\n\n\n\nLOOCV\n\nn <- nrow(mite_dat)\nrmses <- rep(NA, n)\nfor(i in 1:n){\n  train_dat <- mite_dat[-i,]\n  test_dat <- mite_dat[i,]\n  mod <- lm(abundance ~ WatrCont, data = train_dat)\n  pred <- predict(mod, newdata = test_dat)\n  rmses[i] <- sqrt((test_dat$abundance - pred)^2)\n}\nloocv_err <- mean(rmses)\nloocv_err\n\n[1] 9.513248\n\n\nHow does this compare to when I take a usual validation set approach?\n\nset.seed(2)\ntrain_ids <- sample(n, 0.7 * n)\ntrain_dat <- mite_dat[train_ids,]\ntest_dat <- mite_dat[-train_ids,]\nmod <- lm(abundance ~ WatrCont , data = train_dat)\npred <- predict(mod, newdata = test_dat)\nrmse_val <- sqrt(mean((test_dat$abundance - pred)^2))\nrmse_val\n\n[1] 10.73352\n\n\nAlso, if you run with different seeds, you will get different estimated RMSEs!"
  },
  {
    "objectID": "labs/lab-03-cross-validation.html",
    "href": "labs/lab-03-cross-validation.html",
    "title": "Lab 03: Cross-validation",
    "section": "",
    "text": "The data and .Rmd file can be found in your lab-03-ski-resorts GitHub project. Please clone it now! The data is ski_resorts.csv, and come from Kaggle.\nWe have data on ski resorts on the east coast. Each observation is a ski resort, and we information about the features of each resort (e.g. number of lifts, price of ticket, average elvation). A data dictionary can be found in the README.\n\nski_resorts <- read.csv(\"data/ski_resorts.csv\")\n\nWe will compare two models’ prediction performance for the lift ticket price of these ski resorts using all the other quantitative variables as our predictors. We will compare the models via the estimated test RMSE obtained using k-fold cross-validation. The two models are:\n\nA multiple linear regression model, and\nA KNN regression model\n\nThis lab will also explore the effect of standardizing quantitative variables.\nNow that you’ve implemented KNN regression and understand how it works, you are allowed to use the knnreg() R function provided in the caret library! This function is much faster than our own implementations.\n\n\n\n\n\n\nWarning\n\n\n\nSome people are having issues with installing the caret package. It may be safer to use your own implementation!\n\n\nTo use knnreg():\n\nInstall the caret package in your console\nLoad in the caret package at the top of your .Rmd file\nThe knnreg() function works slightly differently than our implementation. It only fits a model to the training data, where you pass in a train_x and a train_y. Then to obtain prediction, you use the predict() function, just as you would for linear regression.\n\nBy default, the knnreg() chooses a neighbor set of \\(K = 5\\). If you want a different choice of neighbors, you must explicitly pass that into the argument k.\nThe train_y you pass into knnreg() must be a vector, not a data frame!\n\n\n\n# suppose my train data are stored as train_x and train_y\n# suppose my test predictors are stores as test_x\nknn_mod <- knnreg(x= train_x, y = train_y, k = 7)\npreds <- predict(knn_mod, newdata = test_x)\n\nThis is a challenging lab assignment because there are a lot of moving parts! Please do not put it off until the last minute!"
  },
  {
    "objectID": "labs/lab-03-cross-validation.html#define-functions",
    "href": "labs/lab-03-cross-validation.html#define-functions",
    "title": "Lab 03: Cross-validation",
    "section": "Define functions",
    "text": "Define functions\nTo make our lives easier, we will write a function that standardizes data for you. Create a function called my_scale() that takes in three arguments:\n\nA data frame (or matrix) that needs to be standardized,\nA vector of means, where element \\(j\\) is the mean of the \\(j\\)-th column of (1), and\nA vector of standard deviations where element \\(j\\) is the standard deviation of the \\(j\\)-th column of (1)\n\nYour function my_scale() should return a standardized version of the data frame that was input. The R function sd() takes a vector as input and outputs the standard deviation.\n\n\n\nYou can confirm your my_scale() function is working by seeing if you get the same results as when you use the scale() function provided by R on the following data temp (you can also confirm if your mean_vec and sd_vec are correct by looking at the attributes center and scale in the following output):\n\ntemp <- data.frame(x = 1:5) %>%\n  mutate(y = sqrt(x))\nscale(temp)\n\n              x          y\n[1,] -1.2649111 -1.3900560\n[2,] -0.6324555 -0.5388977\n[3,]  0.0000000  0.1142190\n[4,]  0.6324555  0.6648219\n[5,]  1.2649111  1.1499128\nattr(,\"scaled:center\")\n       x        y \n3.000000 1.676466 \nattr(,\"scaled:scale\")\n        x         y \n1.5811388 0.4866469 \n\n\n\n\n\n\n\n\nNote\n\n\n\nPlease do not include code that tests your my_scale() function in your final submission."
  },
  {
    "objectID": "labs/lab-03-cross-validation.html#analysis",
    "href": "labs/lab-03-cross-validation.html#analysis",
    "title": "Lab 03: Cross-validation",
    "section": "Analysis",
    "text": "Analysis\nWe will fit a total of four different models using k-fold cross-validation. For all the models, we will predict the price of the lift tickets using all of the remaining quantitative variables. In order to have a fair comparison of the models, each model should be fit and tested on the same folds/partitions of the original data. Therefore, we will begin by creating a set of indices that tell us which fold each observation belongs to.\nI suggest you modify your data such that it only contains the variables of interest for this analysis!\n\n\n\n\nObtain the indices for each fold\nWe will perform 5-fold cross-validation.\n\nRandomly split the indices of the observations into 5 folds of equal size. Because you will be randomly splitting, it is important for you to set a seed for reproducibility. Use a seed of 3. Hint: you will most likely need to use a list!\n\n\n\n\n\n\nMLR: original scale\nUsing your folds in the previous step, run 5-fold CV to obtain an estimate of the test RMSE using MLR.\nNote: suppose you are running lm() and the data you pass in only contains the response y and all of the predictors of interest. Rather than explicitly typing out the name of each predictor in lm(), you can simply type a . and R will recognize that you want to use all the other variables aside from y in the data frame as predictors:\n\nlm(y ~ ., data)\n\n\n\n\n\nReport your estimated test RMSE from running MLR with 5-fold CV.\n\n\n\nKNN: original scale\nUsing the same folds, run 5-fold CV to obtain an estimate of the test RMSE using KNN regression, with \\(K = 10\\) neighbors. You may either use your own implementation of KNN, or you may use the knnreg() + predict() functions provided in R.\n\n\n\n\nState the number of neighbors, and report your estimated test RMSE from running KNN regression with 5-fold CV. How does your estimated test RMSE compare to that obtained from MLR?\n\n\n\nKNN regression: standardized data\nNow, we will run KNN regression where the predictors are standardized. Using the same folds, run 5-fold CV to obtain an estimate of the test RMSE using KNN regression on the standardized data. You should use your my_scale() function, and the same number of neighbors as in the previous section!\nRemember that we should first standardize on the train data, and then use the mean and standard deviations from that standardization to standardize the test data!\n\n\n\n\nState the number of neighbors, and report your estimated test RMSE from running KNN regression with 5-fold CV on the standardized predictors. How does your estimated test RMSE compare to the two previous test RMSEs?\n\n\n\nMLR: standardized data\nFinally, we will run MLR regression where the predictors are standardized. Using the same folds, run 5-fold CV to obtain an estimate of the test RMSE using MLR on the standardized data. You should use your my_scale() function!\n\n\n\n\nReport your estimated test RMSE from running MLR with 5-fold CV on the standardized data. How does your estimate here compare to that obtained from running MLR on the non-standardized data?"
  },
  {
    "objectID": "labs/lab-03-cross-validation.html#comprehension-questions",
    "href": "labs/lab-03-cross-validation.html#comprehension-questions",
    "title": "Lab 03: Cross-validation",
    "section": "Comprehension questions",
    "text": "Comprehension questions\n\nBased on your results, if you had to recommend a model for the price of lift tickets, which model would you choose and why?\nIf you ran this analysis again with a different choice of seed in set.seed(), what would you expect to change and why? What would you expect to stay the same and why?\nIf you ran this analysis again with a larger number of folds, how would you expect the estimated test RMSEs to change? Why?\nI mentioned that the fair way to compare models is to use the same folds/partitions for all models. Briefly explain why that is.\nBased on your results for the two linear regression models, what might be one advantage of fitting a linear regression model compared to a KNN regression model?"
  },
  {
    "objectID": "labs/lab-03-cross-validation.html#submission",
    "href": "labs/lab-03-cross-validation.html#submission",
    "title": "Lab 03: Cross-validation",
    "section": "Submission",
    "text": "Submission\nWhen you’re finished, knit + commit + push to GitHub one last time. Then submit your knitted pdf to Canvas!"
  },
  {
    "objectID": "live-code/live-code-lists.html",
    "href": "live-code/live-code-lists.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "live-code/live-code-lists.html#lists",
    "href": "live-code/live-code-lists.html#lists",
    "title": "Live code:",
    "section": "Lists",
    "text": "Lists\nLists are simply another data object in R. List can hold elements of different types, such as vectors, strings, and numbers, and even more lists! We create a list using the list() function.\n\nmy_list <- list(\"stat\", c(2,1,8))\n\nThis produces the following result:\n\nmy_list\n\n[[1]]\n[1] \"stat\"\n\n[[2]]\n[1] 2 1 8\n\n\nThat’s great! Lists behave similar to, but not exactly like, vectors. You can find the length of the vector:\n\nlength(my_list)\n\n[1] 2\n\n\nAlso, it would be extremely useful to be able to access each element of my_list. However, if we were to use the usual [ ] notation to index, notice what happens:\n\nmy_list[2]\n\n[[1]]\n[1] 2 1 8\n\n\nThis output isn’t a vector; it’s still a list, so I cannot do math on it! The following code wouldn’t work:\n\n2 * my_list[2]\n\nInstead, to access each item in a list, we need to use double brackets, i.e. [[ ]]:\n\nmy_list[[2]]\n\n[1] 2 1 8\n\n\nNow we can work with the vector as normal\n\n2 * my_list[[2]]\n\n[1]  4  2 16\n\n\nStoring items into lists will also require the double brackets. For example,\n\nmy_list[[3]] <- 5\nmy_list\n\n[[1]]\n[1] \"stat\"\n\n[[2]]\n[1] 2 1 8\n\n[[3]]\n[1] 5\n\n\nWhy are we working with lists? We’ll need them for k-fold CV!"
  },
  {
    "objectID": "live-code/live-code-lists.html#apply",
    "href": "live-code/live-code-lists.html#apply",
    "title": "Live code:",
    "section": "apply()",
    "text": "apply()\nA useful function is the apply() function, which applies the same function to either ALL the rows or ALL the columns. It takes three arguments: what R object you want to apply the function two, by row (1) or by column (2), and the function itself.\nIn the following code, I am applying the mean function to each column of dat. Notice that I get back a vector of column means!\n\ndat <- data.frame(x = 1:10, y = 11:20)\napply(dat, 2, mean)\n\n   x    y \n 5.5 15.5"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#tree-based-methods-1",
    "href": "slides/slides-06-regression-trees-01.html#tree-based-methods-1",
    "title": "Regression Trees",
    "section": "Tree-based methods",
    "text": "Tree-based methods\n\nThese methods use a series of if-then rules to divide/segment the predictor space into a number of simple regions\nThe splitting rules can be summarized in a tree, so these approaches are known as decision-tree methods\nCan be simple and useful for interpretation\nDecision trees can be applied to both regression and classification problems\nTypically not competitive with the best supervised learning approaches in terms of prediction accuracy"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#mite-data",
    "href": "slides/slides-06-regression-trees-01.html#mite-data",
    "title": "Regression Trees",
    "section": "Mite data",
    "text": "Mite data\n\n\nWe will begin by showing the results of a regression tree, then we will discuss how to build one"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#mite-data-regression-tree",
    "href": "slides/slides-06-regression-trees-01.html#mite-data-regression-tree",
    "title": "Regression Trees",
    "section": "Mite data: regression tree",
    "text": "Mite data: regression tree"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#terminology",
    "href": "slides/slides-06-regression-trees-01.html#terminology",
    "title": "Regression Trees",
    "section": "Terminology",
    "text": "Terminology\n\nInternal nodes: points along the tree where the predictor space is split\n\nSix internal nodes on previous slide\n\nFirst node is often referred to as root node\nTerminal nodes or leaves: regions where there is no further splitting\n\nSeven terminal nodes on previous slide\nThe value in each terminal node is the value we predict for an observation that follows the path in predictor space to that terminal node\nDecision trees are typically drawn upside down (leaves at bottom)\n\nAny subnode of a given node is called a child node, and the given node, in turn, is the child’s parent node."
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#draw-partitions",
    "href": "slides/slides-06-regression-trees-01.html#draw-partitions",
    "title": "Regression Trees",
    "section": "Draw partitions",
    "text": "Draw partitions"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#interpretation-of-results",
    "href": "slides/slides-06-regression-trees-01.html#interpretation-of-results",
    "title": "Regression Trees",
    "section": "Interpretation of results",
    "text": "Interpretation of results\n\nExtremely rough interpretation!!\nWatrCont may be most important factor for determining the abundance of mites (among these two predictors)\nEnvironments with low WatrCont tend to have very low abundances, as do environments with high SubsDens\nLikely an oversimplification of the true relationships, but easy to display and interpret"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#building-and-using-regression-tree",
    "href": "slides/slides-06-regression-trees-01.html#building-and-using-regression-tree",
    "title": "Regression Trees",
    "section": "Building and using regression tree",
    "text": "Building and using regression tree\n\nTraining/fitting model: Divide predictor space (the set of possible values for \\(X_{1}, \\ldots, X_{p}\\)) into \\(M\\) distinct and non-overlapping regions, \\(R_{1}, \\ldots, R_{M}\\)\nPrediction/using model: For every observation that lands in \\(R_{m}\\), we output the same predicted \\(\\hat{y}\\): the mean of the training responses in \\(R_{m}\\): \\[\\hat{y}_{R_{m}} = \\frac{1}{n_{m}} \\sum_{i \\in R_{m}} y_{i}\\]"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#fitting-a-regression-tree",
    "href": "slides/slides-06-regression-trees-01.html#fitting-a-regression-tree",
    "title": "Regression Trees",
    "section": "Fitting a regression tree",
    "text": "Fitting a regression tree\n\nIn theory, regions \\(R_{1},\\ldots, R_{M}\\) could have any shape. For simplicity, we divde predictor space into high-dimensional rectangles or boxes\nGoal: to train the model, we want to find boxes \\(R_{1},\\ldots, R_{M}\\) that minimize the residual sum of squares (RSS), given by \\[\\sum_{m=1}^{M} \\sum_{i\\in R_{m}} (y_{i} - \\hat{y}_{R_{m}})^2,\\]\nwhere \\(\\hat{y}_{R_{m}}\\) is the predicted/fitted value for \\(y_{i} \\in R_{m}\\) in the training data\nUnfortunately, it is computationally infeasible to consider every possible partition of the feature space into \\(M\\) boxes!"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#fitting-a-regression-tree-cont.",
    "href": "slides/slides-06-regression-trees-01.html#fitting-a-regression-tree-cont.",
    "title": "Regression Trees",
    "section": "Fitting a regression tree (cont.)",
    "text": "Fitting a regression tree (cont.)\n\nWe take a top-down, greedy approach known as recursive binary splitting\n“Top-down”: we begin at the top of tree where all observations belong to a single region, and then successively partition\n“Greedy”: at each step, the best split is made at that current snap-shot in time, rather than looking ahead and picking a split that would be better in some future step\nNote: at every stage of the tree, all predictors are candidates for the decision split (e.g. in mite data, WatrCont was first split, but showed up later down the tree)\nContinue making splits on the data as we go"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#details",
    "href": "slides/slides-06-regression-trees-01.html#details",
    "title": "Regression Trees",
    "section": "Details",
    "text": "Details\n\nAt very beginning of model fit, all observations belong in a single region. We must decide the first split/cut-point\nWe select the predictor \\(X_{j}\\) and the cutpoint value \\(c\\) such that splitting the predictor space into the regions \\(\\{X | X_{j} < c\\}\\) and \\(\\{X | X_{j} \\geq c\\}\\) leads to lowest RSS\n\ni.e., for any predictor \\(j\\) and cutpoint \\(c\\), we define the pair\n\\[S_l(j,c) = \\{X | X_{j} < c\\} \\text{ and } S_{r}(j,c) = \\{X | X_{j} \\geq c\\}\\]\n\nWe seek the values of \\((j, c)\\) that minimize \\[\\sum_{i:x_{i}\\in S_l(j,c)} (y_{i} - \\hat{y}_{S_{l}})^2 + \\sum_{i:x_{i}\\in S_r(j,c)} (y_{i} - \\hat{y}_{S_{r}})^2,\\]\nwhere \\(\\hat{y}_{S_{l}}\\) is the average of the training responses in \\(S_l(j,s)\\)"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#what-are-the-cut-points",
    "href": "slides/slides-06-regression-trees-01.html#what-are-the-cut-points",
    "title": "Regression Trees",
    "section": "What are the cut-points?",
    "text": "What are the cut-points?\nConsider some hypothetical data, where I have a single predictor x and a response variable y:\n\n\n   x y\n1  0 1\n2  3 2\n3  4 3\n4 10 4\n\n\n\nOnly makes sense to split the data based on the observed values of x\n\ni.e. splitting on x < 15 is silly\n\nNotice that choosing a cut-point of \\(c = 1\\) or \\(c= 2\\) leads to same partition of the data, and therefore same RSS\nSo we consider cutpoints as the mean between consecutive values of observed x:\n\nExamine RSS for \\(c = \\{1.5, 3.5, 7\\}\\)"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#return-to-mite-data",
    "href": "slides/slides-06-regression-trees-01.html#return-to-mite-data",
    "title": "Regression Trees",
    "section": "Return to mite data",
    "text": "Return to mite data\n\n\n\n\n\n\n\n\n\n\n\nAt step one of the tree, all 70 observations are together. Deciding first split means considering all of the following:\nSplitting on SubsDens (\\(j = 1\\)):\n\n\\(S_{l}(1,21.765) = \\{\\mathbf{X} | \\text{SubsDens} < 21.765\\}\\) and \\(S_{r}(1, 21.765) = \\{\\mathbf{X} | \\text{SubsDens} \\geq 21.765 \\}\\)\n\\(S_{l}(1, 22.63) = \\{\\mathbf{X} | \\text{SubsDens} < 22.63\\}\\) and \\(S_{r}(1, 22.63) = \\{\\mathbf{X} | \\text{SubsDens} \\geq 22.63\\}\\)\n…\n\nSplitting on WatrCont (\\(j = 2\\)):\n\n\\(S_{l}(2, 139.705) = \\{\\mathbf{X} | \\text{WatrCont} < 139.705\\}\\) and \\(S_{r}(2, 139.705) = \\{\\mathbf{X} | \\text{SubsDens} \\geq 139.705\\}\\)\n\\(S_{l}(2, 145.48) = \\{\\mathbf{X} | \\text{WatrCont} < 145.48\\}\\) and \\(S_{r}(2, 145.48) = \\{\\mathbf{X} | \\text{SubsDens} \\geq 145.48\\}\\)\n…"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#mini-implementation",
    "href": "slides/slides-06-regression-trees-01.html#mini-implementation",
    "title": "Regression Trees",
    "section": "Mini implementation",
    "text": "Mini implementation\n\n\n\n\nLet’s compute the RSS for a few of these candidate splits. Live code!\nWhen splitting on SubsDens < 22.63, we get the following RSS:\n\n\n\n\n[1] 11058.76\n\n\n\n\nWhen splitting on WatrCont < 145.48, we get an RSS of:\n\n\n\n\n[1] 10876.12"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#mini-implementation-cont.",
    "href": "slides/slides-06-regression-trees-01.html#mini-implementation-cont.",
    "title": "Regression Trees",
    "section": "Mini implementation (cont.)",
    "text": "Mini implementation (cont.)\n\n\nDoing this for all possible splits, we get the following SSRs:\n\n\n\n\n\n\n\n\n\n\n\n\nThe split that resulted in lowest RSS out of all these possible splits is splitting on WatrCont < 323.54, which is what we saw in the tree!"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#details-cont.",
    "href": "slides/slides-06-regression-trees-01.html#details-cont.",
    "title": "Regression Trees",
    "section": "Details (cont.)",
    "text": "Details (cont.)\n\nThen, repeat the process of looking for the best predictor and best cut-point in order to split the data further so as to minimize RSS within each of the resulting regions\nInstead of splitting entire predictor space, we split one of the two previously identified regions\nNow we have three regions\nAgain, split one of these further so as to minimize RSS. We continue this process until a stopping criterion is reached"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#categorical-predictors",
    "href": "slides/slides-06-regression-trees-01.html#categorical-predictors",
    "title": "Regression Trees",
    "section": "Categorical predictors",
    "text": "Categorical predictors\n\nWe can also split on qualitative predictors!\nIf \\(X_{j}\\) is categorical variable with categories “1”, “2”, “3”, …, then candidate split regions would be:\n\n\\(S_{l}(j, ``1\") = \\{X | X_{j} = ``1\"\\} \\qquad \\text{ and } \\qquad S_{r}(j, ``1\") = \\{X | X_{j} \\neq ``1\"\\}\\)\n\\(S_{l}(j, ``2\") = \\{X | X_{j} = ``2\"\\} \\qquad \\text{ and } \\qquad S_{r}(j, ``2\") = \\{X | X_{j} \\neq ``2\"\\}\\)\n…\n\nNotice that if \\(X_{j}\\) has more than two levels, we would need to choose the level that yields the best split"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#mite-data-regression-tree-scroll",
    "href": "slides/slides-06-regression-trees-01.html#mite-data-regression-tree-scroll",
    "title": "Regression Trees",
    "section": "Mite data: regression tree (scroll)",
    "text": "Mite data: regression tree (scroll)\n\n\n\n\n\n\n\n\nTop split: observations with WatrCont < 323.54 are assigned to left branch\nObservations with WatrCont \\(\\geq\\) 323.54 are assigned to right branch, and are further subdivided by SubsDens and finer values of WatrCont\nFor a new observation, the predicted abundance of a location with WatrCont < 323.54 is 0.85\nRemarks:\n\nIf condition evaluates to true, we “go left”\nThe splits are always in terms of \\(<\\) for consistency"
  },
  {
    "objectID": "slides/slides-06-regression-trees-01.html#interpretation",
    "href": "slides/slides-06-regression-trees-01.html#interpretation",
    "title": "Regression Trees",
    "section": "Interpretation",
    "text": "Interpretation\n\nTop split: observations with WatrCont < 323.54 are assigned to left branch\nObservations with WatrCont \\(\\geq\\) 323.54 are assigned to right branch, and are further subdivided by SubsDens and finer values of WatrCont\nFor a new observation, the predicted abundance of a location with WatrCont < 323.54 is 0.85\nRemarks:\n\nIf condition evaluates to true, we “go left”\nThe splits are always in terms of \\(<\\) for consistency"
  },
  {
    "objectID": "live-code/live-code-regression-trees.html",
    "href": "live-code/live-code-regression-trees.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "live-code/live-code-regression-trees.html#mini-implementation",
    "href": "live-code/live-code-regression-trees.html#mini-implementation",
    "title": "Live code:",
    "section": "Mini implementation",
    "text": "Mini implementation\nWe will write code to understand how recursive binary splitting works. Specifically, we will pretend we are about to create the root node (i.e. first split) for a regression tree that uses WatrCont and SubsDens to predict abundance of the mites. We need to obtain the residual sum of squares (RSS) for each candidate split, and choose the split that yields the best (lowest) RSS at that step in the tree, where RSS is\n\\[\\sum_{i:x_{i}\\in S_l(j,c)} (y_{i} - \\hat{y}_{S_{l}})^2 + \\sum_{i:x_{i}\\in S_r(j,c)} (y_{i} - \\hat{y}_{S_{r}})^2,\\]\nand \\(\\hat{y}_{S_{l}}\\) is the average of the training responses in \\(S_l(j,s)\\)\nSo from this, we need to:\n\nDetermine if each observation goes left or right based on the condition\nObtain the average of the training responses in each side (\\(\\hat{y}_{S_{l}}\\) and \\(\\hat{y}_{S_{r}}\\))\nObtain the residual of each observation\nObtain the RSS from each set \\(S_{l}\\) and \\(S_{r}\\)\nObtain one single RSS, which is the sum of the two values in (4)\n\nWe saw that one candidate split was SubsDens < 22.63. Let’s see what the resulting RSS is from this split.\nMake sure you understand what each line of code is doing. If not, please ask!\n\nmite_dat%>%\n  mutate(decision = if_else(SubsDens < 22.63, \"left\", \"right\")) %>%\n  group_by(decision) %>%\n  mutate(y_hat = mean(abundance)) %>%\n  ungroup() %>%\n  mutate(sq_resid = (abundance - y_hat)^2) %>%\n  group_by(decision) %>%\n  summarise(rss = sum(sq_resid)) %>%\n  pull(rss) %>%\n  sum()\n\n[1] 11058.76\n\n\nIf instead we considered the candidate split WatrCont < 145.48:\n\nmite_dat%>%\n  mutate(decision = if_else(WatrCont < 145.48, \"left\", \"right\")) %>%\n  group_by(decision) %>%\n  mutate(y_hat = mean(abundance)) %>%\n  ungroup() %>%\n  mutate(sq_resid = (abundance - y_hat)^2) %>%\n  group_by(decision) %>%\n  summarise(rss = sum(sq_resid)) %>%\n  pull(rss) %>%\n  sum()\n\n[1] 10876.12\n\n\nNotice that we get a different candidate RSS!"
  },
  {
    "objectID": "live-code/live-code-regression-trees.html#coding-in-r",
    "href": "live-code/live-code-regression-trees.html#coding-in-r",
    "title": "Live code:",
    "section": "Coding in R",
    "text": "Coding in R\n\ntrees() function\nSimple regression trees can be implemented in R using the trees library (you may have to install) using the tree() function. The syntax is just as in lm():\n\n\n\n\n\n\nWarning\n\n\n\nNote: the tree() function we will use requires all categorical variables to be coded as factors. Additionally, no single categorical variable can have more than 32 levels.\n\n\n\nlibrary(tree)\n\ntree_mites <- tree(abundance ~ WatrCont + SubsDens + Topo,\n\n                   data = mite_dat)\n\nsummary(tree_mites)\n\n\nRegression tree:\ntree(formula = abundance ~ WatrCont + SubsDens + Topo, data = mite_dat)\nNumber of terminal nodes:  8 \nResidual mean deviance:  64.95 = 4027 / 62 \nDistribution of residuals:\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-23.0000  -3.3590  -0.8571   0.0000   2.4890  28.3300 \n\n\nAbove, lines 2-3 fit the regression trees for abundance using the three specified predictors from mite_dat data. Similar to lm(), we can wrap the tree object with summary() to get some more information about the model fit. We see number of terminal notes \\(|T_{0}|\\), the predictors that were used to build the tree, and residual mean deviance:\n\nIf you don’t see list of predictors, then the tree used all of them\nResidual mean deviance: \\(\\text{RSS}/(n - |T_{0}|)\\)\n\nTyping the name of the tree object prints the tree in text form:\n\n#| echo: true\n\ntree_mites\n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 70 11060.0 10.4300  \n   2) Topo: Blanket 44  7760.0 15.3200  \n     4) SubsDens < 48.165 33  5734.0 18.8800  \n       8) WatrCont < 308.725 5    33.2  2.6000 *\n       9) WatrCont > 308.725 28  4139.0 21.7900  \n        18) WatrCont < 386.835 5  1250.0 31.0000 *\n        19) WatrCont > 386.835 23  2372.0 19.7800  \n          38) SubsDens < 41.545 17  1074.0 18.4100  \n            76) WatrCont < 466.975 11   308.7 20.5500 *\n            77) WatrCont > 466.975 6   623.5 14.5000 *\n          39) SubsDens > 41.545 6  1175.0 23.6700 *\n     5) SubsDens > 48.165 11   352.5  4.6360 *\n   3) Topo: Hummock 26   467.4  2.1540  \n     6) WatrCont < 457.02 21   120.6  0.8571 *\n     7) WatrCont > 457.02 5   163.2  7.6000 *\n\n\nWe can interpret the tree as follows:\n\nThe * denotes a terminal node\nsplit: condition used to branch at the node\nn: the number of observations following the left-side of the branch\ndeviance: the deviance associated with that branch\nyval: predicted value at the node\n\n\n\nPlotting trees\nWe will use base R plots; I’m sure there are much more beautiful ggplot functions out there, but I’m not in the business of it today! We simply pass the tree object into plot():\n\nplot(tree_mites)\n\n\n\n\nNotice that there is no text! This isn’t helpful. We need to explicitly add the labels using the text() function:\n\nplot(tree_mites)\ntext(tree_mites, pretty = 0)\n\n\n\n\nThe argument pretty = 0 instructs R to include the category names for any qualitative predictors, rather than simply displaying a generic a, b, c… letter for each category.\n\n\n\n\n\n\nDanger\n\n\n\nIf you get an error when trying to use text(), it’s because text() doesn’t like it when your plot shows up inline. This shouldn’t be an issue when you knit. If you want to see your tree without knitting, go to the gear symbol at the top of the Rmarkdwon document, hit the down arrow, then hit “Chunk output in Console”. You’ll be prompted if you want to remove the current output (yes or not are both fine!) Then try running the code again."
  },
  {
    "objectID": "labs/lab-04-regression-trees.html",
    "href": "labs/lab-04-regression-trees.html",
    "title": "Lab 04: Regression trees",
    "section": "",
    "text": "The purpose of this lab is to gain familiarity and practice with fitting and evaluating regression trees in R. Go ahead and clone your new lab-04-forest-fires GitHub project. You will work with the .Rmd file called lab-04-forest-fires.Rmd\n\n\nFor this assignment, you will predict the size of forest fires in the northeast region of Portugal using meteorological and other covariates. The original data were obtained from the UCI Machine Learning Repository, and I have modified them slightly for the purposes of this implementation.\nEach row in the data set represents one fire. We have the following variables:\n\nfire_id: a variable to identify each fire\nX, Y: coordinates for the location of the fire\nmonth: month of year\nday: day of week\nFFMC: Fine Fuel Moisture Code, represents fuel moisture of forest litter fuels under the shade of a forest canopy\nDMC: Duff Moisture Code, represents fuel moisture of decomposed organic material underneath the litter\ndrought: drought status of location (“Low”, “Moderate”, “Extreme”)\nISI: Initial Spread Index, used to predict fire behavior\ntemp: temperature (Celsius)\nRH: relative humidity (%)\nwind: wind speed (km/h)\nrain: outside rain (mm/m2)\narea: the burned area of the forest (hectares). An area of 0 means that an area of lower than 100 square meters was burned.\n\n\n\n\nUsing regression trees, we will predict the size of a fire given some of these features. We will also compare prediction performance under different modeling choices."
  },
  {
    "objectID": "labs/lab-04-regression-trees.html#prepare-data",
    "href": "labs/lab-04-regression-trees.html#prepare-data",
    "title": "Lab 04: Regression trees",
    "section": "Prepare data",
    "text": "Prepare data\nThe data are in forest_fires.csv in your data folder of this project. We will also require the tidyverse and tree packages. Go ahead and load the data and libraries now.\nPlease save the data using the variable name fire_dat.\n\n\n\n\nWrangle\nWrangle your data to only retain observations from the months of March, July, August, and September, then remove month from the data set. Also, we will not consider the fire_id, day of week, nor geographic location as predictors. Lastly, recall that the tree() function requires all categorical variables to be coded as factors.\n\nModify your data to make all the required changes.\n\n\n\n\n\n\nEDA\n\nVisualize and describe the distribution of the burned `area`.\n\n\n\nWrangle (again)\nLastly, if you were to make a histogram of the response variable area, you would notice it is heavily right-skewed. One way to address this issue is to log-transform area. However, many observations have an observed area = 0, and the log of 0 is \\(-\\infty\\). A common way to get around this is to take the log of (response variable + 1).\n\nCreate a new data frame called fire_dat_log, where you over-write the area variable using the appropriate log transform described above.\n\n\n\n\n\nUsing your new fire_dat_log, create a summary table where for each level of drought, the table displays the mean and standard deviation of the log-burned area, and the total number of observations that fall into that level. Based on what you see, do you think drought will be an important variable in our regression tree? Why or why not?\n\n\n\n\n\n\n\nCommit reminder\n\n\n\n\n\nThis would be a good time to knit, commit, and push your changes to GitHub!"
  },
  {
    "objectID": "labs/lab-04-regression-trees.html#regression-tree-for-log-area",
    "href": "labs/lab-04-regression-trees.html#regression-tree-for-log-area",
    "title": "Lab 04: Regression trees",
    "section": "Regression tree for log area",
    "text": "Regression tree for log area\n\nTrain/test ids\nWe will compare a pruned regression tree to an unpruned regression tree to see if the pruning is actually helpful for predictions.\n\nUsing a seed of 346, split your fire_dat_log data into an 80% training set and a 20% test set.\n\n\n\n\n\n\nGrow large tree\n\nFit a regression tree to the training data for your logged area of the forest fires using all of the other variables as predictors. Explicitly let R grow a large tree by setting the control arguments in tree() to have minsize = 2 (see live code for refresher).\n\n\n\n\n\nDisplay a summary() of your regression tree. How many leaves are there? Was your intuition correct about whether or not drought would be an important predictor for the log burned area?\n\n\n\n\n\n\nCost-complexity pruning\nNow, we will prune back the tree using cost-complexity. Because we will be performing k-fold CV, we should set a seed again in order to have reproducibility of the assignment of observations to folds.\n\nSet a seed of 346 again, and perform cost-complexity pruning using 10-fold CV.\n\n\n\n\n\nFrom your output, make a plot of the size of the candidate pruned trees on the x-axis and the CV deviance estimates on the y-axis (see live code for example plot). Based on your plot, which size tree should we use?\n\n\n\n\n\n\nPrune the tree\n\nBased on your previous answer, prune your original tree to obtain the “best” tree. Plot the pruned tree. How does it compare to your original large tree in terms of the predictors used and number of leaves?\n\n\n\n\n\n\nModel comparison\nNow, compare your pruned and unpruned trees by making predictions on the test data. You can use the predict() function just like we did for linear regression, passing in the fitted model first and specifying the newdata argument.\n\nObtain and report the estimated test RMSEs from both models. Based on your results, did pruning seem to help? Why or why not?\n\n\n\n\n\n\n\n\n\n\nCommit reminder\n\n\n\n\n\nThis would be a good time to knit, commit, and push your changes to GitHub!"
  },
  {
    "objectID": "labs/lab-04-regression-trees.html#examining-variability",
    "href": "labs/lab-04-regression-trees.html#examining-variability",
    "title": "Lab 04: Regression trees",
    "section": "Examining variability",
    "text": "Examining variability\nIn class, I mentioned that one disadvantage of regression trees is that they are highly variable. We will explore that here.\n\nRepeat your same analysis from above, but now setting seeds of 5.\n\nMaybe helpful hint: remember that the prediction for a new observation \\(x_{0}\\) is the average of the training responses in the terminal node that \\(x_{0}\\) falls into.\n\nYou only need to provide code and to fit, prune, and predict from the tree (i.e. I won’t be looking for plots). The only outputs I am looking for are the test RMSEs from the pruned and unpruned trees.\nInstead of answering the questions from the previous section, answer the following:\n\n\nBased on this test/train split using a seed of 5, does the pruned or unpruned tree perform better on the test data?\nHow “useful” would you say your pruned tree here is for someone who is trying to understand what may impact the area burned in a forest fire in Portugal?\nHow does your pruned tree here (seed of 5) compare to the pruned tree in the previous section (seed of 346)?"
  },
  {
    "objectID": "labs/lab-04-regression-trees.html#submission",
    "href": "labs/lab-04-regression-trees.html#submission",
    "title": "Lab 04: Regression trees",
    "section": "Submission",
    "text": "Submission\nWhen you’re finished, knit to PDF one last time and upload the PDF to Canvas. Commit and push your code back to GitHub one last time."
  },
  {
    "objectID": "live-code/live-code-pruning.html",
    "href": "live-code/live-code-pruning.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "live-code/live-code-pruning.html#pruning-in-r",
    "href": "live-code/live-code-pruning.html#pruning-in-r",
    "title": "Live code:",
    "section": "Pruning in R",
    "text": "Pruning in R\nWe will use a few more functions from the tree package to prune a large tree and obtain a “best” subtree via cost-complexity pruning and k-fold CV.\n\nGrow large tree\nFirst, we will grow a large regression tree for abundance using all the predictors. Note: by default, the tree() function will grow a large tree, but will not perfectly fit the training data. It defaults to growing a tree that has at least five observations in each child node.\nIf we want to explicitly tell tree() to grow a larger tree, we can specify the optional argument called control. We set nobs = n (i.e. the number of training observations), and another optional control argument such as mindev, minsize, or mincut. See the help file for tree.control for more details.\nHere, we will specify minsize = 2, which means that the smallest allowed node size is 2. If you view the text version of the tree, you’ll see we have many leaves where only one training observation follows a given path.\n\nlibrary(tree)\nn <- nrow(mite_dat)\ntree_mites <- tree(abundance ~ ., data = mite_dat,\n                   control=tree.control(nobs = n, minsize = 2))\nsummary(tree_mites)\n\n\nRegression tree:\ntree(formula = abundance ~ ., data = mite_dat, control = tree.control(nobs = n, \n    minsize = 2))\nVariables actually used in tree construction:\n[1] \"Topo\"      \"SubsDens\"  \"WatrCont\"  \"Substrate\"\nNumber of terminal nodes:  12 \nResidual mean deviance:  20.38 = 1182 / 58 \nDistribution of residuals:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-13.210  -1.600  -1.167   0.000   1.692  10.790"
  },
  {
    "objectID": "live-code/live-code-pruning.html#prune-the-large-tree",
    "href": "live-code/live-code-pruning.html#prune-the-large-tree",
    "title": "Live code:",
    "section": "Prune the large tree",
    "text": "Prune the large tree\nMaybe we think this tree_mites is too complex and might want to prune it to improve results. First we need to consider a bunch of candidate subtrees, then ultimately choose one single “best” tree.\n\nCost-complexity pruning with k-fold CV\nWe can use cv.tree() to perform k-fold cross-validation in order to determine the optimal level of tree complexity. This function performs cost-complexity pruning on the passed-in tree for various values of \\(\\alpha\\). It defaults to k=10 for the k-fold CV. See the help file for more details.\nComprehension question check: why am I setting a seed?\n\nset.seed(3) \ncv_mites <- cv.tree(tree_mites, K = 5)\ncv_mites\n\n$size\n [1] 12 11 10  9  8  7  5  4  3  2  1\n\n$dev\n [1] 10790.748 10419.939 10419.939 10394.639 10394.639 10273.679  9930.036\n [8] 12384.231 12336.495 13379.901 12952.863\n\n$k\n [1]      -Inf  196.4455  200.1603  220.5000  264.5000  304.0513  706.3217\n [8] 1211.2527 1561.6009 1673.4848 2832.2128\n\n$method\n[1] \"deviance\"\n\nattr(,\"class\")\n[1] \"prune\"         \"tree.sequence\"\n\n\nThe returned output contains the cross-validated results from each sub-tree:\n\nsize: number of terminal nodes of each tree considered\ndev: corresponding deviance of each tree\nk: value of the cost-complexity parameter used (\\(\\alpha\\) in our notation)\n\nWe want tree with lowest deviance. Which candidate tree should we use?\n\nbest_id <- which.min(cv_mites$dev)\nbest_id\n\n[1] 7\n\nmin_size <- cv_mites$size[best_id]\nmin_size\n\n[1] 5\n\n\nSometimes, it’s nice to plot the CV test error as a function of \\(\\alpha\\) (k) or the size of each subtree:"
  },
  {
    "objectID": "live-code/live-code-pruning.html#pruning-to-obtain-final-tree",
    "href": "live-code/live-code-pruning.html#pruning-to-obtain-final-tree",
    "title": "Live code:",
    "section": "Pruning to obtain final tree",
    "text": "Pruning to obtain final tree\nWe will use prune.tree() to prune our original large tree tree_mites to the size we found from cv.tree(). Results in a much simpler tree which we could then use for predictions!\n\nprune_mites <- prune.tree(tree_mites, best = min_size)\nplot(prune_mites)\ntext(prune_mites, pretty = 0)"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#tree-based-methods-part-2",
    "href": "slides/slides-09-bag-forests.html#tree-based-methods-part-2",
    "title": "Bagging and Random Forests",
    "section": "Tree-based methods: Part 2",
    "text": "Tree-based methods: Part 2\n\nRecall the disadvantages of decision trees\n\nLower levels of predictive accuracy compared to some other approaches\nCan be non-robust (small changes in training data can result in a drastically different tree)\n\nWe will now see that aggregating many trees can improve predictive performance!"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#bagging-1",
    "href": "slides/slides-09-bag-forests.html#bagging-1",
    "title": "Bagging and Random Forests",
    "section": "Bagging",
    "text": "Bagging\n\nThe decision trees described previously suffer from high variance, whereas linear regression tends to have low variance (when \\(n >> p\\))\nAn ensemble method is a method that combines many simple “building block” models in order to obtain a single final model\nBootstrap aggregation or bagging is a general-purpose procedure for reducing the variance of a statistical-learning method\n\nGiven a set of \\(n\\) independent observations \\(Z_{1}, \\ldots, Z_{n}\\), each with variance \\(\\sigma^2\\), then \\(\\text{Var}(\\bar{Z}) = \\sigma^2/n\\) (i.e. averaging a set of observations reduces variance)\n\nHowever, we typically don’t have access to multiple training sets"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#bagging-in-general",
    "href": "slides/slides-09-bag-forests.html#bagging-in-general",
    "title": "Bagging and Random Forests",
    "section": "Bagging (in general)",
    "text": "Bagging (in general)\n\nInstead, we can bootstrap by taking repeated samples from a single training set\nBagging:\n\nGenerate \\(B\\) (e.g. \\(B = 100\\)) different bootstrapped training datasets\nTrain our model on the \\(b\\)-th bootstrapped training set in order to get \\(\\hat{f}^{(b)}(x)\\) for \\(b = 1,\\ldots, B\\)\nAverage all the predictions to obtain the final “bagged model”\n\n\n\\[\\hat{f}_{\\text{bag}}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{f}^{(b)}(x)\\]"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#bagging-for-decision-trees",
    "href": "slides/slides-09-bag-forests.html#bagging-for-decision-trees",
    "title": "Bagging and Random Forests",
    "section": "Bagging for decision trees",
    "text": "Bagging for decision trees\n\nTo apply bagging to regression trees:\n\nConstruct \\(B\\) regression trees using \\(B\\) different bootstrapped training sets.\nFrom each tree \\(\\hat{f}^{(b)}(x)\\), we can obtain a prediction for a test observation \\(x_{0}\\): \\(\\hat{y}_{0}^{(b)}\\)\n\nFor the same test point, will end up with \\(B\\) predictions: \\(\\hat{y}_{0}^{(1)}, \\hat{y}_{0}^{(2)}, \\ldots, \\hat{y}_{0}^{(B)}\\)\n\nAverage the predictions to produce a final single prediction: \\(\\hat{y}_{0} = \\frac{1}{B} \\sum_{b=1}^{B}\\hat{y}_{0}^{(b)}\\)\n\nDetails\n\nEach of the \\(B\\) trees are grown deep, and are not pruned. Why?\nThe only parameter we set when bagging decision trees is the number of trees \\(B\\) to include"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#out-of-bag-error-estimation",
    "href": "slides/slides-09-bag-forests.html#out-of-bag-error-estimation",
    "title": "Bagging and Random Forests",
    "section": "Out-of-bag error estimation",
    "text": "Out-of-bag error estimation\n\nEstimating test error of a bagged model is quite easy without performing CV\nOn average, each one of the \\(B\\) trees is fit using about 2/3 of the observations. Remaining 1/3 are called out-of-bag (OOB) observations\nCan predict the response for \\(i\\)-th observation using each of the trees in which that observation was OOB\n\nYields about \\(B/3\\) observations for observation \\(i\\)\n\n\nDiscuss: Why is the resulting OOB error a valid estimate of the test error for the bagged model?\n\nWhen \\(B\\) sufficiently large, OOB error is virtually equivalent to LOOCV\n\nDiscuss and implement: how would you fit a bagged regression tree model where you use OOB observations to estimate test error?"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#mite-data",
    "href": "slides/slides-09-bag-forests.html#mite-data",
    "title": "Bagging and Random Forests",
    "section": "Mite data",
    "text": "Mite data\n\n\nI fit bagged regression trees for \\(B = 2, 3, \\ldots, 200\\) bootstrapped sets using\n\nAll the data, and obtained an estimate of test RMSE using the OOB samples\nA training set of 2/3 of the original observations, and obtained an estimate of the test RMSE using the held-out validation set"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#variable-importance-measures",
    "href": "slides/slides-09-bag-forests.html#variable-importance-measures",
    "title": "Bagging and Random Forests",
    "section": "Variable importance measures",
    "text": "Variable importance measures\n\n\n\nBagging can result in difficulty in interpretation: it’s no longer clear which predictors are most important to the procedure\nBut one main attraction of decision trees is their interpretability!\nCan obtain an overall summary of importance of each predictor using the residual error:\n\nFor bagged regression trees, record the total amount that MSE decreases due to splits over a given predictor, averaged over \\(B\\) (higher explanatory power \\(\\rightarrow\\) larger decrease in MSE \\(\\rightarrow\\) more important)\n\n\n\n\n\n\n\n\n\n\n\nWatrCont is the most important variable. This should make sense!\n\nLive code!"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#random-forests-1",
    "href": "slides/slides-09-bag-forests.html#random-forests-1",
    "title": "Bagging and Random Forests",
    "section": "Random forests",
    "text": "Random forests\n\nRandom forests provide improvement over bagged trees by providing a small tweak that decorrelates the trees\nLike bagging, we build \\(B\\) decision trees using \\(B\\) different bootstrapped training samples\nThe only difference is in how each tree \\(\\hat{f}^{(b)}(x)\\) is constructed\nPrediction in random forests proceeds the same as in bagged trees"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#step-through-algorithm",
    "href": "slides/slides-09-bag-forests.html#step-through-algorithm",
    "title": "Bagging and Random Forests",
    "section": "Step through algorithm",
    "text": "Step through algorithm\nFor the mite data, we have \\(p = 5\\) predictors:\n\n\n[1] \"SubsDens\"  \"WatrCont\"  \"Substrate\" \"Shrub\"     \"Topo\"      \"abundance\"\n\n\n\nSuppose we fit a random forest using \\(B\\) regression trees fit on \\(B\\) different bootstrapped sets.\nFor each regression tree, we first obtain a bootstrap sample of the original data\nThen we build a regression tree where:\n\nFor node 1, we only consider a random sample of \\(m = \\sqrt{p} = \\sqrt{5} \\approx 2\\) predictors:\n\n\n[1] \"SubsDens\" \"Shrub\"   \n\n\n\nThus, the first node will either split on SubsDens or Shrub\n\nFor second node, we consider a different random sample of \\(m = 2\\) predictors:\n\n\n[1] \"SubsDens\" \"WatrCont\"\n\n\nEtc."
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#random-forests-cont.",
    "href": "slides/slides-09-bag-forests.html#random-forests-cont.",
    "title": "Bagging and Random Forests",
    "section": "Random forests (cont.)",
    "text": "Random forests (cont.)\n\nAt each split, algorithm is not allowed to consider a majority of the available predictors\n\nIntuition for why?\n\nBagged trees may be highly correlated, and averaging correlated quantities does not reduce variance as much as average uncorrelated\n\nSmall \\(m\\) is typically helpful when we have a large number of correlated predictors\n\n\nDiscuss: what is the resulting model when \\(m = p\\)?\n\n\nLive code!"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#mite-data-1",
    "href": "slides/slides-09-bag-forests.html#mite-data-1",
    "title": "Bagging and Random Forests",
    "section": "Mite data",
    "text": "Mite data\n\n\n\nFor \\(B = 2, 3, \\ldots, 200\\) tree, I fit a random forest with \\(m = 2\\) candidate predictors at each split using\n\nAll the data, and obtained an estimate of test RMSE using the OOB samples\nA training set of 2/3 of the original observations (the same as in bagging), and obtained an estimate of the test RMSE using the held-out validation set"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#comparison",
    "href": "slides/slides-09-bag-forests.html#comparison",
    "title": "Bagging and Random Forests",
    "section": "Comparison",
    "text": "Comparison\nComparing estimated test error when fitting bagged regression trees vs random forests to mite data:"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#summary",
    "href": "slides/slides-09-bag-forests.html#summary",
    "title": "Bagging and Random Forests",
    "section": "Summary",
    "text": "Summary\n\nBagging and random forests are methods for improving predictive accuracy of regression trees\nConsidered “ensemble” methods\nRandom forests (and another method called boosting) are among state-of-the-art for supervised learning, but are less interpretable"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#variable-importance-plot",
    "href": "slides/slides-09-bag-forests.html#variable-importance-plot",
    "title": "Bagging and Random Forests",
    "section": "Variable importance plot",
    "text": "Variable importance plot\n\n\n\nAs with bagged regression trees, can obtain variable importance measure of each predictor using RSS:\n\n\n\n\n\n\n\n\n\n\nWatrCont is still the most important variable"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#variable-importance",
    "href": "slides/slides-09-bag-forests.html#variable-importance",
    "title": "Bagging and Random Forests",
    "section": "Variable importance",
    "text": "Variable importance\n\nAs with bagged regression trees, can obtain variable importance measure of each predictor in random forests using RSS:\n\n\n\n\n\n\n\n\n\nWatrCont is still the most important variable"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#random-forests-vs-bagging-prediction",
    "href": "slides/slides-09-bag-forests.html#random-forests-vs-bagging-prediction",
    "title": "Bagging and Random Forests",
    "section": "Random forests vs bagging: prediction",
    "text": "Random forests vs bagging: prediction\nComparing estimated test error when fitting bagged regression trees vs random forests to mite data:"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#random-forests-vs-bagging-inference",
    "href": "slides/slides-09-bag-forests.html#random-forests-vs-bagging-inference",
    "title": "Bagging and Random Forests",
    "section": "Random forests vs bagging: inference",
    "text": "Random forests vs bagging: inference\nComparing variable importance from the two models:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice the swap in order of Shrub and Substrate"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#construction",
    "href": "slides/slides-09-bag-forests.html#construction",
    "title": "Bagging and Random Forests",
    "section": "Construction",
    "text": "Construction\n\nEach time a split is considered, a random sample of \\(m\\) predictors is chosen as split candidates from the full set of \\(p\\) predictors.\nThe node will split on one of these \\(m\\) predictors\n\nAt every split, we choose a new sample of \\(m\\) predictors\nTypically choose \\(m \\approx p/3\\)"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#example-construction",
    "href": "slides/slides-09-bag-forests.html#example-construction",
    "title": "Bagging and Random Forests",
    "section": "Example construction",
    "text": "Example construction\nFor the mite data, we have \\(p = 5\\) predictors:\n\n\n[1] \"SubsDens\"  \"WatrCont\"  \"Substrate\" \"Shrub\"     \"Topo\"      \"abundance\"\n\n\n\nSuppose we fit a random forest using \\(B\\) regression trees fit on \\(B\\) different bootstrapped sets.\nFor each regression tree, we first obtain a bootstrap sample of the original data\nThen we build a regression tree where:\n\nFor node 1, we only consider a random sample of \\(m \\approx 5/3 \\approx 2\\) predictors:\n\n\n[1] \"SubsDens\" \"Shrub\"   \n\n\n\nThus, node 1 will either split on SubsDens or Shrub\n\nFor node 2, we consider a different random sample of \\(m = 2\\) predictors:\n\n\n[1] \"SubsDens\" \"WatrCont\"\n\n\nEtc."
  },
  {
    "objectID": "assignments.html#project",
    "href": "assignments.html#project",
    "title": "Assignments",
    "section": "Project",
    "text": "Project\n\n\n\n\n\n\n\nFinal project\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nMerge Conflicts\n\n\n:(\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/slides-bootstrap-08.html#resampling",
    "href": "slides/slides-bootstrap-08.html#resampling",
    "title": "Bootstrap",
    "section": "Resampling",
    "text": "Resampling\n\nEconomically use a collected dataset by repeatedly drawing samples from the same training dataset and fitting a model of interest on each sample\n\nObtain additional information about the fitted model\n\nTwo methods: cross-validation and the bootstrap\nThese slides will focus on thebootstrap"
  },
  {
    "objectID": "slides/slides-bootstrap-08.html#the-bootstrap-1",
    "href": "slides/slides-bootstrap-08.html#the-bootstrap-1",
    "title": "Bootstrap",
    "section": "The Bootstrap",
    "text": "The Bootstrap\n\nThe bootstrap is a flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method\nExample: can be used to estimate the standard errors of the \\(\\beta\\) coefficients in linear regression\nOne goal of statistics: learn about a population.\n\nUsually, population is not available, so must make inference from sample data\n\nBootstrapping operates by resampling this sample data to create many simulated samples"
  },
  {
    "objectID": "slides/slides-bootstrap-08.html#the-bootstrap-cont.",
    "href": "slides/slides-bootstrap-08.html#the-bootstrap-cont.",
    "title": "Bootstrap",
    "section": "The Bootstrap (cont.)",
    "text": "The Bootstrap (cont.)\n\nBootstrapping resamples the original dataset with replacement\nIf the original datset has \\(n\\) observations, then each bootstrap/resampled dataset also has \\(n\\) observations\n\nEach observation has equal probability of being included in resampled dataset\nCan select an observation more than once for a resampled dataset"
  },
  {
    "objectID": "slides/slides-bootstrap-08.html#example",
    "href": "slides/slides-bootstrap-08.html#example",
    "title": "Bootstrap",
    "section": "Example",
    "text": "Example\n\nSuppose a study on adult daily caffeine consumption (mg) collects 4 data points: 110, 130, 150, 200. I want to learn about the average consumption in adults.\nCreate my first bootstrap sample:\n\n\ndat <- c(110, 130, 150, 200)\nn <- length(dat)\n\nsamp1 <- sample(x = dat, size = n, replace = T)\nsamp1\n\n[1] 130 200 130 110\n\n\n\nObtain our first estimate for \\(\\mu\\), the population mean daily caffeine consumption in adults: \\(\\hat{\\mu}_{1} = 142.5\\)"
  },
  {
    "objectID": "slides/slides-bootstrap-08.html#example-cont.",
    "href": "slides/slides-bootstrap-08.html#example-cont.",
    "title": "Bootstrap",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nTake second sample:\n\n\nsamp2 <- sample(x = dat, size = n, replace = T)\nsamp2\n\n[1] 150 130 130 150\n\n\n\n\\(\\hat{\\mu}_{2} = 140\\)\nRepeat this process thousands of times!\n…\n\n\n\n\n\nAfter 1000 bootstrap samples, we end up with 1000 estimates for \\(\\mu\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean over all estimates is \\(\\hat{\\mu} = 147.1575\\)\nApproximate 95% confidence interval for the mean are the 5% and 95% quantiles of the 1000 mean estimates: (120, 182.5)"
  },
  {
    "objectID": "slides/slides-bootstrap-08.html#bootstrap-pros-and-cons",
    "href": "slides/slides-bootstrap-08.html#bootstrap-pros-and-cons",
    "title": "Bootstrap",
    "section": "Bootstrap: pros and cons",
    "text": "Bootstrap: pros and cons\n\nReal world vs bootstrap world\nPros:\n\nNo assumptions about distribution of your data\nVery general method that allows estimating sampling distribution of almost any statistic!\nCost-effective\n\nCons:\n\nIn more complex scenarios, figuring out appropriate way to bootstrap may require thought\nCan fail in some situations\nRelies quite heavily on the original sample"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#resampling",
    "href": "slides/slides-08-bootstrap.html#resampling",
    "title": "Bootstrap",
    "section": "Resampling",
    "text": "Resampling\n\nEconomically use a collected dataset by repeatedly drawing samples from the same training dataset and fitting a model of interest on each sample\n\nObtain additional information about the fitted model\n\nTwo methods: cross-validation and the bootstrap\nThese slides will focus on the bootstrap"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#the-bootstrap-1",
    "href": "slides/slides-08-bootstrap.html#the-bootstrap-1",
    "title": "Bootstrap",
    "section": "The Bootstrap",
    "text": "The Bootstrap\n\nThe bootstrap is a flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method\nExample: can be used to estimate the standard errors of the \\(\\beta\\) coefficients in linear regression\nOne goal of statistics: learn about a population.\n\nUsually, population is not available, so must make inference from sample data\n\nBootstrapping operates by resampling this sample data to create many simulated samples"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#the-bootstrap-cont.",
    "href": "slides/slides-08-bootstrap.html#the-bootstrap-cont.",
    "title": "Bootstrap",
    "section": "The Bootstrap (cont.)",
    "text": "The Bootstrap (cont.)\n\nBootstrapping resamples the original dataset with replacement\nIf the original dataset has \\(n\\) observations, then each bootstrap/resampled dataset also has \\(n\\) observations\n\nEach observation has equal probability of being included in the resampled dataset\nCan select an observation more than once for a resampled dataset"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#example-mms",
    "href": "slides/slides-08-bootstrap.html#example-mms",
    "title": "Bootstrap",
    "section": "Example: M&Ms",
    "text": "Example: M&Ms\n\nSuppose I want to know the true proportion of plain M&M candies that are colored red\nMy sample is a bag of M&Ms that I purchased at a gas station, which contains 56 pieces with the following distribution:\n\n\n\n\n [1] orange orange yellow red    blue   red    red    green  green  blue  \n[11] blue   blue   green  orange brown  orange green  red    orange brown \n[21] red    blue   green  blue   orange orange blue   orange brown  orange\n[31] orange yellow orange blue   brown  green  brown  blue   green  orange\n[41] brown  green  brown  yellow yellow brown  blue   orange green  green \n[51] orange brown  orange blue   blue   blue  \nLevels: red orange yellow green blue brown\n\n\nobs\n   red orange yellow  green   blue  brown \n     5     15      4     10     13      9 \n\n\n\n\nGood first guess for the true proportion of red candies?\n\n5/56 = 0.089\n\nHow would we go about creating a range of plausible estimates? We could bootstrap!"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#example-mms-cont.",
    "href": "slides/slides-08-bootstrap.html#example-mms-cont.",
    "title": "Bootstrap",
    "section": "Example: M&Ms (cont.)",
    "text": "Example: M&Ms (cont.)\n\nTo obtain a single bootstrap sample, we repeatedly pull out an M&M, note its color, and return it to the bag until we have pulled out a total of \\(n = 56\\) candies\nWe typically repeat this process many times, to simulate taking multiple observations from the population"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#step-through-code",
    "href": "slides/slides-08-bootstrap.html#step-through-code",
    "title": "Bootstrap",
    "section": "Step-through code",
    "text": "Step-through code\n\nCreate my first bootstrap sample:\n\n\n\nn <- length(obs)\nsamp1 <- sample(x = obs, size = n, replace = T)\nsamp1\n\n [1] blue   red    green  orange green  red    blue   yellow orange orange\n[11] yellow red    blue   orange blue   orange orange orange orange red   \n[21] green  yellow red    orange green  blue   green  green  green  orange\n[31] orange orange orange green  brown  brown  green  brown  green  blue  \n[41] brown  orange yellow orange orange yellow red    orange blue   green \n[51] green  green  green  orange blue   green \nLevels: red orange yellow green blue brown\n\n\n\n\n\ntable(samp1)\n\nsamp1\n   red orange yellow  green   blue  brown \n     6     18      5     15      8      4 \n\n\n\n\nObtain our first estimate for \\(p_{red}\\), the true proportion of red-colors M&Ms: \\(\\hat{p}^{(1)}_{red} = 0.107\\)"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#example-cont.",
    "href": "slides/slides-08-bootstrap.html#example-cont.",
    "title": "Bootstrap",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\nTake second sample:\n\n\n\nsamp2 <- sample(x = obs, size = n, replace = T)\ntable(samp2)\n\nsamp2\n   red orange yellow  green   blue  brown \n     2     18      3      7     10     16 \n\n\n\n\n\\(\\hat{p}^{(2)}_{red} = 0.036\\)\nRepeat this process thousands of times!\n…\n\n\n\n\n\nAfter 1000 bootstrap samples, we end up with 1000 estimates for \\(p_{red}\\)\nAverage over all estimates is \\(\\hat{p} _{red}= 0.091\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApproximate 95% confidence interval for the proportion are the 5% and 95% quantiles of the 1000 mean estimates: (0.018, 0.179)"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#comprehension-checks",
    "href": "slides/slides-08-bootstrap.html#comprehension-checks",
    "title": "Bootstrap",
    "section": "Comprehension checks",
    "text": "Comprehension checks\nSuppose my original sample has the following \\(n = 5\\) observations: (1, 0, -2, 0.5, 4).\nWhich of the following are possible bootstrap samples we could obtain from the original sample?\n\n(0, 0, 0, 0, 0)\n(1, -2, -2, 3, 4)\n(1, 0, -2, 0.5, 4)\n(4, -2, 0)"
  },
  {
    "objectID": "slides/slides-08-bootstrap.html#bootstrap-pros-and-cons",
    "href": "slides/slides-08-bootstrap.html#bootstrap-pros-and-cons",
    "title": "Bootstrap",
    "section": "Bootstrap: pros and cons",
    "text": "Bootstrap: pros and cons\n\nReal world vs bootstrap world\nPros:\n\nNo assumptions about distribution of your data\nVery general method that allows estimating sampling distribution of almost any statistic!\nCost-effective\n\nCons:\n\nIn more complex scenarios, figuring out appropriate way to bootstrap may require thought\nCan fail in some situations\nRelies quite heavily on the original sample"
  },
  {
    "objectID": "project/description.html#proposal",
    "href": "project/description.html#proposal",
    "title": "Final project",
    "section": "Proposal",
    "text": "Proposal\nDue: Sunday, April 23 at 11:59pm\nYour proposal must be done using R Markdown. You should describe the dataset that you would like to use, and define the variables in the dataset that you intend to explore. You must include some EDA (ex. univariate or bivariate plots, tables of summary statistics, etc), and you must also list at least two questions that you are interested in answering using the data.\nYou should clearly indicate if you intend to pursue a method that you teach yourself.\nYou should clearly indicate if your questions supervised or unsupervised learning tasks.\nThere is no page limit or requirement. For submission, submit the .pdf document to Canvas. The main purpose of this component of the project is to help you get started, and so Professor Tang can give feedback/suggestions about the data and questions of interest."
  },
  {
    "objectID": "project/description.html#plan-of-analysis",
    "href": "project/description.html#plan-of-analysis",
    "title": "Final project",
    "section": "Plan of analysis",
    "text": "Plan of analysis\nDue: Sunday, April 30 at 11:59pm\nYour plan of analysis must be done using R Markdown. Your group should create a new .Rmd file called project_plan.Rmd and work within that new document. Based on the feedback from your proposal, the written plan of analysis should contain:\n\nYour updated research question(s). Please be as clear as possible; do not be overly verbose.\nFor each research question: the methods/models you plan to use to answer. The methods must be appropriate for the given research question. You should justify why each method you choose is suitable for the question.\nDescribe how exactly you plan to implement the methods you selected to answer your research question(s). This may include discussion of necessary data cleaning and preparation, which R packages you intend to use, how you plan on validating/comparing models, etc.\n\n\nRemember: you need some form of (appropriate) model comparison for your final project, so you should clearly indicate the way you will perform comparisons.\n\n\n\nIf you chose to pursue a method that we did not cover in class, you must clearly describe the method in your plan.\nThe main purpose of this component is so Professor Tang can make sure that you are well-prepared to complete the project."
  },
  {
    "objectID": "project/description.html#written-report",
    "href": "project/description.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\nDue: Thursday, May 11 at 11:59pm\nYour written report must be done using R Markdown. You must contribute to the GitHub repository with regular meaningful commits/pushes. Before you finalize your write up, make sure the printing of code chunks is turned off with the option echo = FALSE.\nYour final report must match your GitHub repository exactly. The mandatory components of the report are as follows, but feel free to expand with additional sections as necessary. There is no page limit or requirement – however, you must comprehensively address all aspects below. Please be judicious in what you decide to include in your final write-up. For submission, submit the .pdf document to Canvas.\nThe written report is worth 60 points, broken down as\n\n\n\nTotal\n60 pts\n\n\n\n\nIntroduction/data\n10 pts\n\n\nEDA\n5 pts\n\n\nMethodology\n15 pts\n\n\nResults\n20 pts\n\n\nDiscussion\n10 pts\n\n\n\n\nIntroduction and data\nThe introduction should introduce your general research question(s) and your data (where it came from, how it was collected, what are the cases, what are the variables, etc.). It should be clear from the Introduction if you are planning on pursuing a supervised and/or unsupervised analysis. If you are planning on using supervised methods, you should clearly indicate what variable is your response variable of interest.\n\n\nEDA\nThe methodology section should include the variables used to address your research question, as well as any useful visualizations or summary statistics. Please be judicious in this section. Usually one strong visualization is better than five that are not useful.\n\n\nMethodology\nIn this section, you should introduce, briefly describe, and justify the statistical learning methods that you used to answer your research question(s).\n\n\nResults\nShowcase how you arrived at answers to your question using any techniques we have learned in this class (and some beyond, if you’re feeling adventurous). Provide the main results from your analysis. The goal is not to do an exhaustive data analysis (i.e., do not calculate every statistic and procedure you have learned for every variable), but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on they key results that are related to answering your research questions.\n\n\nDiscussion\nThis section is a conclusion and discussion. This will require a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. A paragraph on what you would do differently if you were able to start over with the project or what you would do next if you were going to continue work on the project should also be included.\nRevision opportunity: after your presentation, you have the opportunity to take feedback from Professor Tang and your peers to revise the written report. If you would like to revise the report, you have within five days of receiving the initial feedback to re-submit the report. This is not a guarantee of an improved grade. I will speak more about the revision process later in the semester."
  },
  {
    "objectID": "project/description.html#repository",
    "href": "project/description.html#repository",
    "title": "Final project",
    "section": "Repository",
    "text": "Repository\nDue: Thursday, May 11 at 11:59pm\nIn addition to your Canvas submissions, I will be checking your GitHub repository. This repository should include:\n\nTwo separate RMarkdown files (formatted to clearly present all of your code and results) that will output: (1) the proposal and (2) final write-up\nMeaningful README file on the GitHub repository that contains a codebook for relevant variables\nDataset(s) (in csv or RData format, in a /data folder)\nPresentation (if using Keynote/PowerPoint/Google Slides, export to PDF and add it to your GitHub repo.)\n\nStyle and format does count for this assignment, so please take the time to make sure everything looks good and your data and code are properly formatted."
  },
  {
    "objectID": "project/description.html#slides",
    "href": "project/description.html#slides",
    "title": "Final project",
    "section": "Slides",
    "text": "Slides\nDue: Thursday, May 11 at 11:59pm\nIn addition to the write-up, you must also create presentation slides that summarize and showcase your project. Introduce your research question and dataset, showcase your EDA visualizations, and provide some conclusions. These slides should serve as a brief visual accompaniment to your write-up and will be graded for content and quality. They can also be used for your Presentation. For submission, convert these slides to a .pdf document to be uploaded to Canvas."
  },
  {
    "objectID": "project/description.html#presentation",
    "href": "project/description.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\nDue: Friday, May 12 during class\nOn the last day of class everyone will present their projects. There will be a five-minute (tentative) time limit for each presentation followed by two minutes for questions, for a total of seven-minutes per presentation. You may, and should, use the slides as detailed in the previous section during your presentation."
  },
  {
    "objectID": "project/description.html#participation",
    "href": "project/description.html#participation",
    "title": "Final project",
    "section": "Participation",
    "text": "Participation\nYou are expected to attend all days of presentations, and be actively engaged by asking questions and providing feedback.\nEveryone will also provide feedback and assess their partner’s contributions. Please complete the evaluation form on the Participation^ assignment in Canvas by TBD."
  },
  {
    "objectID": "slides/slides-10-logistic.html#classification",
    "href": "slides/slides-10-logistic.html#classification",
    "title": "Classification & Logistic Regression",
    "section": "Classification",
    "text": "Classification\n\nUp until now, we have focused on quantitative responses \\(y_{i}\\)\nWhat happens when \\(y_{i}\\) is qualitative? Examples include:\n\nMedical diagnosis: \\(\\mathcal{C} = \\{\\text{yes}, \\text{no}\\}\\)\nEducation level: \\(\\mathcal{C} = \\{\\text{high school}, \\text{college}, \\text{graduate}\\}\\)\n\nEach category in \\(\\mathcal{C}\\) is also known as a label\nIn this setting, we want our model to be a classifier, i.e. given predictors \\(X\\), predict a label from the pool of all possible categories \\(\\mathcal{C}\\)"
  },
  {
    "objectID": "slides/slides-10-logistic.html#classification-1",
    "href": "slides/slides-10-logistic.html#classification-1",
    "title": "Classification & Logistic Regression",
    "section": "Classification",
    "text": "Classification\n\nModel: \\(y_{i} = f(x_{i}) + \\epsilon_{i}\\)\nWe will still have to estimate \\(f\\) with a \\(\\hat{f}\\)\n\\(\\hat{y}_{i}\\) is the predicted class label for observation \\(i\\) using estimate \\(\\hat{f}\\)\nHow to assess model accuracy? Error is more intuitive in classification: we make an error if we predict the incorrect label, and no error otherwise"
  },
  {
    "objectID": "slides/slides-10-logistic.html#classification-error",
    "href": "slides/slides-10-logistic.html#classification-error",
    "title": "Classification & Logistic Regression",
    "section": "Classification error",
    "text": "Classification error\n\nThis can be represented using an indicator variable or function \\(\\mathbf{1}(y_{i} = \\hat{y}_{i})\\): \\[\\mathbf{1}(y_{i} = \\hat{y}_{i}) = \\begin{cases} 1 & \\text{ if } y_{i} = \\hat{y}_{i}\\\\ 0 & \\text{ if } y_{i} \\neq \\hat{y}_{i} \\end{cases}\\]\nWe typically have more than one observation \\(\\Rightarrow\\) calculate the classification error rate or misclassification rate, which is the proportion of mistakes we make in predicted labels: \\[\\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}(y_{i} \\neq \\hat{y}_{i})\\]\n\nSmaller error preferred"
  },
  {
    "objectID": "slides/slides-10-logistic.html#conditional-class-probabilities",
    "href": "slides/slides-10-logistic.html#conditional-class-probabilities",
    "title": "Classification & Logistic Regression",
    "section": "Conditional class probabilities",
    "text": "Conditional class probabilities\n\nHow do we choose which label to predict for a given observation?\nAssume we have a total of \\(J\\) possible labels in \\(\\mathcal{C}\\)\nFor a given observation \\(i\\), can calculate the following probability for each possible label \\(j\\): \\[p_{ij}(x_{i}) = \\text{Pr}(y_{i} = j | X = x_{i})\\]\n\n“Probability that observation \\(i\\) has label \\(j\\), given the predictors \\(x_{i}\\)”\n\nThese probabilities are called conditional class probabilities at \\(x_{i}\\)"
  },
  {
    "objectID": "slides/slides-10-logistic.html#bayes-optimal-classifier-1",
    "href": "slides/slides-10-logistic.html#bayes-optimal-classifier-1",
    "title": "Classification & Logistic Regression",
    "section": "Bayes optimal classifier",
    "text": "Bayes optimal classifier\n\nThe Bayes optimal classifier will assign/predict the label which has the largest conditional class probability\n\nIt can be shown that the test error rate \\(\\frac{1}{n_{test}} \\sum_{i=1}^{n_{test}} \\mathbf{1}(y_{i} \\neq \\hat{y}_{i})\\) is minimized when using the Bayes optimal classifier\n\nFor example, consider a binary response with levels “yes” and “no”\n\nFor observation \\(i\\), if \\(Pr(y_{i} = \\text{yes} | X = x_{i}) > 0.5\\), then predict \\(\\hat{y}_{i} =\\) “yes”\nThe \\(x_{i}\\) where \\(Pr(y_{i} = \\text{yes} | X = x_{i}) = Pr(y_{i} = \\text{no} | X = x_{i})= 0.5\\) is called the Bayes decision boundary"
  },
  {
    "objectID": "slides/slides-10-logistic.html#example",
    "href": "slides/slides-10-logistic.html#example",
    "title": "Classification & Logistic Regression",
    "section": "Example",
    "text": "Example\nThe following plot shows simulated binary data plotted in 2D predictor space, where color corresponds to label. Large dots denote the observations, black line is Bayes decision boundary."
  },
  {
    "objectID": "slides/slides-10-logistic.html#need-for-models",
    "href": "slides/slides-10-logistic.html#need-for-models",
    "title": "Classification & Logistic Regression",
    "section": "Need for models",
    "text": "Need for models\n\nBayes classifier is “gold standard”\nIn practice, we cannot compute \\(p_{ij}(x_{i}) = \\textbf{Pr}(y_{i} = j | X = x_{i})\\) because we do not know these true probabilities (i.e. we don’t know the true conditional distribution of \\(y\\) given \\(x\\))\nInstead, we need to estimate the \\(p_{ij}(x_{i})\\)\nDifferent statistical learning models define different methods to estimate these \\(p_{ij}(x_{i})\\)!\nOnce we have an estimate of these conditional class probabilities, the “way” of classifying is the same no matter the model:\n\nFor observation \\(i\\), predict label \\(j^*\\) if \\(p_{ij^*}(x_{i}) = \\max_{j}\\{p_{ij}(x_{i})\\}\\)"
  },
  {
    "objectID": "slides/slides-10-logistic.html#logistic-regression-1",
    "href": "slides/slides-10-logistic.html#logistic-regression-1",
    "title": "Classification & Logistic Regression",
    "section": "Logistic regression",
    "text": "Logistic regression\nThe observed zero abundances in the mite data were difficult to work with. I consider transforming the abundance to a binary response present as follows:\n\npresence_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG) %>%\n  mutate(present = ifelse(abundance > 0, 1, 0)) %>%\n  select(-abundance)"
  },
  {
    "objectID": "slides/slides-10-logistic.html#logistic-regression-2",
    "href": "slides/slides-10-logistic.html#logistic-regression-2",
    "title": "Classification & Logistic Regression",
    "section": "Logistic regression",
    "text": "Logistic regression\nFitting a logistic regression:"
  },
  {
    "objectID": "slides/slides-10-logistic.html#logistic-regression-3",
    "href": "slides/slides-10-logistic.html#logistic-regression-3",
    "title": "Classification & Logistic Regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nAssume first that we have a single predictor \\(X\\)\nLet \\(p({x}) = \\text{Pr}(Y = 1 | {X} = {x})\\)\n\nFor binary response \\((J = 2)\\), we shorthand the conditional class probability to always be in terms of a “success” class\n\nNeed to somehow restrict \\(0 \\leq p(x) \\leq 1\\)\nLogistic regression uses logistic function: \\[p({x}) = \\frac{e^{\\beta_{0} + \\beta_{1}x}}{1 + e^{\\beta_{0} + \\beta_{1}x}}\\]"
  },
  {
    "objectID": "slides/slides-10-logistic.html#odds-and-log-odds",
    "href": "slides/slides-10-logistic.html#odds-and-log-odds",
    "title": "Classification & Logistic Regression",
    "section": "Odds and Log-odds",
    "text": "Odds and Log-odds\n\nRearranging this equation yields the odds: \\[ \\frac{\\text{Pr(success)}}{\\text{Pr(failure)}} = \\frac{p(x)}{1 - p(x)} = e^{\\beta_{0} + \\beta_{1}x}\\]\nFurthermore, we can obtain the log-odds: \\[\\log\\left(\\frac{p(x)}{1 - p(x)}\\right) = \\log(e^{\\beta_{0} + \\beta_{1}x})  = \\beta_{0} + \\beta_{1}x\\]\n\nWhen using \\(\\log()\\), we refer to natural logarithm function \\(\\ln()\\)"
  },
  {
    "objectID": "slides/slides-10-logistic.html#example-1",
    "href": "slides/slides-10-logistic.html#example-1",
    "title": "Classification & Logistic Regression",
    "section": "Example",
    "text": "Example\n\nFor the mite data, let “success” be when present = 1; i.e. \\(p(x) = \\text{Pr}(\\text{present} = 1 | X = x)\\)\nI fit the following logistic regression model: \\[\\log\\left(\\frac{p(x)}{1-p(x)}\\right) = \\beta_{0} + \\beta_{1} \\text{WatrCont}\\]\n\n\n\nlogistic_mod <- glm(present ~ WatrCont, data = presence_dat, \n                    family = \"binomial\")"
  },
  {
    "objectID": "slides/slides-10-logistic.html#remarks",
    "href": "slides/slides-10-logistic.html#remarks",
    "title": "Classification & Logistic Regression",
    "section": "Remarks",
    "text": "Remarks\n\nEasily extends to \\(p\\) predictor case: let \\(\\mathbf{x} = (x_{1}, x_{2}, \\ldots, x_{p})\\). Then \\[\\log\\left(\\frac{p(\\mathbf{x})}{1-p(\\mathbf{x})}\\right) =\\beta_{0} + \\beta_{1}x_{1} + \\ldots \\beta_{p} x_{p}\\]\nWhy called logistic “regression” if used for classification task?\n\nThe log-odds is a real-valued quantity that is modeled as a linear function of \\(X\\)"
  },
  {
    "objectID": "slides/slides-10-logistic.html#obtaining-probability",
    "href": "slides/slides-10-logistic.html#obtaining-probability",
    "title": "Classification & Logistic Regression",
    "section": "Obtaining probability",
    "text": "Obtaining probability\n\nWe can interpret the coefficients, but remember the original goal: predict a label (success/failure) for an observation based on its predictors\nThat is, we want \\(p(x)\\), not \\(\\log\\left(\\frac{p(x)}{1-p(x)}\\right)\\)\n\nLet’s simply re-arrange the log-odds formula!\n\nWe might ask: what is the estimated probability of presence of mites for a location where WatrCont = 350?\n\n\n\n\n\n\\[\n\\begin{align*}\n&\\hat{p}(x) = \\frac{e^{\\hat{\\beta}_{0} + \\hat{\\beta}_{1}x}}{1 + e^{\\hat{\\beta}_{0} + \\hat{\\beta}_{1}x}} \\\\\n&\\hat{p}(x = 350) = \\frac{e^{-2.4815 + 0.0087 \\times 350}}{1+e^{-2.4815 + 0.0087 \\times 350}} = 0.637262\n\\end{align*}\n\\]\n\n\nDiscuss: based on this model, would you classify an observation with WatrCont = 350 to have mites or not?\nLive code!"
  },
  {
    "objectID": "slides/slides-10-logistic.html#example-cont.",
    "href": "slides/slides-10-logistic.html#example-cont.",
    "title": "Classification & Logistic Regression",
    "section": "Example (cont.)",
    "text": "Example (cont.)\n\n\n\n\nCall:\nglm(formula = present ~ WatrCont, family = \"binomial\", data = presence_dat)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3429  -0.9402   0.4965   0.7911   1.7595  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)   \n(Intercept) -2.481539   1.011855  -2.452  0.01419 * \nWatrCont     0.008743   0.002695   3.244  0.00118 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 85.521  on 69  degrees of freedom\nResidual deviance: 70.796  on 68  degrees of freedom\nAIC: 74.796\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nDiscuss:\n\nWhat is the interpretation of \\(\\hat{\\beta}_{1} =\\) 0.0087?\nIs increasing WatrCont associated with an increasing or decreasing probability of the presence of these mites?"
  },
  {
    "objectID": "slides/slides-10-logistic.html#interpretation-of-coefficients",
    "href": "slides/slides-10-logistic.html#interpretation-of-coefficients",
    "title": "Classification & Logistic Regression",
    "section": "Interpretation of coefficients",
    "text": "Interpretation of coefficients\n\\[\\log\\left(\\frac{p(x)}{1 - p(x)}\\right) = \\log(e^{\\beta_{0} + \\beta_{1}x})  = \\beta_{0} + \\beta_{1}x\\]\n\nInterpretation of \\(\\beta_{1}\\): for every one-unit increase in \\(x\\), we expect an average change of \\(\\beta_{1}\\) in the log-odds (or average multiple of \\(e^{\\beta_{1}}\\) in the odds)\n\n\\(\\beta_{1}\\) does not correspond to the change in \\(p(x)\\) associated with one-unit increase in \\(X\\) (i.e., not a linear relationship between \\(x\\) and \\(p(x)\\))\nIf \\(\\beta_{1} > 0\\), then increasing \\(x\\) is associated with increasing \\(p(x)\\)"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#implementation",
    "href": "slides/slides-09-bag-forests.html#implementation",
    "title": "Bagging and Random Forests",
    "section": "Implementation",
    "text": "Implementation\n\nSuppose we want to fit a bagged regression tree model to predict abundance in the mite data\nFit data on 80% train, predict on 20% test\nDiscuss: how would you fit a bagged regression tree model to obtain predictions for the test set using functions/methods you already know?"
  },
  {
    "objectID": "slides/slides-09-bag-forests.html#live-code",
    "href": "slides/slides-09-bag-forests.html#live-code",
    "title": "Bagging and Random Forests",
    "section": "Live code!",
    "text": "Live code!\nFitting bagged decision trees using the randomForest package"
  },
  {
    "objectID": "implementations/implementation_bagging_regression.html",
    "href": "implementations/implementation_bagging_regression.html",
    "title": "Bagging",
    "section": "",
    "text": "Note: this implementation is not graded."
  },
  {
    "objectID": "implementations/implementation_bagging_regression.html#introduction",
    "href": "implementations/implementation_bagging_regression.html#introduction",
    "title": "Bagging",
    "section": "Introduction",
    "text": "Introduction\nSuppose we want to fit a bagged regression tree model using B = 10 trees. We will first implement the models by hand before learning how to use functions from the randomForest library.\n\nlibrary(tidyverse)\nlibrary(vegan)\nlibrary(tree)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)\nn <- nrow(mite_dat)"
  },
  {
    "objectID": "implementations/implementation_bagging_regression.html#implement-bagging-validation-set",
    "href": "implementations/implementation_bagging_regression.html#implement-bagging-validation-set",
    "title": "Bagging",
    "section": "Implement bagging: validation set",
    "text": "Implement bagging: validation set\nIn this section, you will see that you are provided an 80/20 split of the data.\nImplement a bagged regression tree model where the trees are fit on the train data, and you obtain predictions for the remaining 20% test data. Assume that we want to predict abundance using all the remaining variables as predictors.\nRemember, we are bagging B = 10 trees.\n\nDiscuss with someone next to you before coding:\n\n\nWill you need to iterate multiple times? If so, how many times? What steps need to take place at every iteration?\nWhat are you ultimately trying to obtain/output?\nWhat information will you need keep track off? Will you need to create some vectors?\n\n\nset.seed(18) \ntrain_ids <- sample(1:n, 0.8*n)\nn_train <- length(train_ids)\nn_test <- n - n_train\n\n\n# code here"
  },
  {
    "objectID": "implementations/implementation_bagging_regression.html#implement-bagging-oob",
    "href": "implementations/implementation_bagging_regression.html#implement-bagging-oob",
    "title": "Bagging",
    "section": "Implement bagging: OOB",
    "text": "Implement bagging: OOB\nRather than splitting the data into a train/test set, here we will leverage the out-of-bag (OOB) observations. Implement a bagged regression tree model where the OOB observations are used to estimate the test error.\nHint: remember that different observations will be excluded from each bootstrap sample. So you have to be clever about how you keep track of the predictions (and how many times an observation is OOB).\n\nDiscuss with someone next to you before coding:\n\n\nWhat will be different about OOB predictions compared to a bagged tree where we explicitly define a test/train split? What will be the same?\n\n\n# code here"
  },
  {
    "objectID": "implementations/implementation_bootstrap.html",
    "href": "implementations/implementation_bootstrap.html",
    "title": "Bootstrap",
    "section": "",
    "text": "This is a grouped assignment! Please clone your individual bootstrap_implementation GitHub repo, and work in the .Rmd file contained within it. Then, once your finished, one member of your group should upload your final implementation to Canvas."
  },
  {
    "objectID": "implementations/implementation_bootstrap.html#introduction",
    "href": "implementations/implementation_bootstrap.html#introduction",
    "title": "Bootstrap",
    "section": "Introduction",
    "text": "Introduction\nWe will now derive the probability that a given observation is part of a bootstrap sample. Suppose that our original sample contains \\(n\\) observations, and wish to obtain a bootstrap sample. Remember that in bootstrap sampling we repeatedly sample/draw with replacement from the original sample until we have a bootstrap sample of size \\(n\\). As a result, each draw is assumed independent of the next.\nNote: if two events \\(A\\) and \\(B\\) are independent of each other, then the probability of both events happening is the product of their individual probabilities occurring:\n\\[\\text{Pr}(A \\text{ and } B) = \\text{Pr}(A) \\times \\text{Pr}(B)\\]"
  },
  {
    "objectID": "implementations/implementation_bootstrap.html#part-1-theory",
    "href": "implementations/implementation_bootstrap.html#part-1-theory",
    "title": "Bootstrap",
    "section": "Part 1: “Theory”",
    "text": "Part 1: “Theory”\nSuppose we wish to obtain our first bootstrap sample (which will ultimately be of size \\(n\\)). Answer the following questions using text (no code necessary, unless using R as a calculator).\n\nWhat is the probability that the first bootstrap observation in this sample is not the \\(j\\)-th observation from the original sample? Justify your answer.\nWhat is the probability that the second bootstrap observation is not the \\(j\\)-th observation from the original sample?\nArgue that the probability that the \\(j\\)-th observation is not in the bootstrap sample is \\((1-1/n)^{n}\\).\nWhen \\(n = 5\\), what is the probability that the \\(j\\)-th observation is in the bootstrap sample?\nWhen \\(n = 100\\), what is the probability that the \\(j\\)-th observation is in the bootstrap sample? Comment on how this relates to the probability you found when \\(n = 5\\).\nWhen \\(n = 1000\\), what is the probability that the \\(j\\)-th observation is in the bootstrap sample? Comment on how this relates to the probability you found when \\(n = 100\\).\nThe following plot displays, for each integer value of \\(n\\) from 1 to 1000, the probability that the \\(j\\)-th observation is not included in the bootstrap sample. The orange dashed line is at \\(y= e^{-1} = 1/e\\), and the blue dashed line is at \\(y = 1/3\\). Note that the x-axis is on the log scale.\n\nComment on what you observe."
  },
  {
    "objectID": "implementations/implementation_bootstrap.html#part-2-simulation",
    "href": "implementations/implementation_bootstrap.html#part-2-simulation",
    "title": "Bootstrap",
    "section": "Part 2: Simulation",
    "text": "Part 2: Simulation\nWe will now investigate numerically the probability that a bootstrap sample of size \\(n = 100\\) contains the \\(j\\)-th observation.\nYou will obtain a total of \\(B = 10000\\) bootstrap samples. For each bootstrap sample, you should record a:\n\n1 if the fourth observation (i.e. \\(j = 4\\)) is not contained in the bootstrap sample\n0 if the fourth observation is contained in the bootstrap sample\n\nNote: the actual data does not matter in this simulation. We only care about which observations are selected, not the values of the observations themselves.\n\nThen, take the mean of your \\(B\\) results (which results in a proportion). How does your empirical probability (i.e. simulated proportion) compared to the theory above?"
  },
  {
    "objectID": "implementations/implementation_bootstrap.html#submission",
    "href": "implementations/implementation_bootstrap.html#submission",
    "title": "Bootstrap",
    "section": "Submission",
    "text": "Submission\nWhen finished, make sure to knit + commit + push. One member of your group should upload your final implementation to Canvas. Be sure to include everyone’s names somewhere on the document."
  },
  {
    "objectID": "project/description.html#draft",
    "href": "project/description.html#draft",
    "title": "Final project",
    "section": "Draft",
    "text": "Draft\nDue: Sunday, May 07 at 11:59pm\nYour group should submit a draft of your written report (see below) to Canvas for peer review by another group. This draft does not need to be complete, but I am expecting, at a minimum, a draft of the Introduction and EDA sections. This is a great opportunity for you to obtain feedback from other students to see if a new reader understands the motivation of your project and the data you are working with."
  },
  {
    "objectID": "live-code/live-code-bagging-implementation.html",
    "href": "live-code/live-code-bagging-implementation.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\nlibrary(tree)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "live-code/live-code-bagging-implementation.html#option-1",
    "href": "live-code/live-code-bagging-implementation.html#option-1",
    "title": "Live code:",
    "section": "Option 1:",
    "text": "Option 1:\nHere, I create a vector pred_sums that is in essence, a vector of cumulative sums of predictions.\n\nset.seed(1)\npred_sums <- rep(0, n_test)\n\nfor (b in 1:B){\n  # obtain bootstrap sample\n  boot_ids <- sample(1:n_train, n_train, replace = TRUE)\n  boot_samp <- train_dat[boot_ids,]\n  \n  # fit tree to bootstrap sample\n  boot_tree <- tree(abundance ~ . , data = boot_samp)\n  \n  # obtain predictions for test set\n  predictions <- predict(boot_tree, newdata = test_dat)\n  \n  # store predictions for test set\n  pred_sums <- pred_sums +  predictions\n}\npred_sums/B\n\n         2          3          7         15         16         19         22 \n11.3331103 16.5589754 14.4339754  3.2265457  0.7085599 11.6994505  0.7085599 \n        25         35         36         47         58         59         70 \n 3.2353446  9.8865567 12.4727839  9.8865567 11.6536153  8.7849145 12.8079772"
  },
  {
    "objectID": "live-code/live-code-bagging-implementation.html#option-2",
    "href": "live-code/live-code-bagging-implementation.html#option-2",
    "title": "Live code:",
    "section": "Option 2:",
    "text": "Option 2:\nHere, I create a B x n_test matrix that will hold each prediction:\n\nset.seed(1)\npred_mat <- matrix(0, nrow = B, ncol = n_test)\n\nfor (b in 1:B){\n  # obtain bootstrap sample\n  boot_ids <- sample(1:n_train, n_train, replace = TRUE)\n  boot_samp <- train_dat[boot_ids,]\n  \n  # fit tree to bootstrap sample\n  boot_tree <- tree(abundance ~ . , data = boot_samp)\n  \n  # obtain predictions for test set\n  predictions <- predict(boot_tree, newdata = test_dat)\n  \n  # store predictions for test set\n  pred_mat[b,] <- predictions\n}\n\napply(pred_mat, 2, mean)\n\n [1] 11.3331103 16.5589754 14.4339754  3.2265457  0.7085599 11.6994505\n [7]  0.7085599  3.2353446  9.8865567 12.4727839  9.8865567 11.6536153\n[13]  8.7849145 12.8079772\n\n# this function does the same: colMeans(pred_mat)"
  },
  {
    "objectID": "live-code/live-code-bagging-implementation.html#testtrain-set-approach-for-test-error",
    "href": "live-code/live-code-bagging-implementation.html#testtrain-set-approach-for-test-error",
    "title": "Live code:",
    "section": "Test/train set approach for test error",
    "text": "Test/train set approach for test error\n\nn <- nrow(mite_dat)\nset.seed(18) \ntrain_ids <- sample(1:n, 0.8*n)\nn_train <- length(train_ids)\nn_test <- n - n_train\n\ntrain_dat <- mite_dat[train_ids,]\ntest_dat <- mite_dat[-train_ids,]\nB <- 10\n\nThe two following options differ only in how I keep track of my predictions. I will set some seeds to see if we indeed get the same predictions:\n\nOption 1:\nHere, I create a vector pred_sums that is in essence, a vector of cumulative sums of predictions.\n\nset.seed(1)\npred_sums <- rep(0, n_test)\n\nfor (b in 1:B){\n  # obtain bootstrap sample\n  boot_ids <- sample(1:n_train, n_train, replace = TRUE)\n  boot_samp <- train_dat[boot_ids,]\n  \n  # fit tree to bootstrap sample\n  boot_tree <- tree(abundance ~ . , data = boot_samp)\n  \n  # obtain predictions for test set\n  predictions <- predict(boot_tree, newdata = test_dat)\n  \n  # store predictions for test set\n  pred_sums <- pred_sums +  predictions\n}\npred_sums/B\n\n         2          3          7         15         16         19         22 \n11.3331103 16.5589754 14.4339754  3.2265457  0.7085599 11.6994505  0.7085599 \n        25         35         36         47         58         59         70 \n 3.2353446  9.8865567 12.4727839  9.8865567 11.6536153  8.7849145 12.8079772 \n\n\n\n\nOption 2:\nHere, I create a B x n_test matrix that will hold each prediction:\n\nset.seed(1)\npred_mat <- matrix(0, nrow = B, ncol = n_test)\n\nfor (b in 1:B){\n  # obtain bootstrap sample\n  boot_ids <- sample(1:n_train, n_train, replace = TRUE)\n  boot_samp <- train_dat[boot_ids,]\n  \n  # fit tree to bootstrap sample\n  boot_tree <- tree(abundance ~ . , data = boot_samp)\n  \n  # obtain predictions for test set\n  predictions <- predict(boot_tree, newdata = test_dat)\n  \n  # store predictions for test set\n  pred_mat[b,] <- predictions\n}\n\napply(pred_mat, 2, mean)\n\n [1] 11.3331103 16.5589754 14.4339754  3.2265457  0.7085599 11.6994505\n [7]  0.7085599  3.2353446  9.8865567 12.4727839  9.8865567 11.6536153\n[13]  8.7849145 12.8079772\n\n# this function does the same: colMeans(pred_mat)"
  },
  {
    "objectID": "live-code/live-code-bagging-implementation.html#oob-approach-to-for-test-error",
    "href": "live-code/live-code-bagging-implementation.html#oob-approach-to-for-test-error",
    "title": "Live code:",
    "section": "OOB approach to for test error",
    "text": "OOB approach to for test error\n\nset.seed(1)\nB <- 10\npred_sum <- rep(0, n)\nn_oob <- rep(0,n)\nfor (b in 1:B){\n  boot_ids <- sample(1:n, n, replace = T)\n  oob_ids <- (1:n)[-unique(boot_ids)]\n  \n  tree <- tree(abundance ~ ., data = mite_dat[boot_ids,])\n  pred_sum[oob_ids] <-  pred_sum[oob_ids] + predict(tree, newdata = mite_dat[oob_ids,])\n  n_oob[oob_ids] <- n_oob[oob_ids] + 1\n  \n}\n\npred_sum\n\n [1]   7.183861   3.448718  16.514286  10.061905   2.909420   3.336120\n [7]  27.066026   6.227226   7.176942   4.099206  14.439985  20.536264\n[13]   4.401139  14.272283  29.132601  10.387198   5.800528   6.690494\n[19]  92.931735   4.783861   3.901139   4.150000  15.628571   6.005617\n[25]   3.313043  29.230159   5.773318  19.901810   7.956410  89.646886\n[31]  29.593407  14.483333  58.656410  16.960317  54.034091  54.856410\n[37]  79.111722  57.837662   1.888889  50.145299  45.600000  46.754579\n[43]  26.825397  26.909091  79.837662 120.722436  26.599076  41.107692\n[49] 151.181818  83.603996  57.186039  55.200000 170.867244  71.357143\n[55]  65.155556  66.600000  26.361905  47.000000  28.799603  48.935165\n[61]  85.018182  66.714286 132.310490  67.510490  15.285714  50.018182\n[67]  24.301587  97.774451  45.155311  20.731502\n\nn_oob\n\n [1] 3 2 2 3 3 3 4 5 5 4 5 3 4 4 4 6 5 6 5 4 4 3 4 5 2 5 5 3 3 5 2 4 4 3 2 4 5 5\n[39] 1 3 2 3 4 2 6 6 6 2 4 4 4 4 6 5 3 3 6 3 5 3 4 3 7 4 1 3 6 5 5 3\n\noob_preds <- pred_sum/n_oob\nsqrt(mean((oob_preds - mite_dat$abundance)^2))\n\n[1] 11.03221"
  },
  {
    "objectID": "live-code/live-code-bagging.html",
    "href": "live-code/live-code-bagging.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\nlibrary(randomForest)\ndata(mite)\ndata(mite.env)\nmite_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG)"
  },
  {
    "objectID": "live-code/live-code-bagging.html#introduction",
    "href": "live-code/live-code-bagging.html#introduction",
    "title": "Live code:",
    "section": "Introduction",
    "text": "Introduction\nWe will use the R package called randomForest is fit bagged decision trees and random forests. Go ahead and install this package in your console!\nAs we will see in the slides, bagged trees and random forests are very similar and can be fit using the same function: randomForest(). The difference lies in the specification of the mtry argument, as we will see below."
  },
  {
    "objectID": "live-code/live-code-bagging.html#bagging",
    "href": "live-code/live-code-bagging.html#bagging",
    "title": "Live code:",
    "section": "Bagging",
    "text": "Bagging\nThe syntax for bagged regression trees is the same as in regular regression trees: response ~ predictors.\nIn bagged regression trees, the only parameter that the modeler needs to choose is the number of bootstrap samples \\(B\\) to obtain (and therefore the number of trees to fit). This is denoted as the ntree argument\nHowever, we will need to specify the additional mtry argument to specify we want to fit a bagged model rather than a random forest. For bagged trees, we set mtry equal to the number of predictors we have.\nIn the following code, I fit B = 10 regression trees, and specify mtry = 5.\n\nset.seed(2)\nn <- nrow(mite_dat)\ntrain_ids <- sample(1:n, 0.8*n)\nbag_mod <- randomForest(abundance ~ . , data = mite_dat[train_ids,],\n                    ntree = 10, \n                    mtry = ncol(mite_dat) - 1)\n\nTo make predictions for the test set, we will use the familiar predict() function:\n\npreds <- predict(bag_mod, newdata = mite_dat[-train_ids,])\npreds\n\n       10        14        20        21        24        25        26        29 \n 0.400000  3.675000  0.700000  5.916667  0.400000  4.125000  6.050000  4.166667 \n       31        37        46        52        63        66 \n 9.240000 24.790000 21.910000 16.800000 19.616667 23.231667 \n\n\n\nOut-of-bag error\nThe nice thing about bootstrapping is that typically ~1/3 of observations are left out in each sample (and therefore, in each one of the B trees). So, we don’t necessarily need to explicitly specify a test/train split!\nIn the following code, a fit a bagged model using all of the available observations:\n\nset.seed(5)\nbag_all <- randomForest(abundance ~ . , data = mite_dat,\n                    ntree = 10, \n                    mtry = ncol(mite_dat) - 1)\n\nThe randomForest() function will automatically create a vector of predicted values for the input data based on the out of bag (OOB) samples; i.e. whenever observation \\(i\\) is OOB (not included in the bootstrap sample) for tree \\(b\\), we can treat \\(i\\) as a test observation and obtain a prediction for it. This is accessed through the predicted component of the fitted model:\n\nbag_all$predicted\n\n          1           2           3           4           5           6 \n 3.86666667  5.27777778  8.30000000  3.75833333  0.00000000  0.31111111 \n          7           8           9          10          11          12 \n 3.61944444  2.79000000  0.60000000  0.15000000  2.00000000  0.88888889 \n         13          14          15          16          17          18 \n 0.00000000  5.92500000 33.70000000  2.06250000  1.52777778  0.66666667 \n         19          20          21          22          23          24 \n32.80000000  1.37500000  4.56250000  0.08571429 12.01111111  2.31250000 \n         25          26          27          28          29          30 \n 0.40000000  7.05555556  0.65000000  7.80000000  0.30000000 19.75000000 \n         31          32          33          34          35          36 \n 4.58333333  0.13333333 21.30000000 16.61000000          NA  9.14285714 \n         37          38          39          40          41          42 \n14.99000000 11.75000000  1.00000000 21.10000000 24.82000000 22.60000000 \n         43          44          45          46          47          48 \n 9.70833333  5.86666667 13.41666667 14.50000000  1.40000000 11.31000000 \n         49          50          51          52          53          54 \n44.11666667 13.25000000 16.25000000 16.81250000 18.13333333 17.58333333 \n         55          56          57          58          59          60 \n19.22000000 16.25000000  2.03666667 11.86666667  7.67000000 20.80000000 \n         61          62          63          64          65          66 \n19.06666667 13.40714286 15.03333333 19.32857143 14.75000000 15.45000000 \n         67          68          69          70 \n 6.20000000 34.00000000  4.54666667  3.50000000 \n\n\nDo you notice anything strange in these predictions?\n\n\nImportance measure\nIn order to obtain a measure of how “important” each predictor is by accessing the importance component. For regression tasks, this corresponds to the total amount that MSE decreases due to splits over a predictor, averaged over B:\n\nbag_all$importance\n\n          IncNodePurity\nSubsDens      2061.6646\nWatrCont      5604.9744\nSubstrate      493.4425\nShrub          470.8712\nTopo          1584.0990\n\n\n\nimportance(bag_all)\n\n          IncNodePurity\nSubsDens      2061.6646\nWatrCont      5604.9744\nSubstrate      493.4425\nShrub          470.8712\nTopo          1584.0990\n\n\nWe can use the varImpPlot() function to visualize the importance:\n\nvarImpPlot(bag_all)"
  },
  {
    "objectID": "live-code/live-code-bagging.html#random-forests",
    "href": "live-code/live-code-bagging.html#random-forests",
    "title": "Live code:",
    "section": "Random Forests",
    "text": "Random Forests\nThe syntax for random forests is almost identical to that of bagging regression trees. Unlike bagging, we need to specify two parameters for random forests:\n\nThe number of bootstrap samples \\(B\\) to obtain (as in bagging)\nThe number of predictors we should consider at each split (i.e. the mtry argument)\n\nIn the following code, I fit B = 10 regression trees, and specify mtry = 2.\n\nset.seed(1)\nrf_mod <- randomForest(abundance ~ . , data = mite_dat,\n                    ntree = 10, \n                    mtry = 2)\n\nEverything else is exactly the same as in bagged regression trees!"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#model-assessment-in-classification",
    "href": "slides/slides-11-confusion-auc.html#model-assessment-in-classification",
    "title": "Model Assessment and KNN Classification",
    "section": "Model assessment in classification",
    "text": "Model assessment in classification\nIn the case of binary response, it is common to create a confusion matrix, from which we can obtain the misclassification rate and other rates of interest\n\n\nFP = “false positive”, FN = “false negative”, TP = “true positive, TN =”true negative\n\n“Success” class is the same as “positive” is the same as “1”\n\nCan calculate the overall error/misclassification rate: the proportion of observations that we misclassified\n\nMisclassification rate = \\(\\frac{\\text{FP} + \\text{FN}}{\\text{TP} + \\text{FP} + \\text{FN} + \\text{TN}} = \\frac{\\text{FP} + \\text{FN}}{n}\\)"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#example",
    "href": "slides/slides-11-confusion-auc.html#example",
    "title": "Model Assessment and KNN Classification",
    "section": "Example",
    "text": "Example\n\n\n\n\n\n\n\npred\ntrue\n\n\n\n\n0\n0\n\n\n1\n1\n\n\n0\n1\n\n\n1\n0\n\n\n1\n1\n\n\n1\n1\n\n\n0\n0\n\n\n0\n0\n\n\n1\n1\n\n\n0\n1\n\n\n\n\n\n\n\n10 observations, with true class and predicted class\nMake a confusion matrix!\n\n\n\n\n\n\n \n\nPred\nTrue\n\n  \n      \n    0 \n    1 \n  \n \n\n  \n    0 \n    3 \n    2 \n  \n  \n    1 \n    1 \n    4"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#mite-data",
    "href": "slides/slides-11-confusion-auc.html#mite-data",
    "title": "Model Assessment and KNN Classification",
    "section": "Mite data",
    "text": "Mite data\nI fit a logistic regression to predict heart present using predictors Topo and WatrCont, and obtained the following confusion matrix of the train data:\n\n\n\n\n \n\nPred\nTrue\n\n  \n      \n    0 \n    1 \n  \n \n\n  \n    0 \n    16 \n    5 \n  \n  \n    1 \n    5 \n    44 \n  \n\n\n\n\n\n\nWhat is the misclassification rate?\n\nMisclassification rate: (5 + 5)/70 = 0.143"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#types-of-errors",
    "href": "slides/slides-11-confusion-auc.html#types-of-errors",
    "title": "Model Assessment and KNN Classification",
    "section": "Types of errors",
    "text": "Types of errors\n\nFalse positive rate (FPR): fraction of negative observations incorrectly classified as positive\n\nNumber of failures/negatives in data = \\(\\text{FP} + \\text{TN}\\)\n\\(\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\\)\n\nFalse negative rate (FNR): fraction of positive observations incorrectly classified as negative example\n\nNumber of success/positives in data = \\(\\text{FN} + \\text{TP}\\)\n\\(\\text{FNR} = \\frac{\\text{FN}}{\\text{FN} + \\text{TP}}\\)"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#mite-data-errors",
    "href": "slides/slides-11-confusion-auc.html#mite-data-errors",
    "title": "Model Assessment and KNN Classification",
    "section": "Mite data errors",
    "text": "Mite data errors\nI fit a logistic regression to predict heart present using predictors Topo and WatrCont, and obtained the following confusion matrix of the train data:\n\nmite_log <- glm(present ~ Topo + WatrCont, data = presence_dat,family = \"binomial\")\n\n\n\n\n\n\n\n\n \n\nPred\nTrue\n\n  \n      \n    0 \n    1 \n  \n \n\n  \n    0 \n    16 \n    5 \n  \n  \n    1 \n    5 \n    44 \n  \n\n\n\n\n\n\nWhat is the misclassification rate?\n\nMisclassification rate: (5 + 5)/70 = 0.143\n\nWhat is the FNR? What is the FPR?\n\nFNR: 5/49 = 0.238\nFPR: 5/21 = 0.102"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#threshold",
    "href": "slides/slides-11-confusion-auc.html#threshold",
    "title": "Model Assessment and KNN Classification",
    "section": "Threshold",
    "text": "Threshold\n\nIs a false positive or a false negative worse? Depends on the context!\nThe previous confusion matrix was produced by classifying an observation as present if \\(\\hat{p}(x)=\\widehat{\\text{Pr}}(\\text{present = 1} | \\text{Topo, WatrCont}) \\geq 0.5\\)\n\nHere, 0.5 is the threshold for assigning an observation to the “present” class\nCan change threshold to any value in \\([0,1]\\), which will affect resulting error rates"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#varying-threshold",
    "href": "slides/slides-11-confusion-auc.html#varying-threshold",
    "title": "Model Assessment and KNN Classification",
    "section": "Varying threshold",
    "text": "Varying threshold\n\n\nOverall error rate minimized at threshold near 0.50\nHow to decide a threshold rate? Is there a way to obtain a “threshold-free” version of model performance?"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#roc-curve",
    "href": "slides/slides-11-confusion-auc.html#roc-curve",
    "title": "Model Assessment and KNN Classification",
    "section": "ROC Curve",
    "text": "ROC Curve\n\nThe ROC curve is a measure of performance for binary classification at various thresholds\n\nROC is a probability curve, and the Area under the curve (AUC) tells us how good the model is at distinguishing between/separating the two classes\n\nThe ROC curve simultaneously plots the true positive rate TPR on the y-axis against the false positive rate FPR on the x-axis\nAn excellent model has AUC near 1 (i.e. near perfect separability), whereas a terrible model has AUC near 0 (always predicts the wrong class)\n\nWhen AUC = 0.5, the model has no ability to separate classes"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#knn-classification-1",
    "href": "slides/slides-11-confusion-auc.html#knn-classification-1",
    "title": "Model Assessment and KNN Classification",
    "section": "KNN Classification",
    "text": "KNN Classification\n\nWhile logistic regression is nice (and still frequently used), the basic model only accommodates binary responses. What if we have a response with more than two classes?\nWe will now see how we can use KNN for classification\n\nSide note: when people refer to KNN, they almost always refer to KNN classification\n\nFinding the neighbor sets proceeds exactly the same as in KNN regression! The difference lies in how we predict \\(\\hat{y}\\)"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#example-mite-data",
    "href": "slides/slides-11-confusion-auc.html#example-mite-data",
    "title": "Model Assessment and KNN Classification",
    "section": "Example: mite data",
    "text": "Example: mite data\n\nThis is a similar plot to that from KNN regression slides, where now points (plotted in standardized predictor space) are colored by present status instead of abundance.\nTwo test points, which we’d like to classify using KNN with \\(K = 3\\)"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#how-would-we-classify",
    "href": "slides/slides-11-confusion-auc.html#how-would-we-classify",
    "title": "Model Assessment and KNN Classification",
    "section": "How would we classify?",
    "text": "How would we classify?\n\n\n\n\n\n\n\n\n\nDiscuss: which class labels would you predict for test points 1 and 2, and why?\n\n\nEstimated conditional class probabilities \\(\\hat{p}_{ij}(\\mathbf{x}_{i})\\) are obtained via simple “majority vote”:\n\n\\(\\hat{p}_{1, \\text{present}}(\\mathbf{x}_{1}) = \\frac{3}{3} = 1\\) and \\(\\hat{p}_{1, \\text{absent}}(\\mathbf{x}_{1}) = \\frac{0}{3} = 0\\)\n\\(\\hat{p}_{2, \\text{present}}(\\mathbf{x}_{2}) = \\frac{1}{3}\\) and \\(\\hat{p}_{2, \\text{absent}}(\\mathbf{x}_{2}) = \\frac{2}{3}\\)"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#beyond-two-classes",
    "href": "slides/slides-11-confusion-auc.html#beyond-two-classes",
    "title": "Model Assessment and KNN Classification",
    "section": "Beyond two classes",
    "text": "Beyond two classes\n\nKNN classification is easily extended to more than two classes!\nWe still follow the majority vote approach: simply predict the class that has the highest representation in the neighbor set\npalmerPenguins data: size measurements for adult foraging Adélie, Chinstrap, and Gentoo penguins\nWe will classify penguin species by size measurements!"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#knn-classification-different-k",
    "href": "slides/slides-11-confusion-auc.html#knn-classification-different-k",
    "title": "Model Assessment and KNN Classification",
    "section": "KNN classification: different K",
    "text": "KNN classification: different K\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat class would you predict for the test point when \\(K = 9\\)?\nWhat class would you predict for the test point when \\(K = 5\\)?"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#handling-ties",
    "href": "slides/slides-11-confusion-auc.html#handling-ties",
    "title": "Model Assessment and KNN Classification",
    "section": "Handling ties",
    "text": "Handling ties\n\nAn issue we may encounter in KNN classification is a tie\n\nIt is possible that no single class is a majority!\n\n\nDiscuss: how would you handle ties in the neighbor set?"
  },
  {
    "objectID": "slides/slides-10-logistic.html#logistic-regression-model",
    "href": "slides/slides-10-logistic.html#logistic-regression-model",
    "title": "Classification & Logistic Regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\n\nAssume first that we have a single predictor \\(X\\)\nLet \\(p({x}) = \\text{Pr}(Y = 1 | {X} = {x})\\)\n\nFor binary response \\((J = 2)\\), we shorthand the conditional class probability to always be in terms of a “success” class\n\nNeed to somehow restrict \\(0 \\leq p(x) \\leq 1\\)\nLogistic regression uses logistic function: \\[p({x}) = \\frac{e^{\\beta_{0} + \\beta_{1}x}}{1 + e^{\\beta_{0} + \\beta_{1}x}}\\]"
  },
  {
    "objectID": "live-code/live-code-logistic.html",
    "href": "live-code/live-code-logistic.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nlibrary(vegan)\ndata(mite)\ndata(mite.env)\npresence_dat <- mite.env %>%\n  add_column(abundance = mite$LRUG) %>%\n  mutate(present = ifelse(abundance > 0, 1, 0)) %>%\n  select(-abundance)"
  },
  {
    "objectID": "live-code/live-code-logistic.html#running-logistic-regression",
    "href": "live-code/live-code-logistic.html#running-logistic-regression",
    "title": "Live code:",
    "section": "Running logistic regression",
    "text": "Running logistic regression\nTo run a logistic regression model in R, we will use the glm() function, which will take similar inputs to lm(). Besides the different function name, we need to specify we would like to run a logistic regression model as opposed to a different kind of generalized linear model. This is achieved by setting the family argument equal to “binomial”:\n\ntest_ids <- 1:3\npresence_mod <- glm(present ~ WatrCont + Topo, data = presence_dat[-test_ids,],\n                    family = \"binomial\")\n\nThen, we can use the summary() function and predict() function as usual:\n\nsummary(presence_mod)\n\n\nCall:\nglm(formula = present ~ WatrCont + Topo, family = \"binomial\", \n    data = presence_dat[-test_ids, ])\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.6817  -0.5995   0.3407   0.5027   1.9611  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)   \n(Intercept) -0.538291   1.284897  -0.419  0.67526   \nWatrCont     0.006958   0.003160   2.202  0.02769 * \nTopoHummock -2.237473   0.714437  -3.132  0.00174 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 77.977  on 66  degrees of freedom\nResidual deviance: 51.959  on 64  degrees of freedom\nAIC: 57.959\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor logistic regression using glm(), your response variable must be encoded as either:\n\nA numeric 0 or 1, where 1 represents the success class\nA factor variable with two levels, where the base level is the 0 class\n\nYou will get a strange error if your response variable is categorical!"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#roc-curve-cont.",
    "href": "slides/slides-11-confusion-auc.html#roc-curve-cont.",
    "title": "Model Assessment and KNN Classification",
    "section": "ROC Curve (cont.)",
    "text": "ROC Curve (cont.)\nROC and AUC for the training data:\n\n\nHow do you think we did?"
  },
  {
    "objectID": "slides/slides-11-confusion-auc.html#model-assessment-in-classification-cont.",
    "href": "slides/slides-11-confusion-auc.html#model-assessment-in-classification-cont.",
    "title": "Model Assessment and KNN Classification",
    "section": "Model assessment in classification (cont.)",
    "text": "Model assessment in classification (cont.)\n\nFP = “false positive”, FN = “false negative”, TP = “true positive, TN =”true negative\n\n“Success” class is the same as “positive” is the same as “1”\n\nCan calculate the overall error/misclassification rate: the proportion of observations that we misclassified\n\nMisclassification rate = \\(\\frac{\\text{FP} + \\text{FN}}{\\text{TP} + \\text{FP} + \\text{FN} + \\text{TN}} = \\frac{\\text{FP} + \\text{FN}}{n}\\)"
  },
  {
    "objectID": "live-code/live-code-logistic.html#predictions",
    "href": "live-code/live-code-logistic.html#predictions",
    "title": "Live code:",
    "section": "Predictions",
    "text": "Predictions\n\nLog-odds and probabilities\n\npredict(presence_mod, newdata = presence_dat[test_ids,])\n\n         1          2          3 \n-0.3392814  0.2498166 -0.1891887 \n\n\nNotice that this prediction doesn’t seem the most intuitive. We are interested in the probability of the mite being present, but the prediction here is negative! This is because the default option from predict() for logistic regression is to return the predicted log-odds of the success outcome, as that is the response for the regression, i.e. \\(\\log\\left(\\frac{p(x)}{1-p(x)}\\right) = \\beta_{0} + \\beta_{1}\\text{WatrCont} + \\beta_{2} \\text{Topo}\\).\nIf we want the predictions on the probability scale, we need specify an additional argument in predict():\n\npredict(presence_mod, newdata = presence_dat[test_ids,], type = \"response\")\n\n        1         2         3 \n0.4159841 0.5621314 0.4528434 \n\n\nAs a sanity check, we can confirm this matches the predicted log-odds based on the model:\n\npred_prob <- predict(presence_mod, newdata = presence_dat[test_ids,], type = \"response\")\nlog(pred_prob / (1-pred_prob))\n\n         1          2          3 \n-0.3392814  0.2498166 -0.1891887 \n\n\n\n\nSuccess/failure\nIf we want to explicitly predict a class, we need to choose a threshold value and classify a test observation as a “success” or “failure” depending on the threshold the predicted probability of success:\n\nn_test <- length(test_ids)\nthreshold <- 0.5\npred_class <- rep(NA, n_test)\nfor(i in 1:n_test){\n  if(pred_prob[i] >= threshold){\n    pred_class[i] <- 1\n  }\n  else{\n   pred_class[i] <- 0\n  }\n}\n\npred_class\n\n[1] 0 1 0\n\n\nThis for() loop seems like too much code for such a simple idea! Let’s try taking advantage of vectors and booleans. Note that in R, the boolean TRUE is encoded as a numeric 1, and FALSE as a 0:\n\npred_prob >= threshold\n\n    1     2     3 \nFALSE  TRUE FALSE \n\npred_class <- as.numeric(pred_prob >= threshold)\npred_class\n\n[1] 0 1 0\n\n\nWhat is our misclassification error rate here?\n\ntrue_class <- presence_dat$present[test_ids]\ntrue_class\n\n[1] 0 0 0\n\nmean(true_class == pred_class)\n\n[1] 0.6666667"
  },
  {
    "objectID": "implementations/implementation_knn_classification.html",
    "href": "implementations/implementation_knn_classification.html",
    "title": "KNN classification",
    "section": "",
    "text": "You and your (optional) group will implement KNN classification. You should feel free to copy whatever code is relevant from your KNN regression implementation.\nI encourage you to work together, though each person should still submit their own individual document to Canvas!"
  },
  {
    "objectID": "implementations/implementation_knn_classification.html#discuss",
    "href": "implementations/implementation_knn_classification.html#discuss",
    "title": "KNN classification",
    "section": "Discuss",
    "text": "Discuss\nWith your group, discuss which parts of the KNN regression code you will need to modify and how in order to implement classification. Once you feel ready, clone the GitHub project called knn_classification and work in the file knn_classification_implementation.Rmd.\n\nImplement\n\nYour final implementation must be a function called .knn_class() (note the period) that takes in the “minimal amount” of inputs and returns a vector of the predicted labels for the test data. You may assume that the response variable is of type factor. Your code must be as reproducible as possible, and should accommodate ties when predicting a label by randomly choosing one of the tied labels!\n\n\n\nDeliverable\nOnce you’ve finished your implementation, check it by seeing if you get the same predicted labels as I do below using the following seed, choice of K, and train/test sets from the palmerpenguins dataset. You may need to install the package in your console first!\n\nlibrary(palmerpenguins)\npenguins2 <- penguins %>%\n  filter(year == 2009) %>%\n  select(species, bill_depth_mm, flipper_length_mm) %>%\n  na.omit() \nset.seed(2)\nK <- 4\nn <- nrow(penguins2)\ntrain_ids <- sample(1:n, n*0.8)\ntrain_dat <- penguins2[train_ids,]\ntest_dat <- penguins2[-train_ids,]\n\n\n\n\n\npred_y\n\n [1] \"Chinstrap\" \"Adelie\"    \"Adelie\"    \"Adelie\"    \"Adelie\"    \"Adelie\"   \n [7] \"Gentoo\"    \"Adelie\"    \"Adelie\"    \"Adelie\"    \"Gentoo\"    \"Gentoo\"   \n[13] \"Gentoo\"    \"Gentoo\"    \"Gentoo\"    \"Gentoo\"    \"Gentoo\"    \"Gentoo\"   \n[19] \"Gentoo\"    \"Chinstrap\" \"Adelie\"    \"Adelie\"    \"Adelie\"    \"Adelie\"   \n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is possible we may get slightly different predictions if we implemented the random sampling differently. However, you should at least have the same predictions as I do for the following indices of the test data:\n\n\n [1]  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 22 24\n\n\n\n\nThen, re-create the following table and use code to obtain and report the misclassification test error:\n\ntable(preds = pred_y, true = test_y)\n\n           true\npreds       Adelie Chinstrap Gentoo\n  Adelie         8         4      0\n  Chinstrap      1         1      0\n  Gentoo         1         0      9"
  },
  {
    "objectID": "live-code/live-code-class_imbalance.html",
    "href": "live-code/live-code-class_imbalance.html",
    "title": "Live code",
    "section": "",
    "text": "library(tidyverse)\nlibrary(pROC)"
  },
  {
    "objectID": "live-code/live-code-class_imbalance.html#introduction",
    "href": "live-code/live-code-class_imbalance.html#introduction",
    "title": "Live code",
    "section": "Introduction",
    "text": "Introduction\nThe haberman dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago’s Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n\nlibrary(imbalance)\ndata(haberman)\nhaberman %>% \n  slice(1:5)\n\n  Age Year Positive    Class\n1  38   59        2 negative\n2  39   63        4 negative\n3  49   62        1 negative\n4  53   60        2 negative\n5  47   68        4 negative\n\n\n\nVariables:\n\nAge: age of patient at time of operation\nYear: patient’s year of operation\nPositive: number of positive axillary nodes detected\nClass: Two possible survival status: “positive” (survival rate of less than 5 years), “negative” (survival rate or more than 5 years)\n\nWe may be interested in predicting the probability of survival"
  },
  {
    "objectID": "live-code/live-code-class_imbalance.html#imbalanced-data",
    "href": "live-code/live-code-class_imbalance.html#imbalanced-data",
    "title": "Live code",
    "section": "Imbalanced data",
    "text": "Imbalanced data\n\nhaberman %>%\n  count(Class) %>%\n  mutate(prop = n / sum(n))\n\n     Class   n      prop\n1 negative 225 0.7352941\n2 positive  81 0.2647059\n\n\n\nWhat do you notice?\n\n“Class imbalance”: one (or more, if \\(J \\geq 2\\)) of the possible labels is several underrepresented in the data\n\nDiscuss: I claim that class imbalance is an issue for predictive models! Why do you think that is?"
  },
  {
    "objectID": "live-code/live-code-class_imbalance.html#logistic-regression",
    "href": "live-code/live-code-class_imbalance.html#logistic-regression",
    "title": "Live code",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nset.seed(2)\nhaberman <- haberman %>%\n  mutate(Class = ifelse(Class == \"positive\", 1, 0))\nn <- nrow(haberman)\ntrain_ids <- sample(1:n, 0.8*n)\ntrain_dat <- haberman[train_ids,]\ntest_dat <- haberman[-train_ids,]\nlog_mod <- glm(Class ~ Positive, data = train_dat, family = \"binomial\")\npred_probs <- predict(log_mod, newdata = test_dat, type = \"response\")\npred_class <- as.numeric(pred_probs >= 0.5)\ntable(preds = pred_class, true = test_dat$Class)\n\n     true\npreds  0  1\n    0 44 12\n    1  3  3\n\nroc(test_dat$Class,  pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\n\nCall:\nroc.default(response = test_dat$Class, predictor = pred_class)\n\nData: pred_class in 47 controls (test_dat$Class 0) < 15 cases (test_dat$Class 1).\nArea under the curve: 0.5681"
  },
  {
    "objectID": "live-code/live-code-class_imbalance.html#oversampling",
    "href": "live-code/live-code-class_imbalance.html#oversampling",
    "title": "Live code",
    "section": "Oversampling",
    "text": "Oversampling\n\n# Randomly duplicating examples from the minority class and adding them to the training dataset.\nset.seed(3)\ntrain_minority <- which(train_dat$Class == 1)\ntrain_majority <- which(train_dat$Class == 0)\nn_min <- length(train_minority)\nn_maj <- length(train_majority)\nover_ids <- sample(train_minority, size = 40, replace = T)\n\ntrain_dat_oversample <- rbind(train_dat, train_dat[over_ids,])\nmod_oversample <-  glm(Class ~ Positive, data = train_dat_oversample, family = \"binomial\")\npred_probs <- predict(mod_oversample, newdata = test_dat, type = \"response\")\npred_class <- as.numeric(pred_probs >= 0.5) \ntable(preds = pred_class, true = test_dat$Class)\n\n     true\npreds  0  1\n    0 41 10\n    1  6  5\n\n# the random oversampling may increase the likelihood of overfitting occurring, since it makes exact copies of the minority class examples\nroc(test_dat$Class,  pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\n\nCall:\nroc.default(response = test_dat$Class, predictor = pred_class)\n\nData: pred_class in 47 controls (test_dat$Class 0) < 15 cases (test_dat$Class 1).\nArea under the curve: 0.6028"
  },
  {
    "objectID": "live-code/live-code-class_imbalance.html#undersampling",
    "href": "live-code/live-code-class_imbalance.html#undersampling",
    "title": "Live code",
    "section": "Undersampling",
    "text": "Undersampling\n\n# Randomly remove examples from the majority class in the training dataset.\nset.seed(3)\nremove_ids <- sample(train_majority, n_maj - n_min, replace = F)\n\nmod_undersample <-  glm(Class ~ Positive, data = train_dat[-remove_ids,], family = \"binomial\")\npred_probs <- predict(mod_undersample, newdata = test_dat, type = \"response\")\npred_class <-as.numeric(pred_probs >= 0.5) \ntable(preds = pred_class, true = test_dat$Class)\n\n     true\npreds  0  1\n    0 34  8\n    1 13  7\n\n# the random oversampling may increase the likelihood of overfitting occurring, since it makes exact copies of the minority class examples\nroc(test_dat$Class,  pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\n\nCall:\nroc.default(response = test_dat$Class, predictor = pred_class)\n\nData: pred_class in 47 controls (test_dat$Class 0) < 15 cases (test_dat$Class 1).\nArea under the curve: 0.595"
  },
  {
    "objectID": "project/merge-conflicts.html",
    "href": "project/merge-conflicts.html",
    "title": "Merge Conflicts",
    "section": "",
    "text": "Everyone: decide on a team name\nEveryone: Clone your project repo from GitHub and open up the R Markdown file called project-proposal.Rmd\nAssign the numbers 1-4 to each of the team members.\nTake turns in completing the steps below as written, one member at a time:\n\nMember 1: Change the team name in project-proposal.Rmd to something different from your team name. Knit, commit, and push.\nMember 2: Without pulling first, change the team name to the correct name in your version of project-proposal.Rmd. Knit, commit, and push.\n\nYou will get an error in GitHub Desktop, and be asked to FETCH the changes. Show the error to your team members.\n\nA MERGE CONFLICT occurred because you edited the same part of the document as Member 1. Resolve the conflict with whichever name you want to keep.\n\nKnit, commit and push. You should have no issues pushing now!\n\nMember 3: Change the date to the date the proposal is due (04/23/2023).\n\nKnit, commit, push. You will get an error asking you to fetch. Read it, show the error to your group.\nPull the new changes. No merge conflicts should occur, since you edited a different part of the document from Members 1 and 2.\nKnit, commit, and push your changes.\n\nMember 4: Add everyone’s names in the author section.\n\nKnit, commit, push. You will get an error asking you to fetch. Read it, show the error to your group.\nPull the new changes. No merge conflicts should occur, since you edited a different part of the document from Members 1-3.\nKnit, commit, and push your changes.\n\nEveryone: Pull, and observe the changes in your document (although Member 4 shouldn’t observe any because they have the most recent version)"
  },
  {
    "objectID": "project/merge-conflicts.html#helpful-tips",
    "href": "project/merge-conflicts.html#helpful-tips",
    "title": "Merge Conflicts",
    "section": "Helpful Tips",
    "text": "Helpful Tips\n\nConsider working in the same space with your group members when possible (although with large groups it’s difficult to crowd around a single laptop)\nEach team member can create their own R Markdown document that only they work in. That way, those individual/personal documents shouldn’t have merge conflicts. Then when it becomes necessary, you can work in and add to the entire group’s .Rmd file."
  },
  {
    "objectID": "labs/lab-05-logistic-knn-class.html#introduction",
    "href": "labs/lab-05-logistic-knn-class.html#introduction",
    "title": "Lab 05: Logistic Regression + KNN Classification",
    "section": "Introduction",
    "text": "Introduction\nWe will try to predict if it rained the next day in Wagga Wagga, Australia given certain environmental and climate conditions the previous day. Our data, obtained from Kaggle, consist of measurements of these variables on Fridays from 2009-2016.\n\n\n\n\n\nThe variables are as follows:\n\nEvaporation: The so-called Class A pan evaporation (mm) in the 24 hours to 9am\nSunshine: The number of hours of bright sunshine in the day\nWindSpeed3pm: Wind speed (km/hr) averaged over 10 minutes prior to 3pm\nHumidity3pm: Humidity (percent) at 3pm\nPressure3pm: Atmospheric pressure (hpa) reduced to mean sea level at 3pm\nCloud3pm: Fraction of sky obscured by cloud (in “oktas”: eighths) at 3pm\nTemp3pm: Temperature (degrees C) at 3pm\nRainTomorrow: “yes” or “no” for whether it rained the next day"
  },
  {
    "objectID": "labs/lab-05-logistic-knn-class.html#data",
    "href": "labs/lab-05-logistic-knn-class.html#data",
    "title": "Lab 05: Logistic Regression + KNN Classification",
    "section": "Data",
    "text": "Data\nFirst, load in your data located in the weatherWaggaWagga.csv file. We will consider RainTomorrow = \"yes\" to be the success class.\n\nPick one quantitative variable and create side-by-side boxplots that display the distribution of that variable for each level of RainTomorrow. Also display a table of the total number of successes and failures in the data. Interpret your plot, and comment on the table."
  },
  {
    "objectID": "labs/lab-05-logistic-knn-class.html#part-1-validation-set-approach",
    "href": "labs/lab-05-logistic-knn-class.html#part-1-validation-set-approach",
    "title": "Lab 05: Logistic Regression + KNN Classification",
    "section": "Part 1: validation set approach",
    "text": "Part 1: validation set approach\nWe will compare the performance of logistic regression with that of KNN classification using a validation set approach.\n\nTest/train split\n\n\n\n\nFirst split your data into an 80% train and 20% test set using a seed of 41.\n\n\n\n\n\n\nLogistic regression\n\nFit the model\n\nFit a logistic regression to the training data for RainTomorrow using all the remaining variables in the dataset. Display a summary of the model, and interpret the coefficient for the variable you chose to visualize in the EDA section. How, if at all, is the probability of it raining tomorrow in Wagga Wagga associated with that predictor?\n\n\n\n\n\n\n\nNote\n\n\n\nHypothesis tests of the form \\(H_{0}: \\ \\beta_{j} =0\\) vs \\(H_{a}: \\ \\beta_{j} \\neq 0\\) can be formulated for the coefficients in logistic regression just as they are in linear regression!\n\n\n\n\n\n\n\nPredict\nNow, obtain predicted labels for the test data using a threshold probability of 0.5. Importantly, because the data are in \"yes\"/\"no\" and not 1/0, your predictions should also be in terms of \"yes\"/\"no\".\n\nThen create a confusion matrix for the test set. Using code that is as reproducible as possible, obtain and report the misclassification rate, false negative rate, and false positive rate for the data. This can be achieved using either tidyverse or base R.\nComment on which is larger: your FPR or your FNR. Do these values make sense to you given the data?\n\n\n\n\n\n\n\nKNN Classification\nNow we will fit a KNN model to predict RainTomorrow using K = 20 neighbors. Set a seed of 41 in case there are ties. As our predictors are on completely different scales, first properly standardize your train and test data sets before fitting the model. You may either use your own implementation of KNN classification, or you may use the knn() function from the class library. Paste any functions you may need in the chunk labeled functions at the top of the document.\n\nUnder this model, create a confusion matrix for the test set. Using reproducible code, obtain and report the misclassification rate, false negative rate, and false positive rate for the data.\nHow do your rates and the predicted labels themselves compare to those obtained under the logistic regression model?"
  },
  {
    "objectID": "labs/lab-05-logistic-knn-class.html#part-2-stratified-k-fold-cv",
    "href": "labs/lab-05-logistic-knn-class.html#part-2-stratified-k-fold-cv",
    "title": "Lab 05: Logistic Regression + KNN Classification",
    "section": "Part 2: stratified k-fold CV",
    "text": "Part 2: stratified k-fold CV\nAt this point, we know that k-fold CV is a better approach to estimating the test error compared to a validation set approach. For this lab, we will implement stratified k-fold CV. In stratified k-fold CV, the proportions of each label in each fold should be representative of the proportion of each label in the entire data set.\n\nCreate folds\n\nHere, create your list of fold indices for stratified k-fold CV using 10 folds of roughly equal size. Set a seed of 41 again. “Roughly equal” means that either all 10 folds are the same size, or 9 folds have the same size and the tenth fold has a little less.\nYour code should be as reproducible as possible! That means it should not be specific to this specific data or number of folds. This is the most difficult part of the lab, so think carefully about what you want to do! It could be helpful to write down your thoughts.\n\n\n\n\n\n\nLogistic regression\nNow, fit the logistic regression model again, but now using the stratified 10-fold CV approach to estimate the test error.\n\nReport the estimated test misclassification, false negative, and false positive rates under this model.\n\n\n\n\n\n\nKNN classification\nOnce again using K = 20 neighbors and 10 folds, fit a KNN classification model with stratified k-fold CV using standardized predictors. Set a seed of 41 again.\n\nReport the estimated test misclassification, false negative, and false positive rates under this model. How do the prediction performances of your two models compare based on the estimated test error using stratified 10-fold CV?"
  },
  {
    "objectID": "labs/lab-05-logistic-knn-class.html#part-3-comprehension",
    "href": "labs/lab-05-logistic-knn-class.html#part-3-comprehension",
    "title": "Lab 05: Logistic Regression + KNN Classification",
    "section": "Part 3: Comprehension",
    "text": "Part 3: Comprehension\n\nI also obtained estimates of the test error rates when performing regular 10-fold CV (i.e. non-stratified). The following shows my results:\n\n\n\n\n\n \n  \n      \n    Misclass. rate \n    FNR \n    FPR \n  \n \n\n  \n    Logistic \n    0.1114 \n    0.4322 \n    0.0313 \n  \n  \n    KNN \n    0.1229 \n    0.6028 \n    0.0106 \n  \n\n\n\n\n\nBased on these results, what comparisons (if any) can you make about the performance of the models fit here and the models fit in Part 1 or Part 2? What is the correct way to explain why the results I obtained here are different than the rates you obtained via stratified k-fold CV (apart from the simple fact that we used different fold ids)?\n\nCompare the magnitudes of your estimated misclassification test error rates when using the validation set approach vs the stratified k-fold CV approach. Does this make sense to you? Why or why not?\nIn this problem, do you think a false positive or a false negative rate is worse? Based on your answer, should you increase or decrease the threshold? Why?"
  },
  {
    "objectID": "labs/lab-05-logistic-knn-class.html#submission",
    "href": "labs/lab-05-logistic-knn-class.html#submission",
    "title": "Lab 05: Logistic Regression + KNN Classification",
    "section": "Submission",
    "text": "Submission\nWhen you’re finished, knit to PDF one last time and upload the PDF to Canvas. Commit and push your code back to GitHub one last time."
  },
  {
    "objectID": "live-code/live-code-classification-trees.html",
    "href": "live-code/live-code-classification-trees.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\nobesity <- read.csv(\"https://raw.githubusercontent.com/math218-spring2023/class-data/main/obesity.csv\")\n\nobesity <- obesity %>%\n  mutate_if(is.character, factor)\nobesity %>%\n  count(class)\n\n          class   n\n1  Insufficient 272\n2        Normal 287\n3       Obese_I 351\n4      Obese_II 297\n5     Obese_III 324\n6  Overweight_I 290\n7 Overweight_II 290"
  },
  {
    "objectID": "live-code/live-code-classification-trees.html#traintest-split",
    "href": "live-code/live-code-classification-trees.html#traintest-split",
    "title": "Live code:",
    "section": "Train/test split",
    "text": "Train/test split\n\nset.seed(1)\nn <- nrow(obesity)\ntrain_ids <- sample(1:n, 0.8*n)\ntrain_dat <- obesity[train_ids,]\ntest_dat <- obesity[-train_ids,]"
  },
  {
    "objectID": "live-code/live-code-classification-trees.html#fit-classification-tree-prune",
    "href": "live-code/live-code-classification-trees.html#fit-classification-tree-prune",
    "title": "Live code:",
    "section": "Fit classification tree + prune",
    "text": "Fit classification tree + prune\n\nlibrary(tree)\nmy_tree <- tree(class ~ ., data = train_dat,\n                       control = tree.control(nobs = nrow(train_dat), minsize = 2))\ncv_tree <- cv.tree(my_tree, FUN = prune.misclass)\nbest_size <- min(cv_tree$size[which(cv_tree$dev == min(cv_tree$dev))])\n## equivalent to: prune.tree(my_tree, best = best_size, method - \"misclass\")\nprune_tree <- prune.misclass(my_tree, best = best_size)\nplot(prune_tree)\ntext(prune_tree, pretty = 0, cex = 0.6)\n\n\n\n\n\nObtain predictions\n\nhead(predict(prune_tree, newdata = test_dat))\n\n   Insufficient     Normal   Obese_I   Obese_II Obese_III Overweight_I\n3    0.00000000 0.09395973 0.0000000 0.00000000         0    0.5302013\n4    0.00000000 0.09395973 0.0000000 0.00000000         0    0.5302013\n6    0.01190476 0.89285714 0.0000000 0.00000000         0    0.0952381\n10   0.00000000 0.11382114 0.0000000 0.00000000         0    0.8536585\n18   0.00000000 0.00000000 1.0000000 0.00000000         0    0.0000000\n24   0.00000000 0.00000000 0.9519231 0.02884615         0    0.0000000\n   Overweight_II\n3     0.37583893\n4     0.37583893\n6     0.00000000\n10    0.03252033\n18    0.00000000\n24    0.01923077\n\nhead(predict(prune_tree, newdata = test_dat, type = \"class\"))\n\n[1] Overweight_I Overweight_I Normal       Overweight_I Obese_I     \n[6] Obese_I     \n7 Levels: Insufficient Normal Obese_I Obese_II Obese_III ... Overweight_II\n\ntree_preds <- predict(prune_tree, newdata = test_dat, type = \"class\")\n\nmean(tree_preds != test_dat$class)\n\n[1] 0.1583924"
  },
  {
    "objectID": "live-code/live-code-classification-trees.html#bagged-classification-trees",
    "href": "live-code/live-code-classification-trees.html#bagged-classification-trees",
    "title": "Live code:",
    "section": "Bagged classification trees",
    "text": "Bagged classification trees\n\nlibrary(randomForest)\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nmy_bag <- randomForest(class ~ ., data = obesity, ntree = 100,\n             mtry = ncol(obesity) - 1)\nvarImpPlot(my_bag)\n\n\n\nbag_preds <- my_bag$predicted[-train_ids]\nmean(bag_preds != test_dat$class)\n\n[1] 0.02600473"
  },
  {
    "objectID": "live-code/live-code-classification-trees.html#random-forest-classification",
    "href": "live-code/live-code-classification-trees.html#random-forest-classification",
    "title": "Live code:",
    "section": "Random forest classification",
    "text": "Random forest classification\n\nm <- round(sqrt(ncol(obesity)-1))\nmy_rf <- randomForest(class ~ ., data = obesity, ntree = 100,\n                           mtry = m)\nvarImpPlot(my_rf)\n\n\n\nrf_preds <- my_rf$predicted[-train_ids]\nmean(rf_preds != test_dat$class)\n\n[1] 0.04964539"
  },
  {
    "objectID": "implementations/implementation_bagging_classification.html",
    "href": "implementations/implementation_bagging_classification.html",
    "title": "Bagging",
    "section": "",
    "text": "Today, we will implement a bagged classification tree model using B trees. For the final project, you are welcome to use the functions from the randomForest library. We will specifically implement a bagged classification tree model where the predictions are obtained using the out-of-bag (OOB) observations for each tree \\(b = 1, 2, \\ldots, B\\).\n\nlibrary(tidyverse)\nlibrary(tree)\n\nStarter code can be found in your bag-classification-tree-implementation GitHub repo. We will be working with the seeds.txt data, found in the data folder of this repo."
  },
  {
    "objectID": "implementations/implementation_bagging_classification.html#oob-predictions-for-bagging-classification-trees",
    "href": "implementations/implementation_bagging_classification.html#oob-predictions-for-bagging-classification-trees",
    "title": "Bagging",
    "section": "OOB predictions for bagging classification trees",
    "text": "OOB predictions for bagging classification trees\nRemember that different observations will be excluded from each bootstrap sample. So you have to be clever about how you keep track of the predictions (and how many times an observation is OOB). Refer back to the live code from bagging regression trees for a refresher/starter code!\nHow do we obtain predictions for bagging classification trees?\n\nOption 1\nFor classification trees, we typically “aggregate” the predictions by taking the majority vote approach: for a given test/OOB observation, we predict the label \\(j\\) that has the highest representation across the trees for which it was OOB. For example, if \\(B = 10\\), and observation \\(y_{0}\\) was OOB 6 times with the following counts of predicted labels:\n\n\n  label count\n1     A     3\n2     B     1\n3     C     0\n4     D     2\n\n\nwe would predict label \\(\\hat{y}_{0}\\) = \"A\".\nA slight twist here is that we will have more than observation to keep track of across the \\(B\\) trees!\n\n\n\n\n\n\nNote\n\n\n\nNote: it’s possible that we have ties in predicted labels in bagging. For the purposes of this lab, you don’t have to worry about tied majority votes (so you can use the which.max() function if that’s helpful to you), but know that ties are possible!\n\n\n\n\nOption 2\nAnother way we can make make a prediction is to keep track of the estimated conditional class probabilities from each tree \\(b\\). Then, after iterating through all the \\(B\\) trees, we predict the label that has the highest average conditional class probability (where the average is taken with respect to the number of times the observation was OOB). For example, if the average conditional probabilities are as follows:\n\n\n  label avg_cond_prob\n1     A           0.1\n2     B           0.5\n3     C           0.0\n4     D           0.4\n\n\nthen I would predict \\(\\hat{y}_{0} =\\) \"B\".\n\n\n\n\n\n\nNote\n\n\n\nNote: it’s possible that we have ties in predicted conditional class probabilities as well. For the purposes of this lab, you don’t have to worry about ties here either!"
  },
  {
    "objectID": "implementations/implementation_bagging_classification.html#implementation",
    "href": "implementations/implementation_bagging_classification.html#implementation",
    "title": "Bagging",
    "section": "Implementation",
    "text": "Implementation\nNow, implement bagged classification trees where we obtain predictions using the OOB observations. We will predict seed variety using all the remaining predictors available in the data. Set a seed of 218, and use B = 100 trees.\n\n\n\n\nYou should obtain two sets of OOB predictions using bagged classification trees: one set where we use Option 1 (majority of majority class), and the other set were we use Option 2 (majority of average conditional class probabilities).\n\nWe will then compare if the predictions using both options agree with each other. For this reason, you should only run the for loop over the \\(B\\) trees once in this implementation. We want to ensure that both options see the same bootstrapped datasets.\n\n\n\n\n\n\nNote\n\n\n\nI suggest you begin by focusing on a single option! Would you like to keep track of counts (Option 1) or probabilities (Option 2) first?"
  },
  {
    "objectID": "implementations/implementation_bagging_classification.html#results",
    "href": "implementations/implementation_bagging_classification.html#results",
    "title": "Bagging",
    "section": "Results",
    "text": "Results\n\n\nAfter you’ve obtained your two sets of predictions, using the table() function to compare the predictions you obtained from Option 1 vs Option 2. Do the two methods lead to predictions that agree with each other? If there are are disagreements, clearly specify what the disagreements are.\nWhat proportion of the time was each observation in your dataset out-of-bag? Does this agree with the theoretical result we obtained a few weeks ago about bootstrapping?"
  },
  {
    "objectID": "implementations/implementation_kmeans.html",
    "href": "implementations/implementation_kmeans.html",
    "title": "K-means",
    "section": "",
    "text": "For this assignment, you will implement the two-means clustering algorithm that we learned in class. The algorithm iterates between two steps, so the implementation will ask you to create two functions that perform these step. You will then call/use these two functions in your code.\nBecause this implementation has many steps, there are some provided “code checks” along the way. After each part of this implementation, you should verify that your code is working properly.\nYour code should be as reproducible as possible!"
  },
  {
    "objectID": "implementations/implementation_kmeans.html#creating-functions",
    "href": "implementations/implementation_kmeans.html#creating-functions",
    "title": "K-means",
    "section": "Creating functions",
    "text": "Creating functions\nTo get started, we will need some data. In the following, I generate \\(n = 50\\) observations with \\(p=2\\) features each. The data are generated to have two true clusters: the first 25 observations are in cluster 1 and the second 25 observations belong to cluster 2. I also add an id column to keep track of the observation’s index. Take a look at df to see the data.\n\n\n\nWe will run 2-means clustering.\n\nPart 1: defining variables\nCreate/store three variables:\n\n\\(n\\): the number of observations\n\\(p\\): the number of features\n\\(K\\): the number of clusters\n\n\n# your code\n\n\n\nPart 2: formatting\nThe data frame df currently only has the features and id for each observation. However, because \\(K\\)-means re-assigns each observation to a cluster, we should add another column to df:\n\ncluster: holds the cluster assignment of the observation\n\nBecause we haven’t yet assigned observations to clusters, simply assign the first half of the observations to cluster 1, and the second half to cluster 2. This literally means the first and second halves of the observations in df as it currently looks (i.e. do not assign the clusters based on id).\nNote: we won’t use these clusters yet, but it’s good to have a data frame with all variable/columns defined prior to running the algorithm.\n\n# your code\n\n\n\nPart 3: obtain initial centroids and store into a data frame\nAs discussed in class, there are many ways we could initialize the centroids. For the sake of getting the code running, for now you can simply take the first \\(K\\) observations as your centroids. Create a data frame called centroid_df that has \\(K\\) rows and the following \\(p+1\\) columns:\n\ncluster: which of the \\(K\\) clusters the centroid corresponds to. This is arbitrary, so simply assign cluster to be 1, 2, … K to each centroid.\nthe remaining \\(p\\) columns should hold the \\(p\\) feature values\n\nYou might want to consider slice()-ing or indexing the original df data frame.\n\n# your code\n\n\n\n\n\n\n\nCODE CHECK\n\n\n\n\n\nYour centroid_df data frame should look like this:\n\n\n\n\n\n\n\n\n\n\nPart 4: re-assign step\nWrite a function called get_clusts() that finds the nearest centroid to each observation. Specifically, you should return a vector of the new cluster assignments. I suggest passing in the following arguments into your function:\n\nn: the number of observations\ncentroids: a \\(K \\times p\\) data frame of the centroids’ feature values only\nX: an \\(n \\times p\\) data frame of the observed data’s feature values only\nSome helpful hints:\n\nYou will most likely want to write a for loop in this function\nTo calculate the Euclidean distance between a vector x another vector y, you can paste in your Euclidean distance function that you created into the code chunk at the top of the document. Then you can use your distance function in your implementation\nYou may assume there aren’t any ties in distance!\n\n\n\nget_clusts <- function(_____){\n  # your code here\n}\n\n\n\n\n\n\n\nCODE CHECK\n\n\n\n\n\nIf you run your get_clusts() function on the current data, you should return the following vector of cluster assignments:\n\n\n\n\n\n\n\n\n\n\nPart 5: obtain centroids\nWe’re so close! Write a function called get_centroids() that finds the centroid of each cluster. You should pass in the df as the argument, and return a new data frame of centroids that is of the exact same format as the centroid_df you created in Part 3.\n\n# your code\n\n\n\n\n\n\n\nCODE CHECK\n\n\n\n\n\nIf you run your get_centroids() function on the current data, you should return the following data frame (column order shouldn’t really matter):"
  },
  {
    "objectID": "implementations/implementation_kmeans.html#run-the-algorithm",
    "href": "implementations/implementation_kmeans.html#run-the-algorithm",
    "title": "K-means",
    "section": "Run the algorithm",
    "text": "Run the algorithm\n\nPart 6: putting it all together!\nNow, we need to put everything together into a single algorithm. We want to continue iterating back and forth between re-assigning and calculating centroids until we converge (i.e. when the cluster assignments stop changing). We can use a while loop for this! The syntax is while(condidition){} that says while the condition is TRUE, continue to run the loop. The caution here is that your loop could run FOREVER if you don’t have a line of code somewhere that will “break” the loop. IF THIS HAPPENS: you can always interrupt code in R by typing Ctrl + C.\nAt the bottom of the while loop, I provide code that will check if we have converged or not using the identical() function. Note that this function requires the two objects to be exactly identical (same ordering of columns, rows, column names, etc.)\nTo test your code, I suggest stepping through each line code of within the while loop one-at-a-time and then going back to the top of the loop and stepping through the code again, rather than run the entire loop at once. Once you’re happy with it, uncomment where I set flag <- TRUE above the while() loop, and run your loop!\nBe careful about the inputs/arguments that each function expects!\n\n# define flag = T\nwhile(flag){\n  # TO DO: obtain new clusters\n  \n  \n  # TO DO: replace the clusters in df with the new clusters obtained above\n  \n  \n  # TO DO: obtain centroids of new clusters; store into a data frame called centroid_df_new\n  \n  \n  \n  # check if centroid assignments have changed\n  if(identical(centroid_df_new, centroid_df) == TRUE){ \n    # if no: set flag = FALSE, and break out of loop\n    print(\"done\")\n    flag <- F\n  } else{ \n    # if yes: need to continue iterating\n    print(\"centroids:\")\n    print(centroid_df_new)\n    centroid_df <- centroid_df_new\n  }\n}\n\n\n\n\n\n\n\nCODE CHECK\n\n\n\n\n\nIf you run your algorithm given the same data and initial centroids as described above, your final centroids should be (note: the cluster value is arbitrary):\n\n\n\n\n\n\n\n\n\n\nPart 7: Visualize!\n\nUsing df, plot the observations by their features and color by the final cluster assignment. Use centroid_df to add the centroids to your plot, and use the shape aesthetic to denote whether an observation was clustered into a correct group. Recall that the observations with id 1-25 were truly a cluster, and those with id 26-50 were truly another cluster.\nWhat do you notice about the observations that are incorrectly clustered, if any?"
  },
  {
    "objectID": "implementations/implementation_kmeans.html#submit",
    "href": "implementations/implementation_kmeans.html#submit",
    "title": "K-means",
    "section": "Submit",
    "text": "Submit\nDon’t forget to set eval = TRUE in all the code chunk headers before you submit! Knit + commit + push one last time, then submit the PDF to Canvas."
  },
  {
    "objectID": "live-code/live-code-h-clust.html",
    "href": "live-code/live-code-h-clust.html",
    "title": "Live code:",
    "section": "",
    "text": "library(tidyverse)\n\nWe use the function hclust() to implement hierarchical clustering! We need to pass in two arguments:\n\nA distance matrix of the dissimilarities between observations. The distance matrix must always be \\(n \\times n\\), where \\(n\\) is the number of observations. The pairwise Euclidean distances are easily calculated used dist().\nWe also need to specify the type of linkage, in quotes\n\n“average”, “single”, “complete”, or “centroid” (there are others, but we didn’t discuss in class)\n\n\nWe will visit the USArrests data we saw in class. I will grab two variables, and go ahead and standardize them.\n\ndata(\"USArrests\")\nusarrests <- USArrests %>%\n  select(Murder, UrbanPop) %>%\n  mutate_all(scale)\n\ndists <- dist(usarrests)\nhc_complete <- hclust(d = dists, method = \"complete\")\n\nWe can easily pass the output into the plot() function to visualize the entire dendrogram:\n\nplot(hc_complete)\n\n\n\n\nI personally prefer ggplots, so if you install the ggdendro package, you can obtain the following plot:\n\nlibrary(ggdendro)\nggdendrogram(hc_complete) +\n  ggtitle(\"Complete linkage\")\n\n\n\n\nTo determine the cluster labels associated with a given cut of the dendrogram, we use the cutree() function. It takes in the output from hclust() and the number of clusters k we want to obtain. In the following, I obtain three clusters:\n\nk <- 3\nhclusts <- cutree(hc_complete, k = k)\nhclusts\n\n       Alabama         Alaska        Arizona       Arkansas     California \n             1              2              2              2              2 \n      Colorado    Connecticut       Delaware        Florida        Georgia \n             2              2              2              2              1 \n        Hawaii          Idaho       Illinois        Indiana           Iowa \n             2              3              2              2              3 \n        Kansas       Kentucky      Louisiana          Maine       Maryland \n             2              2              1              3              2 \n Massachusetts       Michigan      Minnesota    Mississippi       Missouri \n             2              2              3              1              2 \n       Montana       Nebraska         Nevada  New Hampshire     New Jersey \n             3              3              2              3              2 \n    New Mexico       New York North Carolina   North Dakota           Ohio \n             2              2              1              3              2 \n      Oklahoma         Oregon   Pennsylvania   Rhode Island South Carolina \n             2              3              2              2              1 \n  South Dakota      Tennessee          Texas           Utah        Vermont \n             3              1              2              2              3 \n      Virginia     Washington  West Virginia      Wisconsin        Wyoming \n             2              2              3              3              2 \n\n\nFrom the output, we can see to which of the 4 clusters each state has been assigned. To get an idea of the spread across the clusters, we can use the table() function:\n\ntable(hclusts)\n\nhclusts\n 1  2  3 \n 7 30 13"
  },
  {
    "objectID": "live-code/live-code-h-clust.html#comparing-to-k-means",
    "href": "live-code/live-code-h-clust.html#comparing-to-k-means",
    "title": "Live code:",
    "section": "Comparing to k-means",
    "text": "Comparing to k-means\nWhat happens if I run the k-means algorithm on the same set of data? Do we think the two methods will agree with each other if I specify I want the same number of clusters?\n\nset.seed(1)\nkmeans_out <- kmeans(usarrests, centers = k, nstart = 10)\nkmeans_clusts <- kmeans_out$cluster\n\nNow, let’s be careful! There’s no reason why cluster 1 from hierarchical clustering should be the “same” as cluster 1 from k-means. So if we want to compare the results from the two methods, we just need to see if a cluster from the hierarchical method has a lot of the same observations as a cluster from k-means.\n\ntable(hclusts, kmeans_clusts)\n\n       kmeans_clusts\nhclusts  1  2  3\n      1  0  0  7\n      2  1 21  8\n      3 12  1  0"
  },
  {
    "objectID": "live-code/live-code-h-clust.html#linkage-choices",
    "href": "live-code/live-code-h-clust.html#linkage-choices",
    "title": "Live code:",
    "section": "Linkage choices",
    "text": "Linkage choices\nTry playing around with different choices of linkage! What do you notice if you use single linkage?"
  }
]